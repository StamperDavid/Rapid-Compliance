[{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\analyze-eslint-stream.js","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":1,"column":12,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":1,"endColumn":25},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":2,"column":18,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":2,"endColumn":37}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"const fs = require('fs');\r\nconst readline = require('readline');\r\n\r\nasync function analyzeESLint() {\r\n  const fileStream = fs.createReadStream('eslint-output.txt', { encoding: 'utf8' });\r\n  const rl = readline.createInterface({\r\n    input: fileStream,\r\n    crlfDelay: Infinity\r\n  });\r\n\r\n  const ruleCounts = {};\r\n  const severityCounts = { error: 0, warning: 0 };\r\n  let totalIssues = 0;\r\n  let filesWithIssues = 0;\r\n\r\n  const issuePattern = /^\\s+(\\d+):(\\d+)\\s+(error|warning)\\s+(.+)$/;\r\n  const filePattern = /^[A-Z]:\\\\.+\\.(tsx?|jsx?|css)$/;\r\n\r\n  for await (const line of rl) {\r\n    // Check if it's a file path\r\n    if (filePattern.test(line.trim())) {\r\n      filesWithIssues++;\r\n      continue;\r\n    }\r\n\r\n    // Check if it's an issue line\r\n    const match = line.match(issuePattern);\r\n    if (match) {\r\n      const [, lineNum, col, severity, rest] = match;\r\n      \r\n      // Split by 2+ spaces to separate message from rule name\r\n      const parts = rest.split(/\\s{2,}/);\r\n      if (parts.length >= 2) {\r\n        const ruleId = parts[parts.length - 1].trim();\r\n        const message = parts.slice(0, -1).join(' ').trim();\r\n        \r\n        if (!ruleCounts[ruleId]) {\r\n          ruleCounts[ruleId] = { total: 0, errors: 0, warnings: 0, sampleMessage: message };\r\n        }\r\n        \r\n        ruleCounts[ruleId].total++;\r\n        if (severity === 'error') {\r\n          ruleCounts[ruleId].errors++;\r\n          severityCounts.error++;\r\n        } else {\r\n          ruleCounts[ruleId].warnings++;\r\n          severityCounts.warning++;\r\n        }\r\n        totalIssues++;\r\n      }\r\n    }\r\n  }\r\n\r\n  // Sort by total count\r\n  const sortedRules = Object.entries(ruleCounts)\r\n    .sort((a, b) => b[1].total - a[1].total);\r\n\r\n  // Print summary\r\n  console.log('='.repeat(105));\r\n  console.log('ESLINT DIAGNOSTIC REPORT - src/app/**');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n  console.log(`Files with Issues: ${filesWithIssues}`);\r\n  console.log(`Total Errors: ${severityCounts.error}`);\r\n  console.log(`Total Warnings: ${severityCounts.warning}`);\r\n  console.log(`Total Issues: ${totalIssues}`);\r\n  console.log(`Unique Rules Triggered: ${sortedRules.length}`);\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('TOP 10 MOST FREQUENT ESLINT RULES');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n  console.log('Rank'.padStart(5) + ' ' + 'Rule Name'.padEnd(55) + 'Total'.padStart(10) + ' ' + 'Errors'.padStart(8) + ' ' + 'Warns'.padStart(8) + ' ' + '%'.padStart(8));\r\n  console.log('-'.repeat(105));\r\n\r\n  sortedRules.slice(0, 10).forEach(([rule, counts], index) => {\r\n    const percentage = ((counts.total / totalIssues) * 100).toFixed(1);\r\n    console.log(\r\n      (index + 1).toString().padStart(5) + ' ' +\r\n      rule.padEnd(55) + \r\n      counts.total.toString().padStart(10) + ' ' +\r\n      counts.errors.toString().padStart(8) + ' ' +\r\n      counts.warnings.toString().padStart(8) + ' ' +\r\n      (percentage + '%').padStart(8)\r\n    );\r\n  });\r\n\r\n  const top10Total = sortedRules.slice(0, 10).reduce((sum, [_, counts]) => sum + counts.total, 0);\r\n  const top10Percentage = ((top10Total / totalIssues) * 100).toFixed(1);\r\n  console.log('-'.repeat(105));\r\n  console.log('TOP 10 TOTAL:'.padEnd(61) + top10Total.toString().padStart(10) + ''.padStart(10) + ''.padStart(10) + (top10Percentage + '%').padStart(8));\r\n\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('RULES 11-20');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n  console.log('Rank'.padStart(5) + ' ' + 'Rule Name'.padEnd(55) + 'Total'.padStart(10) + ' ' + 'Errors'.padStart(8) + ' ' + 'Warns'.padStart(8) + ' ' + '%'.padStart(8));\r\n  console.log('-'.repeat(105));\r\n\r\n  sortedRules.slice(10, 20).forEach(([rule, counts], index) => {\r\n    const percentage = ((counts.total / totalIssues) * 100).toFixed(1);\r\n    console.log(\r\n      (index + 11).toString().padStart(5) + ' ' +\r\n      rule.padEnd(55) + \r\n      counts.total.toString().padStart(10) + ' ' +\r\n      counts.errors.toString().padStart(8) + ' ' +\r\n      counts.warnings.toString().padStart(8) + ' ' +\r\n      (percentage + '%').padStart(8)\r\n    );\r\n  });\r\n\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('GHOST ERRORS ANALYSIS');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n  console.log('Checking for rules that trigger actual \"error\" severity...');\r\n  console.log('(These rules are configured as \"error\" but may need to be \"warn\" or vice versa)');\r\n  console.log();\r\n\r\n  const rulesWithErrors = sortedRules.filter(([_, counts]) => counts.errors > 0);\r\n  if (rulesWithErrors.length > 0) {\r\n    console.log(`‚ö†Ô∏è  Found ${rulesWithErrors.length} rules with ERROR severity:`);\r\n    console.log();\r\n    rulesWithErrors.forEach(([rule, counts]) => {\r\n      console.log(`  ${rule}:`);\r\n      console.log(`    ${counts.errors} errors, ${counts.warnings} warnings`);\r\n      console.log(`    Sample: ${counts.sampleMessage}`);\r\n      console.log();\r\n    });\r\n  } else {\r\n    console.log('  ‚úì No \"ghost errors\" found');\r\n    console.log('  All violations are at \"warning\" level (as configured in .eslintrc.json)');\r\n  }\r\n\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('TOP 10 RULES - SAMPLE VIOLATIONS');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n\r\n  sortedRules.slice(0, 10).forEach(([rule, counts], index) => {\r\n    console.log(`${index + 1}. ${rule}`);\r\n    console.log(`   Count: ${counts.total} | Sample: ${counts.sampleMessage}`);\r\n    console.log();\r\n  });\r\n\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('ALL RULES SUMMARY (' + sortedRules.length + ' unique rules)');\r\n  console.log('='.repeat(105));\r\n  console.log();\r\n\r\n  sortedRules.forEach(([rule, counts], index) => {\r\n    const percentage = ((counts.total / totalIssues) * 100).toFixed(1);\r\n    console.log(`${(index + 1).toString().padStart(3)}. ${rule.padEnd(55)} ${counts.total.toString().padStart(6)} (${percentage.padStart(5)}%)`);\r\n  });\r\n\r\n  // Save detailed analysis\r\n  const analysis = {\r\n    summary: {\r\n      filesWithIssues,\r\n      totalErrors: severityCounts.error,\r\n      totalWarnings: severityCounts.warning,\r\n      totalIssues,\r\n      uniqueRules: sortedRules.length\r\n    },\r\n    topRules: sortedRules.slice(0, 20).map(([rule, counts]) => ({\r\n      rule,\r\n      total: counts.total,\r\n      errors: counts.errors,\r\n      warnings: counts.warnings,\r\n      percentage: ((counts.total / totalIssues) * 100).toFixed(2),\r\n      sampleMessage: counts.sampleMessage\r\n    })),\r\n    allRules: sortedRules.map(([rule, counts]) => ({\r\n      rule,\r\n      total: counts.total,\r\n      errors: counts.errors,\r\n      warnings: counts.warnings,\r\n      percentage: ((counts.total / totalIssues) * 100).toFixed(2)\r\n    }))\r\n  };\r\n\r\n  fs.writeFileSync('eslint-analysis.json', JSON.stringify(analysis, null, 2));\r\n  console.log();\r\n  console.log('='.repeat(105));\r\n  console.log('‚úÖ Detailed JSON analysis saved to: eslint-analysis.json');\r\n  console.log('='.repeat(105));\r\n}\r\n\r\nanalyzeESLint().catch(console.error);\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\analyze-post-recovery-lint.js","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":1,"column":12,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":1,"endColumn":25}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"const fs = require('fs');\r\n\r\n// Read the ESLint JSON output\r\nconst rawData = fs.readFileSync('post_recovery_lint.json', 'utf8');\r\nconst results = JSON.parse(rawData);\r\n\r\n// Calculate totals\r\nlet totalErrors = 0;\r\nlet totalWarnings = 0;\r\nconst fileWarnings = [];\r\n\r\nresults.forEach(file => {\r\n  totalErrors += file.errorCount || 0;\r\n  totalWarnings += file.warningCount || 0;\r\n  \r\n  if (file.warningCount > 0) {\r\n    fileWarnings.push({\r\n      filePath: file.filePath,\r\n      warningCount: file.warningCount,\r\n      errorCount: file.errorCount || 0\r\n    });\r\n  }\r\n});\r\n\r\n// Sort files by warning count (descending)\r\nfileWarnings.sort((a, b) => b.warningCount - a.warningCount);\r\n\r\n// Get top 5 files with most warnings\r\nconst top5Files = fileWarnings.slice(0, 5);\r\n\r\n// Original count (from user's mention of 21,000)\r\nconst originalWarnings = 21000;\r\nconst ghostFactor = originalWarnings - totalWarnings;\r\n\r\n// Output results\r\nconst report = {\r\n  totalErrors,\r\n  totalWarnings,\r\n  ghostFactor,\r\n  ghostFactorPercentage: ((ghostFactor / originalWarnings) * 100).toFixed(2),\r\n  top5Files: top5Files.map(f => ({\r\n    file: f.filePath.replace(/\\\\/g, '/').split('/').slice(-3).join('/'), // Show last 3 path segments\r\n    fullPath: f.filePath,\r\n    warnings: f.warningCount,\r\n    errors: f.errorCount\r\n  }))\r\n};\r\n\r\nconsole.log(JSON.stringify(report, null, 2));\r\n\r\n// Also save to a file for reference\r\nfs.writeFileSync('post_recovery_lint_analysis.json', JSON.stringify(report, null, 2));\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\batch-fix-orgid.js","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":1,"column":12,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":1,"endColumn":25},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":2,"column":14,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":2,"endColumn":29}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"const fs = require('fs');\r\nconst glob = require('glob');\r\n\r\n// Find all API route files\r\nconst apiFiles = glob.sync('src/app/api/**/*.ts', { nodir: true });\r\n\r\nlet fixCount = 0;\r\n\r\napiFiles.forEach(file => {\r\n  try {\r\n    let content = fs.readFileSync(file, 'utf8');\r\n    let modified = false;\r\n\r\n    // Pattern 1: const organizationId = token.organizationId; (without check)\r\n    const pattern1 = /(const organizationId = token\\.organizationId;)\\n(\\s+)(const |let |if |const\\s*{|\\/\\/)/;\r\n    if (pattern1.test(content) && !content.includes('if (!organizationId)')) {\r\n      content = content.replace(\r\n        pattern1,\r\n        `$1\\n$2\\n$2if (!organizationId) {\\n$2  return NextResponse.json({ error: 'Organization ID required' }, { status: 400 });\\n$2}\\n$2\\n$2$3`\r\n      );\r\n      modified = true;\r\n    }\r\n\r\n    // Pattern 2: const { user } = authResult; await ...user.organizationId (without check in between)\r\n    const pattern2 = /(const { user } = authResult;)\\n(\\s+)(await .+user\\.organizationId)/;\r\n    if (pattern2.test(content) && !content.match(/const { user } = authResult;\\s+if \\(!user\\.organizationId\\)/)) {\r\n      content = content.replace(\r\n        pattern2,\r\n        `$1\\n$2\\n$2if (!user.organizationId) {\\n$2  return errors.badRequest('Organization ID required');\\n$2}\\n$2\\n$2$3`\r\n      );\r\n      modified = true;\r\n    }\r\n\r\n    if (modified) {\r\n      fs.writeFileSync(file, content, 'utf8');\r\n      console.log(`‚úÖ Fixed: ${file}`);\r\n      fixCount++;\r\n    }\r\n  } catch (error) {\r\n    // Silently skip files that don't match\r\n  }\r\n});\r\n\r\nconsole.log(`\\n‚úÖ Total files fixed: ${fixCount}`);\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\fix-org-id-checks.js","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":1,"column":12,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":1,"endColumn":25},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":2,"column":14,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":2,"endColumn":29}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"const fs = require('fs');\r\nconst path = require('path');\r\n\r\n// Files that need organizationId checks\r\nconst files = [\r\n  'src/app/api/crm/activities/stats/route.ts',\r\n  'src/app/api/crm/activities/timeline/route.ts',\r\n  'src/app/api/crm/deals/[dealId]/health/route.ts',\r\n  'src/app/api/meetings/schedule/route.ts',\r\n  'src/app/api/team/leaderboard/route.ts',\r\n  'src/app/api/leads/route-lead/route.ts',\r\n  'src/app/api/team/tasks/route.ts',\r\n  'src/app/api/crm/duplicates/merge/route.ts',\r\n  'src/app/api/crm/analytics/velocity/route.ts',\r\n  'src/app/api/proposals/generate/route.ts',\r\n  'src/app/api/crm/duplicates/route.ts',\r\n];\r\n\r\nlet fixedCount = 0;\r\n\r\nfiles.forEach(filePath => {\r\n  try {\r\n    let content = fs.readFileSync(filePath, 'utf8');\r\n    \r\n    // Pattern: const organizationId = token.organizationId; followed by next line\r\n    const pattern = /(const organizationId = token\\.organizationId;)\\n(\\s+)(const |let )/;\r\n    \r\n    if (pattern.test(content)) {\r\n      content = content.replace(\r\n        pattern,\r\n        `$1\\n$2\\n$2if (!organizationId) {\\n$2  return NextResponse.json({ error: 'Organization ID required' }, { status: 400 });\\n$2}\\n$2\\n$2$3`\r\n      );\r\n      \r\n      fs.writeFileSync(filePath, content, 'utf8');\r\n      console.log(`‚úÖ Fixed: ${filePath}`);\r\n      fixedCount++;\r\n    } else {\r\n      console.log(`‚è≠Ô∏è  Skipped (pattern not found): ${filePath}`);\r\n    }\r\n  } catch (error) {\r\n    console.log(`‚ùå Error processing ${filePath}:`, error.message);\r\n  }\r\n});\r\n\r\nconsole.log(`\\n‚úÖ Fixed ${fixedCount} files`);\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\jest.globalTeardown.js","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":8,"column":20,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":8,"endColumn":37},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":9,"column":29,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":9,"endColumn":60}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Jest Global Teardown\r\n * Runs AFTER all tests to clean up test data from DEV database\r\n * \r\n * USES db-manager.js as single source of truth for cleanup logic\r\n */\r\n\r\nconst { config } = require('dotenv');\r\nconst { cleanupTestData } = require('./scripts/db-manager');\r\n\r\n// Load environment variables\r\nconfig({ path: '.env.local' });\r\n\r\nmodule.exports = async () => {\r\n  console.log('\\nüßπ ========================================');\r\n  console.log('üßπ JEST TEARDOWN: Cleaning test data...');\r\n  console.log('üßπ Using db-manager.js for cleanup');\r\n  console.log('üßπ ========================================\\n');\r\n\r\n  try {\r\n    // Use the official cleanup logic from db-manager.js\r\n    // Run in LIVE mode (not dry run) to actually clean up\r\n    await cleanupTestData(false);\r\n    \r\n  } catch (error) {\r\n    console.error('\\n‚ùå Cleanup failed:', error);\r\n    // Don't fail the tests if cleanup fails\r\n  }\r\n};\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\jest.setup.js","messages":[{"ruleId":"@typescript-eslint/ban-ts-comment","severity":2,"message":"Use \"@ts-expect-error\" instead of \"@ts-ignore\", as \"@ts-ignore\" will do nothing if the following line is error-free.","line":48,"column":3,"nodeType":"Line","messageId":"tsIgnoreInsteadOfExpectError","endLine":48,"endColumn":16,"suggestions":[{"messageId":"replaceTsIgnoreWithTsExpectError","fix":{"range":[1916,1929],"text":"// @ts-expect-error"},"desc":"Replace \"@ts-ignore\" with \"@ts-expect-error\"."}]},{"ruleId":"@typescript-eslint/ban-ts-comment","severity":2,"message":"Use \"@ts-expect-error\" instead of \"@ts-ignore\", as \"@ts-ignore\" will do nothing if the following line is error-free.","line":52,"column":3,"nodeType":"Line","messageId":"tsIgnoreInsteadOfExpectError","endLine":52,"endColumn":16,"suggestions":[{"messageId":"replaceTsIgnoreWithTsExpectError","fix":{"range":[1999,2012],"text":"// @ts-expect-error"},"desc":"Replace \"@ts-ignore\" with \"@ts-expect-error\"."}]},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":57,"column":1,"nodeType":"Identifier","messageId":"undef","endLine":57,"endColumn":5},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":60,"column":13,"nodeType":"Identifier","messageId":"undef","endLine":60,"endColumn":17},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":61,"column":16,"nodeType":"Identifier","messageId":"undef","endLine":61,"endColumn":20},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":62,"column":17,"nodeType":"Identifier","messageId":"undef","endLine":62,"endColumn":21},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":63,"column":13,"nodeType":"Identifier","messageId":"undef","endLine":63,"endColumn":17},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":76,"column":1,"nodeType":"Identifier","messageId":"undef","endLine":76,"endColumn":5},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":77,"column":37,"nodeType":"Identifier","messageId":"undef","endLine":77,"endColumn":41},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":78,"column":24,"nodeType":"Identifier","messageId":"undef","endLine":78,"endColumn":28},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":90,"column":1,"nodeType":"Identifier","messageId":"undef","endLine":90,"endColumn":5},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":92,"column":14,"nodeType":"Identifier","messageId":"undef","endLine":92,"endColumn":18},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":93,"column":20,"nodeType":"Identifier","messageId":"undef","endLine":93,"endColumn":24},{"ruleId":"no-undef","severity":2,"message":"'jest' is not defined.","line":94,"column":15,"nodeType":"Identifier","messageId":"undef","endLine":94,"endColumn":19}],"suppressedMessages":[],"errorCount":14,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"// Load environment variables FIRST (before any other imports)\nimport { config } from 'dotenv'\nconfig({ path: '.env.local' })\n\n// Set NODE_ENV to test\nprocess.env.NODE_ENV = 'test'\n\n// üõ°Ô∏è PROTECTION: Block tests from running against PRODUCTION\n// DEV database (ai-sales-platform-dev) is correct for tests\n// PROD database (ai-sales-platform-4f5e4) must NEVER have tests run against it\nconst PRODUCTION_PROJECT_ID = 'ai-sales-platform-4f5e4';\nconst DEV_PROJECT_ID = 'ai-sales-platform-dev';\n\nconst currentProjectId = process.env.FIREBASE_ADMIN_PROJECT_ID || process.env.NEXT_PUBLIC_FIREBASE_PROJECT_ID;\n\n// Block if hitting PRODUCTION\nif (currentProjectId && currentProjectId.includes(PRODUCTION_PROJECT_ID)) {\n  console.error('\\n‚ùå ========================================');\n  console.error('‚ùå TESTS BLOCKED - PRODUCTION DATABASE');\n  console.error('‚ùå ========================================\\n');\n  console.error(`Current: ${currentProjectId}`);\n  console.error(`Production: ${PRODUCTION_PROJECT_ID}`);\n  console.error('\\nTests must use DEV database, not PROD!');\n  console.error('‚ùå ========================================\\n');\n  process.exit(1);\n}\n\n// Verify we're using DEV\nif (!currentProjectId || (!currentProjectId.includes(DEV_PROJECT_ID) && currentProjectId !== 'demo-ai-sales-platform')) {\n  console.warn('\\n‚ö†Ô∏è  WARNING: Tests may not be using DEV database');\n  console.warn(`   Current Project: ${currentProjectId || 'NOT SET'}`);\n  console.warn(`   Expected: ${DEV_PROJECT_ID}\\n`);\n}\n\nconsole.log('‚úÖ Test environment: DEV database');\nconsole.log(`   Project ID: ${currentProjectId}\\n`);\n\n// Learn more: https://github.com/testing-library/jest-dom\nimport '@testing-library/jest-dom'\nimport { TextEncoder, TextDecoder } from 'util'\nimport { ReadableStream } from 'stream/web'\n\n// Node test environment polyfills\nif (!global.TextEncoder) {\n  global.TextEncoder = TextEncoder\n}\nif (!global.TextDecoder) {\n  // @ts-ignore\n  global.TextDecoder = TextDecoder\n}\nif (!global.ReadableStream) {\n  // @ts-ignore\n  global.ReadableStream = ReadableStream\n}\n\n// Mock Next.js router\njest.mock('next/navigation', () => ({\n  useRouter() {\n    return {\n      push: jest.fn(),\n      replace: jest.fn(),\n      prefetch: jest.fn(),\n      back: jest.fn(),\n    }\n  },\n  useSearchParams() {\n    return new URLSearchParams()\n  },\n  usePathname() {\n    return '/'\n  },\n}))\n\n// Mock FirestoreService to use AdminFirestoreService (bypasses security rules for tests)\n// This is CRITICAL - Admin SDK bypasses Firestore security rules, allowing tests to write to dev database\njest.mock('@/lib/db/firestore-service', () => {\n  const { AdminFirestoreService } = jest.requireActual('@/lib/db/admin-firestore-service');\n  const actualModule = jest.requireActual('@/lib/db/firestore-service');\n  return {\n    FirestoreService: AdminFirestoreService,\n    COLLECTIONS: actualModule.COLLECTIONS,\n    RecordService: actualModule.RecordService,\n    WorkflowService: actualModule.WorkflowService,\n    EmailCampaignService: actualModule.EmailCampaignService,\n    LeadNurturingService: actualModule.LeadNurturingService,\n  };\n});\n\n// Mock API Key Service\njest.mock('@/lib/api-keys/api-key-service', () => ({\n  apiKeyService: {\n    getKeys: jest.fn(),\n    getServiceKey: jest.fn(),\n    saveKeys: jest.fn(),\n  },\n}));\n\n// Firebase will use real config from environment variables\n// Tests connect to actual Firebase DEV database using Admin SDK (bypasses security rules)\n\n// Log Firebase Admin config for debugging\nconsole.log('[Jest Setup] Firebase Admin Config:', {\n  projectId: process.env.FIREBASE_ADMIN_PROJECT_ID || 'NOT SET',\n  clientEmail: process.env.FIREBASE_ADMIN_CLIENT_EMAIL ? 'SET' : 'NOT SET',\n  privateKeyLength: process.env.FIREBASE_ADMIN_PRIVATE_KEY ? process.env.FIREBASE_ADMIN_PRIVATE_KEY.length : 0\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\scripts\\backup-firestore.ts","messages":[{"ruleId":null,"fatal":true,"severity":2,"message":"Parsing error: \"parserOptions.project\" has been provided for @typescript-eslint/parser.\nThe file was not found in any of the provided project(s): scripts\\backup-firestore.ts","nodeType":null}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":1,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Firestore Backup Script\r\n * Automated database backups with point-in-time recovery\r\n * \r\n * Run with: ts-node scripts/backup-firestore.ts\r\n */\r\n\r\nimport { initializeApp, cert } from 'firebase-admin/app';\r\nimport { getFirestore } from 'firebase-admin/firestore';\r\nimport * as fs from 'fs';\r\nimport * as path from 'path';\r\n\r\n// Configuration\r\nconst BACKUP_DIR = process.env.BACKUP_DIR || './backups';\r\nconst BACKUP_RETENTION_DAYS = parseInt(process.env.BACKUP_RETENTION_DAYS || '30');\r\nconst COLLECTIONS_TO_BACKUP = [\r\n  'organizations',\r\n  'workspaces',\r\n  'customers',\r\n  'products',\r\n  'orders',\r\n  'workflows',\r\n  'agents',\r\n  'integrations',\r\n];\r\n\r\n/**\r\n * Initialize Firebase Admin\r\n */\r\nfunction initializeFirebase() {\r\n  if (!process.env.GOOGLE_APPLICATION_CREDENTIALS) {\r\n    throw new Error('GOOGLE_APPLICATION_CREDENTIALS environment variable not set');\r\n  }\r\n  \r\n  initializeApp({\r\n    credential: cert(process.env.GOOGLE_APPLICATION_CREDENTIALS),\r\n  });\r\n  \r\n  return getFirestore();\r\n}\r\n\r\n/**\r\n * Create backup directory\r\n */\r\nfunction ensureBackupDir(timestamp: string): string {\r\n  const backupPath = path.join(BACKUP_DIR, timestamp);\r\n  \r\n  if (!fs.existsSync(backupPath)) {\r\n    fs.mkdirSync(backupPath, { recursive: true });\r\n  }\r\n  \r\n  return backupPath;\r\n}\r\n\r\n/**\r\n * Backup a single collection\r\n */\r\nasync function backupCollection(\r\n  db: FirebaseFirestore.Firestore,\r\n  collectionName: string,\r\n  backupPath: string\r\n): Promise<number> {\r\n  console.log(`[Backup] Starting backup of ${collectionName}...`);\r\n  \r\n  const collection = db.collection(collectionName);\r\n  const snapshot = await collection.get();\r\n  \r\n  const documents: any[] = [];\r\n  \r\n  snapshot.forEach(doc => {\r\n    documents.push({\r\n      id: doc.id,\r\n      data: doc.data(),\r\n    });\r\n  });\r\n  \r\n  const filePath = path.join(backupPath, `${collectionName}.json`);\r\n  fs.writeFileSync(filePath, JSON.stringify(documents, null, 2));\r\n  \r\n  console.log(`[Backup] ‚úì Backed up ${documents.length} documents from ${collectionName}`);\r\n  \r\n  return documents.length;\r\n}\r\n\r\n/**\r\n * Backup all collections\r\n */\r\nasync function backupAllCollections(): Promise<void> {\r\n  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');\r\n  const backupPath = ensureBackupDir(timestamp);\r\n  \r\n  console.log(`[Backup] Starting full backup to ${backupPath}`);\r\n  console.log(`[Backup] Timestamp: ${timestamp}`);\r\n  \r\n  const db = initializeFirebase();\r\n  \r\n  let totalDocuments = 0;\r\n  \r\n  for (const collectionName of COLLECTIONS_TO_BACKUP) {\r\n    try {\r\n      const count = await backupCollection(db, collectionName, backupPath);\r\n      totalDocuments += count;\r\n    } catch (error) {\r\n      console.error(`[Backup] Error backing up ${collectionName}:`, error);\r\n    }\r\n  }\r\n  \r\n  // Create metadata file\r\n  const metadata = {\r\n    timestamp,\r\n    collections: COLLECTIONS_TO_BACKUP,\r\n    totalDocuments,\r\n    completed: new Date().toISOString(),\r\n  };\r\n  \r\n  fs.writeFileSync(\r\n    path.join(backupPath, '_metadata.json'),\r\n    JSON.stringify(metadata, null, 2)\r\n  );\r\n  \r\n  console.log(`[Backup] ‚úì Backup complete! Total documents: ${totalDocuments}`);\r\n  console.log(`[Backup] Backup location: ${backupPath}`);\r\n}\r\n\r\n/**\r\n * Restore from backup\r\n */\r\nasync function restoreFromBackup(backupTimestamp: string): Promise<void> {\r\n  const backupPath = path.join(BACKUP_DIR, backupTimestamp);\r\n  \r\n  if (!fs.existsSync(backupPath)) {\r\n    throw new Error(`Backup not found: ${backupPath}`);\r\n  }\r\n  \r\n  console.log(`[Restore] Starting restore from ${backupPath}`);\r\n  \r\n  const db = initializeFirebase();\r\n  \r\n  for (const collectionName of COLLECTIONS_TO_BACKUP) {\r\n    const filePath = path.join(backupPath, `${collectionName}.json`);\r\n    \r\n    if (!fs.existsSync(filePath)) {\r\n      console.warn(`[Restore] Skipping ${collectionName} (file not found)`);\r\n      continue;\r\n    }\r\n    \r\n    console.log(`[Restore] Restoring ${collectionName}...`);\r\n    \r\n    const data = JSON.parse(fs.readFileSync(filePath, 'utf-8'));\r\n    const collection = db.collection(collectionName);\r\n    \r\n    const batch = db.batch();\r\n    let batchCount = 0;\r\n    \r\n    for (const doc of data) {\r\n      batch.set(collection.doc(doc.id), doc.data);\r\n      batchCount++;\r\n      \r\n      // Firestore batch limit is 500\r\n      if (batchCount === 500) {\r\n        await batch.commit();\r\n        batchCount = 0;\r\n      }\r\n    }\r\n    \r\n    // Commit remaining\r\n    if (batchCount > 0) {\r\n      await batch.commit();\r\n    }\r\n    \r\n    console.log(`[Restore] ‚úì Restored ${data.length} documents to ${collectionName}`);\r\n  }\r\n  \r\n  console.log(`[Restore] ‚úì Restore complete!`);\r\n}\r\n\r\n/**\r\n * Clean up old backups\r\n */\r\nfunction cleanupOldBackups(): void {\r\n  console.log(`[Cleanup] Removing backups older than ${BACKUP_RETENTION_DAYS} days...`);\r\n  \r\n  if (!fs.existsSync(BACKUP_DIR)) {\r\n    return;\r\n  }\r\n  \r\n  const now = Date.now();\r\n  const retentionMs = BACKUP_RETENTION_DAYS * 24 * 60 * 60 * 1000;\r\n  \r\n  const backups = fs.readdirSync(BACKUP_DIR);\r\n  let removed = 0;\r\n  \r\n  for (const backup of backups) {\r\n    const backupPath = path.join(BACKUP_DIR, backup);\r\n    const stats = fs.statSync(backupPath);\r\n    \r\n    if (now - stats.mtimeMs > retentionMs) {\r\n      fs.rmSync(backupPath, { recursive: true, force: true });\r\n      console.log(`[Cleanup] Removed old backup: ${backup}`);\r\n      removed++;\r\n    }\r\n  }\r\n  \r\n  console.log(`[Cleanup] ‚úì Removed ${removed} old backups`);\r\n}\r\n\r\n/**\r\n * Main execution\r\n */\r\nasync function main() {\r\n  const command = process.argv[2];\r\n  \r\n  try {\r\n    switch (command) {\r\n      case 'backup':\r\n        await backupAllCollections();\r\n        cleanupOldBackups();\r\n        break;\r\n      \r\n      case 'restore':\r\n        const timestamp = process.argv[3];\r\n        if (!timestamp) {\r\n          console.error('Usage: ts-node backup-firestore.ts restore <timestamp>');\r\n          process.exit(1);\r\n        }\r\n        await restoreFromBackup(timestamp);\r\n        break;\r\n      \r\n      case 'list':\r\n        if (fs.existsSync(BACKUP_DIR)) {\r\n          const backups = fs.readdirSync(BACKUP_DIR);\r\n          console.log('Available backups:');\r\n          backups.forEach(backup => {\r\n            const metadataPath = path.join(BACKUP_DIR, backup, '_metadata.json');\r\n            if (fs.existsSync(metadataPath)) {\r\n              const metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf-8'));\r\n              console.log(`  ${backup} - ${metadata.totalDocuments} documents`);\r\n            }\r\n          });\r\n        } else {\r\n          console.log('No backups found');\r\n        }\r\n        break;\r\n      \r\n      default:\r\n        console.log('Usage:');\r\n        console.log('  ts-node backup-firestore.ts backup          - Create new backup');\r\n        console.log('  ts-node backup-firestore.ts restore <time>  - Restore from backup');\r\n        console.log('  ts-node backup-firestore.ts list            - List available backups');\r\n        process.exit(1);\r\n    }\r\n  } catch (error) {\r\n    console.error('[Error]', error);\r\n    process.exit(1);\r\n  }\r\n}\r\n\r\n// Run if called directly\r\nif (require.main === module) {\r\n  main();\r\n}\r\n\r\nexport { backupAllCollections, restoreFromBackup, cleanupOldBackups };\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\scripts\\filter-orgs-by-date.js","messages":[{"ruleId":"no-empty","severity":2,"message":"Empty block statement.","line":217,"column":23,"nodeType":"BlockStatement","messageId":"unexpected","endLine":217,"endColumn":25,"suggestions":[{"messageId":"suggestComment","data":{"type":"block"},"fix":{"range":[7729,7729],"text":" /* empty */ "},"desc":"Add comment inside empty block statement."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * FILTER ORGANIZATIONS BY DATE\r\n * \r\n * Shows all organizations with their creation dates.\r\n * Can delete orgs created before a specific date.\r\n * \r\n * Usage:\r\n *   node scripts/filter-orgs-by-date.js                    # List all with dates\r\n *   node scripts/filter-orgs-by-date.js --before 2024-12-30 # Show orgs before date\r\n *   node scripts/filter-orgs-by-date.js --before 2024-12-30 --confirm # DELETE orgs before date\r\n */\r\n\r\nconst admin = require('firebase-admin');\r\nconst path = require('path');\r\n\r\nrequire('dotenv').config({ path: path.join(__dirname, '../.env.local') });\r\n\r\n// PROTECTED ORGS - NEVER DELETE\r\nconst PROTECTED_ORG_IDS = [\r\n  'platform',\r\n  'org_demo_auraflow',\r\n  'org_demo_greenthumb',\r\n  'org_demo_adventuregear',\r\n  'org_demo_summitwm',\r\n  'org_demo_pixelperfect',\r\n  'org_1767162182929_zybiwt',     // AuraFlow Analytics (TEST) - Dec 30, 2024\r\n  'org_1767162183846_33y89i',     // GreenThumb Landscaping (TEST) - Dec 30, 2024\r\n  'org_1767162184756_5xf9a9',     // The Adventure Gear Shop (TEST) - Dec 30, 2024\r\n  'org_1767162185614_xo5ryr',     // Summit Wealth Management (TEST) - Dec 30, 2024\r\n  'org_1767162186490_tptncm'      // PixelPerfect Design Co. (TEST) - Dec 30, 2024\r\n];\r\n\r\nconst args = process.argv.slice(2);\r\nconst beforeDateStr = args.find(arg => !arg.startsWith('--')) || args[args.indexOf('--before') + 1];\r\nconst confirm = args.includes('--confirm');\r\n\r\nconsole.log('\\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');\r\nconsole.log('‚ïë                                                                           ‚ïë');\r\nconsole.log('‚ïë                    FILTER ORGANIZATIONS BY DATE                           ‚ïë');\r\nconsole.log('‚ïë                                                                           ‚ïë');\r\nconsole.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\\n');\r\nconsole.log(`Project: ${process.env.FIREBASE_ADMIN_PROJECT_ID}`);\r\nconsole.log('');\r\n\r\nif (!admin.apps.length) {\r\n  admin.initializeApp({\r\n    credential: admin.credential.cert({\r\n      projectId: process.env.FIREBASE_ADMIN_PROJECT_ID,\r\n      clientEmail: process.env.FIREBASE_ADMIN_CLIENT_EMAIL,\r\n      privateKey: process.env.FIREBASE_ADMIN_PRIVATE_KEY.replace(/\\\\n/g, '\\n')\r\n    })\r\n  });\r\n}\r\n\r\nconst db = admin.firestore();\r\nconst auth = admin.auth();\r\n\r\n/**\r\n * Extract creation date from org ID or Firestore metadata\r\n */\r\nfunction getOrgCreationDate(orgId, orgData) {\r\n  // Method 1: Extract from org ID timestamp (org_TIMESTAMP_random)\r\n  const timestampMatch = orgId.match(/^(?:org|test-org|test-product)[-_](\\d{13})/);\r\n  if (timestampMatch) {\r\n    return new Date(parseInt(timestampMatch[1]));\r\n  }\r\n  \r\n  // Method 2: Use Firestore createdAt field\r\n  if (orgData && orgData.createdAt) {\r\n    if (orgData.createdAt.toDate) {\r\n      return orgData.createdAt.toDate();\r\n    }\r\n    if (orgData.createdAt instanceof Date) {\r\n      return orgData.createdAt;\r\n    }\r\n  }\r\n  \r\n  // Method 3: Unknown - use epoch\r\n  return new Date(0);\r\n}\r\n\r\n/**\r\n * Recursively delete subcollections\r\n */\r\nasync function deleteSubcollections(docRef) {\r\n  const subcollections = await docRef.listCollections();\r\n  \r\n  for (const subcollection of subcollections) {\r\n    const snapshot = await subcollection.get();\r\n    const batch = db.batch();\r\n    let batchCount = 0;\r\n    \r\n    for (const doc of snapshot.docs) {\r\n      await deleteSubcollections(doc.ref);\r\n      batch.delete(doc.ref);\r\n      batchCount++;\r\n      \r\n      if (batchCount >= 400) {\r\n        await batch.commit();\r\n        batchCount = 0;\r\n      }\r\n    }\r\n    \r\n    if (batchCount > 0) {\r\n      await batch.commit();\r\n    }\r\n  }\r\n}\r\n\r\nasync function filterByDate() {\r\n  console.log('üìã Scanning all organizations...\\n');\r\n  \r\n  const orgsSnapshot = await db.collection('organizations').get();\r\n  const orgs = [];\r\n  \r\n  // Collect all orgs with their dates\r\n  for (const doc of orgsSnapshot.docs) {\r\n    const orgId = doc.id;\r\n    const orgData = doc.data();\r\n    const createdAt = getOrgCreationDate(orgId, orgData);\r\n    const isProtected = PROTECTED_ORG_IDS.includes(orgId);\r\n    \r\n    orgs.push({\r\n      id: orgId,\r\n      name: orgData.name || 'Unnamed',\r\n      createdAt,\r\n      isProtected,\r\n      data: orgData\r\n    });\r\n  }\r\n  \r\n  // Sort by date (oldest first)\r\n  orgs.sort((a, b) => a.createdAt - b.createdAt);\r\n  \r\n  // Show all orgs with dates\r\n  console.log('üìÖ ALL ORGANIZATIONS (sorted by creation date):\\n');\r\n  console.log('Created Date       | Organization ID                    | Name                              | Status');\r\n  console.log('‚îÄ'.repeat(115));\r\n  \r\n  orgs.forEach(org => {\r\n    const dateStr = org.createdAt.toISOString().split('T')[0];\r\n    const timeStr = org.createdAt.toTimeString().split(' ')[0];\r\n    const status = org.isProtected ? 'üõ°Ô∏è  PROTECTED' : '  ';\r\n    const idPadded = org.id.padEnd(35);\r\n    const namePadded = org.name.substring(0, 30).padEnd(30);\r\n    console.log(`${dateStr} ${timeStr} | ${idPadded} | ${namePadded} | ${status}`);\r\n  });\r\n  \r\n  console.log('');\r\n  \r\n  // If filtering by date\r\n  if (beforeDateStr) {\r\n    const beforeDate = new Date(beforeDateStr);\r\n    console.log(`\\nüîç FILTERING: Organizations created BEFORE ${beforeDate.toISOString().split('T')[0]}\\n`);\r\n    \r\n    const orgsToDelete = orgs.filter(org => \r\n      !org.isProtected && org.createdAt < beforeDate\r\n    );\r\n    \r\n    const protectedBeforeDate = orgs.filter(org =>\r\n      org.isProtected && org.createdAt < beforeDate\r\n    );\r\n    \r\n    if (protectedBeforeDate.length > 0) {\r\n      console.log('üõ°Ô∏è  PROTECTED orgs before this date (will NOT delete):');\r\n      protectedBeforeDate.forEach(org => {\r\n        console.log(`   ‚úÖ ${org.id} - ${org.name} (${org.createdAt.toISOString().split('T')[0]})`);\r\n      });\r\n      console.log('');\r\n    }\r\n    \r\n    if (orgsToDelete.length === 0) {\r\n      console.log('‚úÖ No unprotected organizations found before this date!\\n');\r\n      return;\r\n    }\r\n    \r\n    console.log(`‚ö†Ô∏è  Found ${orgsToDelete.length} organizations to delete:\\n`);\r\n    orgsToDelete.forEach(org => {\r\n      console.log(`   ‚ùå ${org.id} - ${org.name} (${org.createdAt.toISOString().split('T')[0]})`);\r\n    });\r\n    console.log('');\r\n    \r\n    if (!confirm) {\r\n      console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');\r\n      console.log('üîç DRY RUN - No changes made');\r\n      console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n');\r\n      console.log('To actually delete these organizations, run:');\r\n      console.log(`   node scripts/filter-orgs-by-date.js --before ${beforeDateStr} --confirm\\n`);\r\n      return;\r\n    }\r\n    \r\n    // LIVE MODE - Actually delete\r\n    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');\r\n    console.log('‚ö†Ô∏è  DELETING ORGANIZATIONS...');\r\n    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n');\r\n    console.log('‚è≥ Starting in 3 seconds... (Press Ctrl+C to cancel)\\n');\r\n    \r\n    await new Promise(resolve => setTimeout(resolve, 3000));\r\n    \r\n    let deletedOrgs = 0;\r\n    let deletedUsers = 0;\r\n    \r\n    for (const org of orgsToDelete) {\r\n      try {\r\n        console.log(`\\nüóëÔ∏è  Deleting: ${org.id} - ${org.name}`);\r\n        \r\n        // Delete users\r\n        const usersSnapshot = await db.collection('users')\r\n          .where('organizationId', '==', org.id)\r\n          .get();\r\n        \r\n        for (const userDoc of usersSnapshot.docs) {\r\n          const userData = userDoc.data();\r\n          await db.collection('users').doc(userDoc.id).delete();\r\n          try {\r\n            await auth.deleteUser(userDoc.id);\r\n          } catch (e) {}\r\n          console.log(`   - Deleted user: ${userData.email}`);\r\n          deletedUsers++;\r\n        }\r\n        \r\n        // Delete org with subcollections\r\n        const orgRef = db.collection('organizations').doc(org.id);\r\n        await deleteSubcollections(orgRef);\r\n        await orgRef.delete();\r\n        \r\n        console.log(`   ‚úÖ Deleted organization and all data`);\r\n        deletedOrgs++;\r\n        \r\n      } catch (error) {\r\n        console.error(`   ‚ùå Error: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    console.log('\\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');\r\n    console.log('‚úÖ CLEANUP COMPLETE');\r\n    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n');\r\n    console.log(`Organizations deleted: ${deletedOrgs}`);\r\n    console.log(`Users deleted: ${deletedUsers}`);\r\n    console.log('');\r\n    \r\n  } else {\r\n    console.log('üí° To filter by date, run:');\r\n    console.log('   node scripts/filter-orgs-by-date.js --before YYYY-MM-DD');\r\n    console.log('');\r\n    console.log('Examples:');\r\n    console.log('   node scripts/filter-orgs-by-date.js --before 2024-12-30  # Show orgs before Dec 30');\r\n    console.log('   node scripts/filter-orgs-by-date.js --before 2025-01-01 --confirm  # DELETE orgs before Jan 1');\r\n    console.log('');\r\n  }\r\n}\r\n\r\nfilterByDate()\r\n  .then(() => process.exit(0))\r\n  .catch(error => {\r\n    console.error('\\n‚ùå Error:', error);\r\n    process.exit(1);\r\n  });\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\scripts\\seed-test-organizations.ts","messages":[{"ruleId":null,"fatal":true,"severity":2,"message":"Parsing error: \"parserOptions.project\" has been provided for @typescript-eslint/parser.\nThe file was not found in any of the provided project(s): scripts\\seed-test-organizations.ts","nodeType":null}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":1,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Seed Complete Test Organizations\n * Creates fully-configured test organizations with:\n * - Auth users\n * - Complete onboarding data\n * - Configured AI agents (Base Model + Golden Master)\n * - Product/service catalogs\n * - Ready to login and test\n */\n\nimport { initializeApp } from 'firebase/app';\nimport { getAuth, createUserWithEmailAndPassword, signInWithEmailAndPassword, connectAuthEmulator } from 'firebase/auth';\nimport { getFirestore, doc, setDoc, collection, Timestamp, connectFirestoreEmulator } from 'firebase/firestore';\nimport { MOCK_TEST_ORGANIZATIONS } from '../src/lib/test-data/mock-organizations';\nimport type { CompleteTestOrganization } from '../src/lib/test-data/mock-organizations';\n\n// Firebase config for emulators\nconst firebaseConfig = {\n  apiKey: 'demo-key',\n  authDomain: 'demo-project.firebaseapp.com',\n  projectId: 'demo-ai-sales-platform',\n};\n\nconst app = initializeApp(firebaseConfig);\nconst auth = getAuth(app);\nconst db = getFirestore(app);\n\n// Connect to emulators (Firebase v9+ modular SDK)\ntry {\n  connectAuthEmulator(auth, 'http://localhost:9099');\n  connectFirestoreEmulator(db, 'localhost', 8080);\n} catch (error) {\n  // Emulators already connected or not available\n  console.log('Emulators not connected:', error);\n}\n\ninterface SeedResult {\n  orgId: string;\n  orgName: string;\n  email: string;\n  password: string;\n  success: boolean;\n  error?: string;\n}\n\nasync function createTestOrganization(testOrg: CompleteTestOrganization, index: number): Promise<SeedResult> {\n  const email = `test${index + 1}@example.com`;\n  const password = 'TestPass123!';\n  \n  try {\n    console.log(`\\n${'='.repeat(80)}`);\n    console.log(`Creating: ${testOrg.name}`);\n    console.log(`${'='.repeat(80)}`);\n    \n    // Step 1: Create Auth User\n    console.log('üìß Creating auth user...');\n    let userCredential;\n    try {\n      userCredential = await createUserWithEmailAndPassword(auth, email, password);\n    } catch (error: any) {\n      if (error.code === 'auth/email-already-in-use') {\n        console.log('   User already exists, signing in...');\n        userCredential = await signInWithEmailAndPassword(auth, email, password);\n      } else {\n        throw error;\n      }\n    }\n    const userId = userCredential.user.uid;\n    console.log(`   ‚úÖ User created: ${userId}`);\n    \n    // Step 2: Create Organization Document\n    console.log('üè¢ Creating organization...');\n    const orgRef = doc(db, 'organizations', testOrg.id);\n    await setDoc(orgRef, {\n      id: testOrg.id,\n      name: testOrg.name,\n      slug: testOrg.slug,\n      plan: testOrg.plan,\n      planLimits: testOrg.planLimits,\n      billingEmail: testOrg.billingEmail,\n      branding: testOrg.branding,\n      settings: testOrg.settings,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n      createdBy: userId,\n      status: testOrg.status,\n      trialEndsAt: testOrg.trialEndsAt ? Timestamp.fromDate(new Date(testOrg.trialEndsAt)) : null,\n      testOrg: true, // Mark as test\n      testIndustry: testOrg.testIndustry,\n    });\n    console.log(`   ‚úÖ Organization created: ${testOrg.id}`);\n    \n    // Step 3: Create User Profile\n    console.log('üë§ Creating user profile...');\n    const userRef = doc(db, 'users', userId);\n    await setDoc(userRef, {\n      id: userId,\n      email: email,\n      displayName: 'Test Admin',\n      organizationId: testOrg.id,\n      role: 'owner',\n      createdAt: Timestamp.now(),\n      lastLoginAt: Timestamp.now(),\n      isTestUser: true,\n    });\n    console.log(`   ‚úÖ User profile created`);\n    \n    // Step 4: Add Organization Member\n    console.log('üë• Adding to organization members...');\n    const memberRef = doc(db, 'organizations', testOrg.id, 'members', userId);\n    await setDoc(memberRef, {\n      userId: userId,\n      email: email,\n      role: 'owner',\n      permissions: ['*'], // All permissions\n      addedAt: Timestamp.now(),\n      addedBy: userId,\n      status: 'active',\n    });\n    console.log(`   ‚úÖ Member added`);\n    \n    // Step 5: Save Complete Onboarding Data\n    console.log('üìã Saving onboarding data...');\n    const onboardingRef = doc(db, 'organizations', testOrg.id, 'onboarding', 'current');\n    await setDoc(onboardingRef, {\n      ...testOrg.onboardingData,\n      organizationId: testOrg.id,\n      completedAt: Timestamp.now(),\n      completedBy: userId,\n    });\n    console.log(`   ‚úÖ Onboarding data saved`);\n    \n    // Step 6: Build Agent Persona\n    console.log('ü§ñ Building AI agent persona...');\n    const personaRef = doc(db, 'organizations', testOrg.id, 'agentPersona', 'current');\n    await setDoc(personaRef, {\n      name: testOrg.onboardingData.agentName || `${testOrg.name} AI`,\n      tone: testOrg.onboardingData.tone,\n      greeting: testOrg.onboardingData.greeting,\n      closingMessage: testOrg.onboardingData.closingMessage,\n      objectives: [\n        testOrg.onboardingData.primaryObjective,\n        ...testOrg.onboardingData.secondaryObjectives,\n      ],\n      escalationRules: testOrg.onboardingData.escalationRules.split('\\n'),\n      organizationId: testOrg.id,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n    });\n    console.log(`   ‚úÖ Persona created`);\n    \n    // Step 7: Build Knowledge Base\n    console.log('üìö Building knowledge base...');\n    const knowledgeRef = doc(db, 'organizations', testOrg.id, 'knowledgeBase', 'current');\n    await setDoc(knowledgeRef, {\n      documents: [], // Could upload docs here\n      urls: testOrg.onboardingData.urls.map(url => ({\n        url,\n        addedAt: Timestamp.now(),\n        status: 'pending',\n      })),\n      faqs: testOrg.onboardingData.faqs.split('\\n').filter(q => q.includes('Q:')).map((qa, idx) => ({\n        id: `faq-${idx}`,\n        question: qa.split('A:')[0].replace('Q:', '').trim(),\n        answer: qa.split('A:')[1]?.trim() || '',\n        category: 'General',\n      })),\n      organizationId: testOrg.id,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n    });\n    console.log(`   ‚úÖ Knowledge base created`);\n    \n    // Step 8: Create Base Model (pre-training state)\n    console.log('üß™ Creating Base Model...');\n    const baseModelId = `base_${Date.now()}`;\n    const baseModelRef = doc(db, 'organizations', testOrg.id, 'baseModels', baseModelId);\n    await setDoc(baseModelRef, {\n      id: baseModelId,\n      organizationId: testOrg.id,\n      createdBy: userId,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n      status: 'ready_for_golden_master', // Skip training for test data\n      businessContext: {\n        businessName: testOrg.onboardingData.businessName,\n        industry: testOrg.onboardingData.industry,\n        problemSolved: testOrg.onboardingData.problemSolved,\n        uniqueValue: testOrg.onboardingData.uniqueValue,\n        topProducts: testOrg.onboardingData.topProducts,\n        pricingStrategy: testOrg.onboardingData.pricingStrategy,\n        discountPolicy: testOrg.onboardingData.discountPolicy,\n        returnPolicy: testOrg.onboardingData.returnPolicy,\n        warrantyTerms: testOrg.onboardingData.warrantyTerms,\n        geographicCoverage: testOrg.onboardingData.geographicCoverage,\n        deliveryTimeframes: testOrg.onboardingData.deliveryTimeframes,\n        typicalSalesFlow: testOrg.onboardingData.typicalSalesFlow,\n        discoveryQuestions: testOrg.onboardingData.discoveryQuestions,\n        commonObjections: testOrg.onboardingData.commonObjections,\n        priceObjections: testOrg.onboardingData.priceObjections,\n        timeObjections: testOrg.onboardingData.timeObjections,\n        competitorObjections: testOrg.onboardingData.competitorObjections,\n      },\n      agentPersona: {\n        name: testOrg.onboardingData.agentName || `${testOrg.name} AI`,\n        tone: testOrg.onboardingData.tone,\n        greeting: testOrg.onboardingData.greeting,\n        closingMessage: testOrg.onboardingData.closingMessage,\n        objectives: [\n          testOrg.onboardingData.primaryObjective,\n          ...testOrg.onboardingData.secondaryObjectives,\n        ],\n        escalationRules: testOrg.onboardingData.escalationRules.split('\\n'),\n      },\n      behaviorConfig: {\n        closingAggressiveness: testOrg.onboardingData.closingAggressiveness,\n        questionFrequency: testOrg.onboardingData.questionFrequency,\n        responseLength: testOrg.onboardingData.responseLength,\n        proactiveLevel: testOrg.onboardingData.proactiveLevel,\n      },\n    });\n    console.log(`   ‚úÖ Base Model created: ${baseModelId}`);\n    \n    // Step 9: Create Golden Master (deployed agent)\n    console.log('‚≠ê Creating Golden Master (deployed agent)...');\n    const goldenMasterId = `gm_${Date.now()}`;\n    const goldenMasterRef = doc(db, 'organizations', testOrg.id, 'goldenMasters', goldenMasterId);\n    await setDoc(goldenMasterRef, {\n      id: goldenMasterId,\n      version: '1.0.0',\n      organizationId: testOrg.id,\n      createdBy: userId,\n      createdAt: Timestamp.now(),\n      deployedAt: Timestamp.now(),\n      isActive: true,\n      status: 'deployed',\n      baseModelId: baseModelId,\n      businessContext: {\n        businessName: testOrg.onboardingData.businessName,\n        industry: testOrg.onboardingData.industry,\n        problemSolved: testOrg.onboardingData.problemSolved,\n        uniqueValue: testOrg.onboardingData.uniqueValue,\n        topProducts: testOrg.onboardingData.topProducts,\n        pricingStrategy: testOrg.onboardingData.pricingStrategy,\n        discountPolicy: testOrg.onboardingData.discountPolicy,\n        returnPolicy: testOrg.onboardingData.returnPolicy,\n        warrantyTerms: testOrg.onboardingData.warrantyTerms,\n        geographicCoverage: testOrg.onboardingData.geographicCoverage,\n        deliveryTimeframes: testOrg.onboardingData.deliveryTimeframes,\n        typicalSalesFlow: testOrg.onboardingData.typicalSalesFlow,\n        discoveryQuestions: testOrg.onboardingData.discoveryQuestions,\n        commonObjections: testOrg.onboardingData.commonObjections,\n        priceObjections: testOrg.onboardingData.priceObjections,\n        timeObjections: testOrg.onboardingData.timeObjections,\n        competitorObjections: testOrg.onboardingData.competitorObjections,\n      },\n      agentPersona: {\n        name: testOrg.onboardingData.agentName || `${testOrg.name} AI`,\n        tone: testOrg.onboardingData.tone,\n        greeting: testOrg.onboardingData.greeting,\n        closingMessage: testOrg.onboardingData.closingMessage,\n        objectives: [\n          testOrg.onboardingData.primaryObjective,\n          ...testOrg.onboardingData.secondaryObjectives,\n        ],\n        escalationRules: testOrg.onboardingData.escalationRules.split('\\n'),\n      },\n      behaviorConfig: {\n        closingAggressiveness: testOrg.onboardingData.closingAggressiveness,\n        questionFrequency: testOrg.onboardingData.questionFrequency,\n        responseLength: testOrg.onboardingData.responseLength,\n        proactiveLevel: testOrg.onboardingData.proactiveLevel,\n      },\n      knowledgeBase: {\n        documents: [],\n        urls: testOrg.onboardingData.urls.map(url => ({\n          url,\n          addedAt: Timestamp.now(),\n          status: 'pending',\n        })),\n        faqs: testOrg.onboardingData.faqs.split('\\n').filter(q => q.includes('Q:')).map((qa, idx) => ({\n          id: `faq-${idx}`,\n          question: qa.split('A:')[0].replace('Q:', '').trim(),\n          answer: qa.split('A:')[1]?.trim() || '',\n          category: 'General',\n        })),\n      },\n      systemPrompt: buildSystemPrompt(testOrg),\n      trainedScenarios: [],\n      trainingCompletedAt: Timestamp.now(),\n    });\n    console.log(`   ‚úÖ Golden Master deployed: ${goldenMasterId}`);\n    \n    // Step 10: Create Product/Service Schema\n    console.log('üì¶ Creating product schema...');\n    const schemaId = 'products';\n    const schemaRef = doc(db, 'organizations', testOrg.id, 'schemas', schemaId);\n    await setDoc(schemaRef, {\n      id: schemaId,\n      name: 'Product',\n      pluralName: 'Products',\n      singularName: 'Product',\n      icon: 'üì¶',\n      organizationId: testOrg.id,\n      createdBy: userId,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n      fields: [\n        { id: 'f1', key: 'name', label: 'Product Name', type: 'text', required: true },\n        { id: 'f2', key: 'sku', label: 'SKU', type: 'text', required: true },\n        { id: 'f3', key: 'description', label: 'Description', type: 'longText', required: false },\n        { id: 'f4', key: 'price', label: 'Price', type: 'currency', required: true },\n        { id: 'f5', key: 'cost', label: 'Cost', type: 'currency', required: false },\n        { id: 'f6', key: 'category', label: 'Category', type: 'text', required: false },\n        { id: 'f7', key: 'active', label: 'Active', type: 'checkbox', required: true },\n        { id: 'f8', key: 'stock_quantity', label: 'Stock Quantity', type: 'number', required: false },\n        { id: 'f9', key: 'unit', label: 'Unit', type: 'text', required: false },\n      ],\n    });\n    console.log(`   ‚úÖ Product schema created`);\n    \n    // Step 11: Seed Products\n    console.log(`üì¶ Seeding ${testOrg.products.length} products...`);\n    for (const product of testOrg.products) {\n      const productId = `prod_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n      const productRef = doc(db, 'organizations', testOrg.id, 'entities_products', productId);\n      await setDoc(productRef, {\n        id: productId,\n        ...product,\n        organizationId: testOrg.id,\n        createdBy: userId,\n        createdAt: Timestamp.now(),\n        updatedAt: Timestamp.now(),\n      });\n    }\n    console.log(`   ‚úÖ ${testOrg.products.length} products seeded`);\n    \n    // Step 12: Create default workspace\n    console.log('üèóÔ∏è Creating default workspace...');\n    const workspaceId = `ws_${testOrg.id}`;\n    const workspaceRef = doc(db, 'organizations', testOrg.id, 'workspaces', workspaceId);\n    await setDoc(workspaceRef, {\n      id: workspaceId,\n      organizationId: testOrg.id,\n      name: `${testOrg.name} Workspace`,\n      slug: testOrg.slug,\n      industry: testOrg.testIndustry,\n      createdBy: userId,\n      createdAt: Timestamp.now(),\n      updatedAt: Timestamp.now(),\n      status: 'active',\n      settings: {\n        allowGuestAccess: false,\n        enableAI: true,\n        enableWorkflows: true,\n        dataRetentionDays: 365,\n      },\n    });\n    console.log(`   ‚úÖ Workspace created: ${workspaceId}`);\n    \n    console.log(`\\n‚ú® SUCCESS: ${testOrg.name}`);\n    console.log(`   üìß Login: ${email}`);\n    console.log(`   üîë Password: ${password}`);\n    console.log(`   üè¢ Org ID: ${testOrg.id}`);\n    console.log(`   üë§ User ID: ${userId}`);\n    console.log(`   üì¶ Products: ${testOrg.products.length}`);\n    console.log(`   ü§ñ AI Agent: DEPLOYED (${goldenMasterId})`);\n    \n    return {\n      orgId: testOrg.id,\n      orgName: testOrg.name,\n      email,\n      password,\n      success: true,\n    };\n    \n  } catch (error: any) {\n    console.error(`\\n‚ùå ERROR creating ${testOrg.name}:`, error.message);\n    return {\n      orgId: testOrg.id,\n      orgName: testOrg.name,\n      email,\n      password,\n      success: false,\n      error: error.message,\n    };\n  }\n}\n\nfunction buildSystemPrompt(testOrg: CompleteTestOrganization): string {\n  const d = testOrg.onboardingData;\n  return `You are an AI sales and customer service agent for ${d.businessName}.\n\n# Your Role & Objectives\n- Primary: ${d.primaryObjective}\n- Secondary: ${d.secondaryObjectives.join(', ')}\n\n# Business Context\nIndustry: ${d.industry}\nWhat we do: ${d.problemSolved}\nWhat makes us unique: ${d.uniqueValue}\n\n# Products/Services\n${d.topProducts}\n\n# Pricing Strategy\n${d.pricingStrategy}\n${d.discountPolicy}\n\n# Policies\nReturn Policy: ${d.returnPolicy}\nWarranty: ${d.warrantyTerms}\nShipping: ${d.geographicCoverage}\nDelivery Time: ${d.deliveryTimeframes}\n\n# Your Sales Process\n${d.typicalSalesFlow}\n\nDiscovery Questions to Ask:\n${d.discoveryQuestions}\n\n# Objection Handling\n${d.commonObjections}\n\nPrice Objections: ${d.priceObjections}\nTime Objections: ${d.timeObjections}\nCompetitor Objections: ${d.competitorObjections}\n\n# Your Personality\nName: ${d.agentName || `${d.businessName} AI`}\nTone: ${d.tone}\nGreeting: \"${d.greeting}\"\nClosing: \"${d.closingMessage}\"\n\n# Behavioral Guidelines\n- Closing Aggressiveness: ${d.closingAggressiveness}/10\n- Ask ${d.questionFrequency} discovery questions before recommending\n- Response Length: ${d.responseLength}\n- Proactive Level: ${d.proactiveLevel}/10\n\n# Compliance\n${d.requiredDisclosures}\nProhibited Topics: ${d.prohibitedTopics}\n\nRemember: ${d.escalationRules}`;\n}\n\nasync function seedAllTestOrganizations() {\n  console.log('\\nüöÄ SEEDING COMPLETE TEST ORGANIZATIONS');\n  console.log('='.repeat(80));\n  console.log(`Creating ${MOCK_TEST_ORGANIZATIONS.length} fully configured test organizations...`);\n  console.log('Each includes:');\n  console.log('  ‚úÖ Auth user & organization');\n  console.log('  ‚úÖ Complete 16-step onboarding data');\n  console.log('  ‚úÖ AI agent persona & knowledge base');\n  console.log('  ‚úÖ Base Model + Deployed Golden Master');\n  console.log('  ‚úÖ Product/service catalogs');\n  console.log('  ‚úÖ Default workspace\\n');\n  \n  const results: SeedResult[] = [];\n  \n  for (let i = 0; i < MOCK_TEST_ORGANIZATIONS.length; i++) {\n    const testOrg = MOCK_TEST_ORGANIZATIONS[i];\n    const result = await createTestOrganization(testOrg, i);\n    results.push(result);\n    \n    // Small delay between creations\n    await new Promise(resolve => setTimeout(resolve, 500));\n  }\n  \n  // Summary\n  console.log('\\n\\n');\n  console.log('='.repeat(80));\n  console.log('üìä SEEDING SUMMARY');\n  console.log('='.repeat(80));\n  \n  const successful = results.filter(r => r.success);\n  const failed = results.filter(r => !r.success);\n  \n  console.log(`‚úÖ Successful: ${successful.length}/${results.length}`);\n  console.log(`‚ùå Failed: ${failed.length}/${results.length}`);\n  \n  if (successful.length > 0) {\n    console.log('\\n‚úÖ TEST ACCOUNTS READY TO LOGIN:\\n');\n    successful.forEach((r, idx) => {\n      console.log(`${idx + 1}. ${r.orgName}`);\n      console.log(`   üìß Email: ${r.email}`);\n      console.log(`   üîë Password: ${r.password}`);\n      console.log(`   üè¢ Org ID: ${r.orgId}`);\n      console.log('');\n    });\n  }\n  \n  if (failed.length > 0) {\n    console.log('\\n‚ùå FAILED:\\n');\n    failed.forEach(r => {\n      console.log(`   ${r.orgName}: ${r.error}`);\n    });\n  }\n  \n  console.log('\\nüéØ WHAT YOU CAN TEST NOW:');\n  console.log('   ‚úÖ Login with any test account');\n  console.log('   ‚úÖ AI agent is FULLY CONFIGURED and knows the business');\n  console.log('   ‚úÖ Products are loaded in the catalog');\n  console.log('   ‚úÖ Agent personality matches industry');\n  console.log('   ‚úÖ Test across multiple industries');\n  console.log('   ‚úÖ No onboarding needed - everything is ready!');\n  \n  console.log('\\nüß™ NEXT STEPS:');\n  console.log('   1. Go to http://localhost:3000');\n  console.log('   2. Login with test1@example.com / TestPass123!');\n  console.log('   3. Chat with the AI agent - it knows the business!');\n  console.log('   4. View products in the catalog');\n  console.log('   5. Test other industries with test2@, test3@, etc.\\n');\n}\n\n// Run the seeding\nseedAllTestOrganizations()\n  .then(() => {\n    console.log('‚úÖ SEEDING COMPLETE!\\n');\n    process.exit(0);\n  })\n  .catch((error) => {\n    console.error('‚ùå SEEDING FAILED:', error);\n    process.exit(1);\n  });\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\scripts\\setup-jasper-golden-master.js","messages":[{"ruleId":"no-dupe-keys","severity":2,"message":"Duplicate key 'industry'.","line":113,"column":7,"nodeType":"ObjectExpression","messageId":"unexpected","endLine":113,"endColumn":15}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Setup Jasper - Platform Golden Master\r\n * This creates the AI sales agent for the platform's landing page\r\n */\r\n\r\nconst admin = require('firebase-admin');\r\nconst serviceAccount = require('../serviceAccountKey.json');\r\n\r\nif (!admin.apps.length) {\r\n  admin.initializeApp({\r\n    credential: admin.credential.cert(serviceAccount),\r\n  });\r\n}\r\n\r\nconst db = admin.firestore();\r\n\r\nasync function setupJasperGoldenMaster() {\r\n  console.log('ü§ñ Setting up Jasper - Platform AI Sales Agent...\\n');\r\n\r\n  const orgId = 'platform';\r\n  const goldenMasterId = 'jasper-v1';\r\n\r\n  // Jasper's personality and knowledge\r\n  const goldenMaster = {\r\n    id: goldenMasterId,\r\n    version: '1.0.0',\r\n    name: 'Jasper',\r\n    organizationId: orgId,\r\n    \r\n    // Core AI Configuration\r\n    model: 'openrouter/anthropic/claude-3.5-sonnet',\r\n    systemPrompt: `You are Jasper, the AI sales agent for the AI Sales Platform.\r\n\r\n**Your Role:**\r\n- Help visitors understand our AI sales agent platform\r\n- Answer questions about features, pricing, and capabilities\r\n- Qualify leads and guide them to sign up for a free trial\r\n- Be consultative, confident, and helpful\r\n\r\n**Product Overview:**\r\nThe AI Sales Platform helps businesses automate their sales process with AI agents that:\r\n- Qualify leads automatically 24/7\r\n- Answer customer questions intelligently\r\n- Schedule meetings and demos\r\n- Close deals and process orders\r\n- Integrate with existing tools (Stripe, calendars, Slack, etc.)\r\n\r\n**Pricing:**\r\n- Free Trial: 14 days, full access, no credit card required\r\n- Starter: $99/mo - Up to 1,000 conversations/month\r\n- Professional: $299/mo - Up to 5,000 conversations/month  \r\n- Enterprise: Custom pricing - Unlimited conversations, white-label, dedicated support\r\n\r\n**Key Features:**\r\n1. AI Agents: Deploy intelligent sales agents trained on your business\r\n2. Lead Qualification: Automatically score and route qualified leads\r\n3. Integrations: Stripe, Google/Microsoft calendars, Slack, Shopify, WordPress\r\n4. Analytics: Real-time dashboards showing conversions, revenue, pipeline\r\n5. Workflows: Automate follow-ups, nurture sequences, and handoffs\r\n6. White-Label: Custom branding for agencies and resellers\r\n\r\n**Use Cases:**\r\n- SaaS companies: Qualify trial signups, reduce churn\r\n- E-commerce: Product recommendations, cart recovery\r\n- Agencies: Scale client support without hiring\r\n- B2B: Qualify enterprise leads, schedule demos\r\n\r\n**Technical Capabilities:**\r\n- Multi-model AI (GPT-4, Claude, Gemini)\r\n- Real-time learning from conversations\r\n- API access for custom integrations\r\n- SOC 2 compliant, GDPR ready\r\n- 99.9% uptime SLA\r\n\r\n**Tone:**\r\n- Professional but approachable\r\n- Data-driven (use specific numbers when possible)\r\n- Solution-focused (understand their needs, then recommend)\r\n- Never pushy - focus on value, not sales pressure\r\n\r\n**Response Guidelines:**\r\n- Keep answers concise (2-3 sentences ideal)\r\n- Ask clarifying questions to understand their use case\r\n- Offer to schedule a demo for complex questions\r\n- If they're interested, guide them to start a free trial\r\n- Always end with a clear next step or call-to-action`,\r\n\r\n    temperature: 0.7,\r\n    maxTokens: 400,\r\n    topP: 0.9,\r\n    \r\n    // Knowledge Base\r\n    knowledgeBase: {\r\n      documents: [],\r\n      lastUpdated: new Date(),\r\n      embeddingsEnabled: false,\r\n    },\r\n    \r\n    // Business Knowledge\r\n    businessContext: {\r\n      companyName: 'AI Sales Platform',\r\n      industry: 'SaaS / AI Sales Automation',\r\n      targetAudience: 'Founders, revenue leaders, sales teams',\r\n      valueProposition: 'AI agents that qualify leads, answer questions, and close deals automatically',\r\n      keyDifferentiators: [\r\n        'One platform for the entire sales process',\r\n        'Multi-model AI for best-in-class responses',\r\n        'Real-time learning and improvement',\r\n        'Usage-based pricing (no seat licenses)',\r\n        'Built for developers with full API access',\r\n      ],\r\n      businessName: 'AI Sales Platform',\r\n      industry: 'SaaS / AI Sales Automation',\r\n      problemSolved: 'Automate sales conversations, lead qualification, and closing deals with AI',\r\n      uniqueValue: 'Multi-model AI with real-time learning and full API access',\r\n      topProducts: 'AI Sales Agents, Lead Qualification, Automated Follow-ups, Analytics Dashboard',\r\n      pricingStrategy: 'Usage-based pricing starting at $99/mo for 1,000 conversations',\r\n      discountPolicy: 'Annual plans get 20% discount. Enterprise plans are custom',\r\n      returnPolicy: '30-day money-back guarantee, no questions asked',\r\n      warrantyTerms: 'N/A - SaaS product',\r\n      geographicCoverage: 'Global - available worldwide',\r\n      deliveryTimeframes: 'Instant access upon signup',\r\n      typicalSalesFlow: 'Qualify need ‚Üí Show demo ‚Üí Start free trial ‚Üí Convert to paid',\r\n      discoveryQuestions: 'What is your current sales process? How many leads do you get monthly? What is your biggest sales challenge?',\r\n      commonObjections: 'Cost, AI accuracy concerns, implementation complexity',\r\n      priceObjections: 'Show ROI calculator, offer free trial to prove value',\r\n      timeObjections: 'Setup takes 5 minutes, AI is ready immediately',\r\n      competitorObjections: 'Multi-model AI, built for developers, usage-based pricing',\r\n      requiredDisclosures: 'N/A',\r\n      prohibitedTopics: 'Medical advice, legal advice, financial advice',\r\n    },\r\n    \r\n    // Agent Persona\r\n    agentPersona: {\r\n      name: 'Jasper',\r\n      tone: 'Professional, consultative, confident',\r\n      greeting: 'Hi! I\\'m Jasper, your AI sales assistant. How can I help you today?',\r\n      closingMessage: 'Thanks for chatting! Feel free to reach out anytime.',\r\n      objectives: [\r\n        'Qualify leads based on budget, need, timeline, and decision-making authority',\r\n        'Answer product questions clearly and concisely',\r\n        'Guide interested prospects to start a free trial',\r\n        'Schedule demos for enterprise prospects',\r\n      ],\r\n      escalationRules: [\r\n        'Enterprise custom pricing requests',\r\n        'Technical integration questions beyond API docs',\r\n        'Complaints or urgent issues',\r\n        'Requests for contracts or legal terms',\r\n      ],\r\n    },\r\n    \r\n    // Behavior Config\r\n    behaviorConfig: {\r\n      closingAggressiveness: 5,\r\n      questionFrequency: 2,\r\n      responseLength: 'concise',\r\n      proactiveLevel: 7,\r\n    },\r\n    \r\n    // Conversation Configuration\r\n    conversationConfig: {\r\n      enableMemory: true,\r\n      enableLearning: true,\r\n      confidenceThreshold: 0.7,\r\n      maxTurns: 20,\r\n      handoffEnabled: true,\r\n      handoffTriggers: [\r\n        'schedule a demo',\r\n        'talk to sales',\r\n        'enterprise pricing',\r\n        'custom contract',\r\n      ],\r\n    },\r\n    \r\n    // Training Status\r\n    trainingStatus: {\r\n      status: 'deployed',\r\n      accuracy: 0.95,\r\n      totalSessions: 0,\r\n      lastTrainedAt: new Date(),\r\n    },\r\n    \r\n    // Metadata\r\n    deployedAt: new Date(),\r\n    deployedBy: 'system',\r\n    isActive: true,\r\n    tags: ['sales', 'platform', 'landing-page'],\r\n    createdAt: new Date(),\r\n    updatedAt: new Date(),\r\n  };\r\n\r\n  try {\r\n    // Create Golden Master\r\n    await db\r\n      .collection('organizations')\r\n      .doc(orgId)\r\n      .collection('goldenMasters')\r\n      .doc(goldenMasterId)\r\n      .set(goldenMaster);\r\n    \r\n    console.log('‚úÖ Jasper Golden Master created successfully!');\r\n    console.log(`   ID: ${goldenMasterId}`);\r\n    console.log(`   Version: ${goldenMaster.version}`);\r\n    console.log(`   Model: ${goldenMaster.model}\\n`);\r\n\r\n    // Set as active Golden Master\r\n    await db\r\n      .collection('organizations')\r\n      .doc(orgId)\r\n      .update({\r\n        activeGoldenMasterId: goldenMasterId,\r\n        updatedAt: new Date(),\r\n      });\r\n    \r\n    console.log('‚úÖ Set as active Golden Master for platform organization\\n');\r\n\r\n    // Create agent config (for backwards compatibility)\r\n    const agentConfig = {\r\n      selectedModel: goldenMaster.model,\r\n      modelConfig: {\r\n        temperature: goldenMaster.temperature,\r\n        maxTokens: goldenMaster.maxTokens,\r\n        topP: goldenMaster.topP,\r\n      },\r\n      systemPrompt: goldenMaster.systemPrompt,\r\n      enableMemory: true,\r\n      enableLearning: true,\r\n      updatedAt: new Date(),\r\n    };\r\n\r\n    await db\r\n      .collection('organizations')\r\n      .doc(orgId)\r\n      .collection('agentConfig')\r\n      .doc('default')\r\n      .set(agentConfig);\r\n\r\n    console.log('‚úÖ Agent config created\\n');\r\n\r\n    // Enable chat widget\r\n    const chatWidgetConfig = {\r\n      enabled: true,\r\n      theme: {\r\n        primaryColor: '#6366f1',\r\n        headerText: 'Chat with Jasper',\r\n        welcomeMessage: 'Hi! I\\'m Jasper, your AI sales assistant. How can I help you today?',\r\n        placeholderText: 'Ask about features, pricing, or getting started...',\r\n      },\r\n      position: 'bottom-right',\r\n      showOnPages: ['/', '/pricing', '/about'],\r\n      updatedAt: new Date(),\r\n    };\r\n\r\n    await db\r\n      .collection('organizations')\r\n      .doc(orgId)\r\n      .collection('settings')\r\n      .doc('chatWidget')\r\n      .set(chatWidgetConfig);\r\n\r\n    console.log('‚úÖ Chat widget enabled\\n');\r\n\r\n    console.log('üéâ Jasper is ready! Test on your landing page at http://localhost:3000');\r\n    \r\n  } catch (error) {\r\n    console.error('‚ùå Error setting up Jasper:', error);\r\n    throw error;\r\n  }\r\n}\r\n\r\nsetupJasperGoldenMaster()\r\n  .then(() => {\r\n    console.log('\\n‚úÖ Setup complete!');\r\n    process.exit(0);\r\n  })\r\n  .catch((error) => {\r\n    console.error('\\n‚ùå Setup failed:', error);\r\n    process.exit(1);\r\n  });\r\n\r\n\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\scripts\\verify-database.js","messages":[{"ruleId":"no-empty","severity":2,"message":"Empty block statement.","line":13,"column":17,"nodeType":"BlockStatement","messageId":"unexpected","endLine":13,"endColumn":19,"suggestions":[{"messageId":"suggestComment","data":{"type":"block"},"fix":{"range":[284,284],"text":" /* empty */ "},"desc":"Add comment inside empty block statement."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Verify which database we're actually connecting to\r\n */\r\n\r\nconst admin = require('firebase-admin');\r\nconst path = require('path');\r\n\r\nasync function verify() {\r\n  // Clear any existing instances\r\n  admin.apps.forEach(app => {\r\n    try {\r\n      app.delete();\r\n    } catch (e) {}\r\n  });\r\n  \r\n  console.log('\\nüîç DATABASE CONNECTION VERIFICATION\\n');\r\n  console.log('Environment variables:');\r\n  console.log(`  FIRESTORE_EMULATOR_HOST: ${process.env.FIRESTORE_EMULATOR_HOST || 'NOT SET'}`);\r\n  console.log(`  FIREBASE_AUTH_EMULATOR_HOST: ${process.env.FIREBASE_AUTH_EMULATOR_HOST || 'NOT SET'}\\n`);\r\n  \r\n  const serviceAccount = require(path.join(__dirname, '../serviceAccountKey.json'));\r\n  \r\n  console.log('Service account info:');\r\n  console.log(`  Project ID: ${serviceAccount.project_id}`);\r\n  console.log(`  Client Email: ${serviceAccount.client_email}\\n`);\r\n  \r\n  const app = admin.initializeApp({\r\n    credential: admin.credential.cert(serviceAccount)\r\n  });\r\n  \r\n  const adminDb = admin.firestore();\r\n  \r\n  console.log('Firestore instance info:');\r\n  console.log(`  Project ID: ${adminDb.projectId || 'unknown'}\\n`);\r\n  \r\n  // Count documents\r\n  const orgsSnapshot = await adminDb.collection('organizations').get();\r\n  \r\n  console.log(`üìä Total organizations: ${orgsSnapshot.size}\\n`);\r\n  console.log('Organizations found:');\r\n  \r\n  orgsSnapshot.forEach((doc, index) => {\r\n    const data = doc.data();\r\n    console.log(`  ${index + 1}. ${doc.id} - \"${data.name || 'UNNAMED'}\"`);\r\n  });\r\n  \r\n  process.exit(0);\r\n}\r\n\r\nverify().catch(console.error);\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\PageRenderer.tsx","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":27,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":27,"endColumn":82}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"'use client';\n\nimport React from 'react';\nimport Link from 'next/link';\nimport type { PageContent } from '@/hooks/usePageContent';\nimport { useWebsiteTheme } from '@/hooks/useWebsiteTheme';\n\ninterface WidgetElement {\n  id: string;\n  type: string;\n  content?: any;\n  children?: WidgetElement[];\n  styles?: {\n    desktop?: Record<string, string>;\n    tablet?: Record<string, string>;\n    mobile?: Record<string, string>;\n  };\n  settings?: Record<string, any>;\n}\n\nfunction ElementRenderer({ element }: { element: WidgetElement }) {\n  const { theme } = useWebsiteTheme();\n  const styles = element.styles?.desktop || {};\n\n  switch (element.type) {\n    case 'heading':\n      const Tag = (element.settings?.tag || 'h2') as keyof JSX.IntrinsicElements;\n      return <Tag style={styles}>{element.content}</Tag>;\n\n    case 'text':\n      return <p style={styles}>{element.content}</p>;\n\n    case 'button':\n      return (\n        <Link\n          href={element.settings?.href || '#'}\n          style={{\n            display: 'inline-block',\n            textDecoration: 'none',\n            ...styles,\n          }}\n        >\n          {element.content}\n        </Link>\n      );\n\n    case 'image':\n      return (\n        <img\n          src={typeof element.content === 'string' ? element.content : '/placeholder.jpg'}\n          alt={element.settings?.alt || ''}\n          style={{ maxWidth: '100%', ...styles }}\n        />\n      );\n\n    case 'icon':\n      return <span style={{ fontSize: '3rem', ...styles }}>{element.content}</span>;\n\n    case 'spacer':\n      return <div style={{ height: styles.height || '40px' }} />;\n\n    case 'divider':\n      return <hr style={{ border: 'none', borderTop: '1px solid rgba(255,255,255,0.1)', margin: '2rem 0', ...styles }} />;\n\n    case 'stats':\n      if (element.content?.items) {\n        return (\n          <div style={{ display: 'flex', justifyContent: 'center', gap: '4rem', flexWrap: 'wrap', ...styles }}>\n            {element.content.items.map((item: { value: string; label: string }, idx: number) => (\n              <div key={idx} style={{ textAlign: 'center' }}>\n                <div style={{ fontSize: '3rem', fontWeight: 'bold', color: theme.primaryColor }}>{item.value}</div>\n                <div style={{ fontSize: '1rem', color: 'rgba(255,255,255,0.7)' }}>{item.label}</div>\n              </div>\n            ))}\n          </div>\n        );\n      }\n      return null;\n\n    case 'feature-grid':\n      if (element.content?.items) {\n        return (\n          <div style={{ \n            display: 'grid', \n            gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', \n            gap: '24px',\n            ...styles \n          }}>\n            {element.content.items.map((item: { icon: string; title: string; desc: string }, idx: number) => (\n              <div \n                key={idx} \n                style={{ \n                  padding: '24px', \n                  backgroundColor: 'rgba(255,255,255,0.05)', \n                  borderRadius: '12px',\n                  border: '1px solid rgba(255,255,255,0.1)',\n                }}\n              >\n                <div style={{ fontSize: '2.5rem', marginBottom: '12px' }}>{item.icon}</div>\n                <h3 style={{ fontSize: '1.25rem', fontWeight: 'bold', color: '#fff', marginBottom: '8px' }}>{item.title}</h3>\n                <p style={{ fontSize: '0.9rem', color: 'rgba(255,255,255,0.7)', lineHeight: '1.6' }}>{item.desc}</p>\n              </div>\n            ))}\n          </div>\n        );\n      }\n      return null;\n\n    case 'faq':\n      if (element.content?.items) {\n        return (\n          <div style={{ display: 'flex', flexDirection: 'column', gap: '16px', ...styles }}>\n            {element.content.items.map((item: { q: string; a: string }, idx: number) => (\n              <div \n                key={idx} \n                style={{ \n                  padding: '24px', \n                  backgroundColor: 'rgba(255,255,255,0.05)', \n                  borderRadius: '12px',\n                  border: '1px solid rgba(255,255,255,0.1)',\n                }}\n              >\n                <h3 style={{ fontSize: '1.125rem', fontWeight: 'bold', color: '#fff', marginBottom: '12px' }}>{item.q}</h3>\n                <p style={{ fontSize: '1rem', color: 'rgba(255,255,255,0.7)', lineHeight: '1.6' }}>{item.a}</p>\n              </div>\n            ))}\n          </div>\n        );\n      }\n      return null;\n\n    case 'pricing-table':\n      if (element.content?.plans) {\n        return (\n          <div style={{ \n            display: 'grid', \n            gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', \n            gap: '24px',\n            ...styles \n          }}>\n            {element.content.plans.map((plan: { name: string; price: string; period: string; features: string[]; highlighted?: boolean }, idx: number) => (\n              <div \n                key={idx} \n                style={{ \n                  padding: '32px', \n                  backgroundColor: plan.highlighted ? theme.primaryColor : 'rgba(255,255,255,0.05)', \n                  borderRadius: '16px',\n                  border: plan.highlighted ? 'none' : '1px solid rgba(255,255,255,0.1)',\n                  position: 'relative',\n                  transform: plan.highlighted ? 'scale(1.05)' : 'none',\n                }}\n              >\n                {plan.highlighted && (\n                  <div style={{\n                    position: 'absolute',\n                    top: '-12px',\n                    left: '50%',\n                    transform: 'translateX(-50%)',\n                    padding: '4px 16px',\n                    backgroundColor: '#fbbf24',\n                    color: '#000',\n                    fontSize: '0.75rem',\n                    fontWeight: 'bold',\n                    borderRadius: '9999px',\n                  }}>\n                    MOST POPULAR\n                  </div>\n                )}\n                <h3 style={{ fontSize: '1.5rem', fontWeight: 'bold', color: '#fff', marginBottom: '8px' }}>{plan.name}</h3>\n                <div style={{ marginBottom: '24px' }}>\n                  <span style={{ fontSize: '3rem', fontWeight: 'bold', color: '#fff' }}>{plan.price}</span>\n                  <span style={{ color: 'rgba(255,255,255,0.7)' }}>{plan.period}</span>\n                </div>\n                <Link\n                  href=\"/signup\"\n                  style={{\n                    display: 'block',\n                    width: '100%',\n                    padding: '12px',\n                    textAlign: 'center',\n                    backgroundColor: plan.highlighted ? '#fff' : theme.primaryColor,\n                    color: plan.highlighted ? theme.primaryColor : '#fff',\n                    borderRadius: '8px',\n                    fontWeight: '600',\n                    textDecoration: 'none',\n                    marginBottom: '24px',\n                  }}\n                >\n                  Get Started\n                </Link>\n                <ul style={{ listStyle: 'none', padding: 0, margin: 0 }}>\n                  {plan.features.map((feature, fIdx) => (\n                    <li key={fIdx} style={{ display: 'flex', alignItems: 'flex-start', gap: '8px', marginBottom: '12px', color: 'rgba(255,255,255,0.9)' }}>\n                      <span style={{ color: plan.highlighted ? '#fff' : theme.primaryColor }}>‚úì</span>\n                      {feature}\n                    </li>\n                  ))}\n                </ul>\n              </div>\n            ))}\n          </div>\n        );\n      }\n      return null;\n\n    case 'testimonial':\n      if (typeof element.content === 'object') {\n        return (\n          <div style={{ \n            padding: '32px', \n            backgroundColor: 'rgba(255,255,255,0.05)', \n            borderRadius: '16px',\n            border: '1px solid rgba(255,255,255,0.1)',\n            ...styles \n          }}>\n            <p style={{ fontSize: '1.25rem', fontStyle: 'italic', color: '#fff', marginBottom: '16px', lineHeight: '1.6' }}>\n              \"{element.content.quote}\"\n            </p>\n            <div>\n              <div style={{ fontWeight: 'bold', color: '#fff' }}>{element.content.author}</div>\n              <div style={{ fontSize: '0.875rem', color: 'rgba(255,255,255,0.7)' }}>\n                {element.content.role}{element.content.company ? `, ${element.content.company}` : ''}\n              </div>\n            </div>\n          </div>\n        );\n      }\n      return null;\n\n    case 'icon-box':\n      if (typeof element.content === 'object') {\n        return (\n          <div style={{ \n            padding: '24px', \n            backgroundColor: 'rgba(255,255,255,0.05)', \n            borderRadius: '12px',\n            border: '1px solid rgba(255,255,255,0.1)',\n            ...styles \n          }}>\n            <div style={{ fontSize: '2.5rem', marginBottom: '12px' }}>{element.content.icon}</div>\n            <h3 style={{ fontSize: '1.25rem', fontWeight: 'bold', color: '#fff', marginBottom: '8px' }}>{element.content.title}</h3>\n            <p style={{ fontSize: '0.9rem', color: 'rgba(255,255,255,0.7)', lineHeight: '1.6' }}>{element.content.text}</p>\n          </div>\n        );\n      }\n      return null;\n\n    case 'counter':\n      if (typeof element.content === 'object') {\n        return (\n          <div style={{ textAlign: 'center', ...styles }}>\n            <div style={{ fontSize: '3rem', fontWeight: 'bold', color: theme.primaryColor }}>\n              {element.content.number}{element.content.suffix}\n            </div>\n            <div style={{ fontSize: '1rem', color: 'rgba(255,255,255,0.7)' }}>{element.content.label}</div>\n          </div>\n        );\n      }\n      return null;\n\n    case 'hero':\n    case 'cta':\n      if (typeof element.content === 'object') {\n        return (\n          <div style={{ textAlign: 'center', ...styles }}>\n            <h2 style={{ fontSize: '2.5rem', fontWeight: 'bold', color: '#fff', marginBottom: '16px' }}>{element.content.title}</h2>\n            {element.content.subtitle && (\n              <p style={{ fontSize: '1.25rem', color: 'rgba(255,255,255,0.8)', marginBottom: '24px', maxWidth: '600px', margin: '0 auto 24px' }}>\n                {element.content.subtitle}\n              </p>\n            )}\n            {element.content.buttonText && (\n              <Link\n                href={element.content.buttonLink || '/signup'}\n                style={{\n                  display: 'inline-block',\n                  padding: '16px 32px',\n                  backgroundColor: theme.primaryColor,\n                  color: '#fff',\n                  borderRadius: '8px',\n                  fontWeight: '600',\n                  textDecoration: 'none',\n                }}\n              >\n                {element.content.buttonText}\n              </Link>\n            )}\n          </div>\n        );\n      }\n      return null;\n\n    default:\n      // For unknown types, try to render content as text\n      if (typeof element.content === 'string') {\n        return <div style={styles}>{element.content}</div>;\n      }\n      return null;\n  }\n}\n\ninterface PageRendererProps {\n  page: PageContent;\n}\n\nexport default function PageRenderer({ page }: PageRendererProps) {\n  if (!page?.sections) {\n    return null;\n  }\n\n  return (\n    <>\n      {page.sections\n        .filter(section => section.visible !== false)\n        .map(section => (\n          <section\n            key={section.id}\n            style={{\n              ...section.styles?.desktop,\n            }}\n          >\n            <div style={{ maxWidth: '1280px', margin: '0 auto' }}>\n              {section.children?.map(element => (\n                <ElementRenderer key={element.id} element={element} />\n              ))}\n            </div>\n          </section>\n        ))}\n    </>\n  );\n}\n\n\n\n\n\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\ui\\input.tsx","messages":[{"ruleId":"@typescript-eslint/no-empty-object-type","severity":2,"message":"An interface declaring no members is equivalent to its supertype.","line":4,"column":18,"nodeType":"Identifier","messageId":"noEmptyInterfaceWithSuper","endLine":4,"endColumn":28,"suggestions":[{"messageId":"replaceEmptyInterfaceWithSuper","fix":{"range":[75,153],"text":"type InputProps = React.InputHTMLAttributes<HTMLInputElement>"},"desc":"Replace empty interface with a type alias."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import * as React from \"react\"\r\nimport { cn } from \"@/lib/utils\"\r\n\r\nexport interface InputProps\r\n  extends React.InputHTMLAttributes<HTMLInputElement> {}\r\n\r\nconst Input = React.forwardRef<HTMLInputElement, InputProps>(\r\n  ({ className, type, ...props }, ref) => {\r\n    return (\r\n      <input\r\n        type={type}\r\n        className={cn(\r\n          \"flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50\",\r\n          className\r\n        )}\r\n        ref={ref}\r\n        {...props}\r\n      />\r\n    )\r\n  }\r\n)\r\nInput.displayName = \"Input\"\r\n\r\nexport { Input }\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\ui\\label.tsx","messages":[{"ruleId":"@typescript-eslint/no-empty-object-type","severity":2,"message":"An interface declaring no members is equivalent to its supertype.","line":4,"column":18,"nodeType":"Identifier","messageId":"noEmptyInterfaceWithSuper","endLine":4,"endColumn":28,"suggestions":[{"messageId":"replaceEmptyInterfaceWithSuper","fix":{"range":[75,153],"text":"type LabelProps = React.LabelHTMLAttributes<HTMLLabelElement>"},"desc":"Replace empty interface with a type alias."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import * as React from \"react\"\r\nimport { cn } from \"@/lib/utils\"\r\n\r\nexport interface LabelProps\r\n  extends React.LabelHTMLAttributes<HTMLLabelElement> {}\r\n\r\nconst Label = React.forwardRef<HTMLLabelElement, LabelProps>(\r\n  ({ className, ...props }, ref) => (\r\n    <label\r\n      ref={ref}\r\n      className={cn(\r\n        \"text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70\",\r\n        className\r\n      )}\r\n      {...props}\r\n    />\r\n  )\r\n)\r\nLabel.displayName = \"Label\"\r\n\r\nexport { Label }\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\ui\\textarea.tsx","messages":[{"ruleId":"@typescript-eslint/no-empty-object-type","severity":2,"message":"An interface declaring no members is equivalent to its supertype.","line":4,"column":18,"nodeType":"Identifier","messageId":"noEmptyInterfaceWithSuper","endLine":4,"endColumn":31,"suggestions":[{"messageId":"replaceEmptyInterfaceWithSuper","fix":{"range":[75,162],"text":"type TextareaProps = React.TextareaHTMLAttributes<HTMLTextAreaElement>"},"desc":"Replace empty interface with a type alias."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import * as React from \"react\"\r\nimport { cn } from \"@/lib/utils\"\r\n\r\nexport interface TextareaProps\r\n  extends React.TextareaHTMLAttributes<HTMLTextAreaElement> {}\r\n\r\nconst Textarea = React.forwardRef<HTMLTextAreaElement, TextareaProps>(\r\n  ({ className, ...props }, ref) => {\r\n    return (\r\n      <textarea\r\n        className={cn(\r\n          \"flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50\",\r\n          className\r\n        )}\r\n        ref={ref}\r\n        {...props}\r\n      />\r\n    )\r\n  }\r\n)\r\nTextarea.displayName = \"Textarea\"\r\n\r\nexport { Textarea }\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\website-builder\\ResponsiveRenderer.tsx","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":234,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":234,"endColumn":44},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":235,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":235,"endColumn":69},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":352,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":352,"endColumn":62},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":382,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":382,"endColumn":56},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":497,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":497,"endColumn":56}],"suppressedMessages":[],"errorCount":5,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Responsive Page Renderer\n * Automatically applies mobile-responsive styling to page content\n * Handles breakpoints: desktop (1200px+), tablet (768-1199px), mobile (<768px)\n */\n\n'use client';\n\nimport type { PageSection, Widget } from '@/types/website';\nimport { OptimizedImage } from './OptimizedImage';\nimport { AccessibleWidget, SkipToMain } from './AccessibleWidget';\n\ninterface ResponsiveRendererProps {\n  content: PageSection[];\n  breakpoint?: 'desktop' | 'tablet' | 'mobile';\n}\n\nexport function ResponsiveRenderer({ content, breakpoint = 'desktop' }: ResponsiveRendererProps) {\n  return (\n    <div className=\"responsive-page\" role=\"main\" id=\"main-content\">\n      <SkipToMain />\n      {content.map((section, idx) => (\n        <Section key={section.id || idx} section={section} breakpoint={breakpoint} />\n      ))}\n\n      <style>{`\n        .responsive-page {\n          width: 100%;\n          min-height: 100vh;\n        }\n\n        /* Responsive typography */\n        @media (max-width: 767px) {\n          h1 { font-size: 28px !important; }\n          h2 { font-size: 24px !important; }\n          h3 { font-size: 20px !important; }\n          h4 { font-size: 18px !important; }\n          p { font-size: 16px; line-height: 1.6; }\n        }\n\n        /* Responsive spacing */\n        @media (max-width: 767px) {\n          .section { padding: 40px 20px !important; }\n          .widget { margin-bottom: 20px !important; }\n        }\n\n        /* Responsive images */\n        img {\n          max-width: 100%;\n          height: auto;\n        }\n\n        /* Responsive buttons */\n        button, .button {\n          min-width: fit-content;\n          padding: 12px 24px;\n        }\n\n        @media (max-width: 767px) {\n          button, .button {\n            width: 100%;\n            display: block;\n          }\n        }\n\n        /* Responsive grids */\n        .feature-grid,\n        .pricing-grid,\n        .logo-grid {\n          display: grid;\n          gap: 24px;\n        }\n\n        @media (min-width: 1200px) {\n          .feature-grid,\n          .pricing-grid {\n            grid-template-columns: repeat(3, 1fr);\n          }\n          .logo-grid {\n            grid-template-columns: repeat(4, 1fr);\n          }\n        }\n\n        @media (min-width: 768px) and (max-width: 1199px) {\n          .feature-grid,\n          .pricing-grid,\n          .logo-grid {\n            grid-template-columns: repeat(2, 1fr);\n          }\n        }\n\n        @media (max-width: 767px) {\n          .feature-grid,\n          .pricing-grid,\n          .logo-grid {\n            grid-template-columns: 1fr;\n          }\n        }\n\n        /* Responsive flexbox */\n        .flex-container {\n          display: flex;\n          gap: 24px;\n        }\n\n        @media (max-width: 767px) {\n          .flex-container {\n            flex-direction: column;\n          }\n        }\n\n        /* Responsive navigation */\n        @media (max-width: 767px) {\n          .nav-menu {\n            display: none;\n            position: fixed;\n            top: 60px;\n            left: 0;\n            right: 0;\n            background: white;\n            padding: 20px;\n            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n          }\n          \n          .nav-menu.open {\n            display: block;\n          }\n\n          .hamburger {\n            display: block !important;\n          }\n        }\n      `}</style>\n    </div>\n  );\n}\n\nfunction Section({ section, breakpoint }: { section: PageSection; breakpoint: string }) {\n  const getResponsivePadding = () => {\n    if (breakpoint === 'mobile') {\n      return '40px 20px';\n    }\n    if (breakpoint === 'tablet') {\n      return '60px 40px';\n    }\n    return section.padding\n      ? `${section.padding.top || '80px'} ${section.padding.right || '40px'} ${section.padding.bottom || '80px'} ${section.padding.left || '40px'}`\n      : '80px 40px';\n  };\n\n  const sectionStyle: React.CSSProperties = {\n    backgroundColor: section.backgroundColor || 'transparent',\n    backgroundImage: section.backgroundImage ? `url(${section.backgroundImage})` : undefined,\n    backgroundSize: 'cover',\n    backgroundPosition: 'center',\n    padding: getResponsivePadding(),\n    maxWidth: section.fullWidth ? '100%' : section.maxWidth || '1200px',\n    margin: '0 auto',\n    width: '100%',\n  };\n\n  return (\n    <section className=\"section\" style={sectionStyle}>\n      <div className={section.columns.length > 1 ? 'flex-container' : ''}>\n        {section.columns.map((column, idx) => (\n          <div\n            key={column.id || idx}\n            style={{\n              flex: section.columns.length > 1 ? `${column.width}` : undefined,\n              width: section.columns.length === 1 ? '100%' : undefined,\n            }}\n          >\n            {column.widgets.map((widget, widgetIdx) => (\n              <AccessibleWidget key={widget.id || widgetIdx} widget={widget}>\n                <div className=\"widget\">\n                  <WidgetRenderer widget={widget} breakpoint={breakpoint} />\n                </div>\n              </AccessibleWidget>\n            ))}\n          </div>\n        ))}\n      </div>\n    </section>\n  );\n}\n\nfunction WidgetRenderer({ widget, breakpoint }: { widget: Widget; breakpoint: string }) {\n  const convertSpacing = (spacing?: any): string => {\n    if (!spacing) {return '0';}\n    if (typeof spacing === 'string') {return spacing;}\n    return `${spacing.top || 0} ${spacing.right || 0} ${spacing.bottom || 0} ${spacing.left || 0}`;\n  };\n\n  const getResponsiveStyle = (): React.CSSProperties => {\n    const baseStyle: any = { ...(widget.style || {}) };\n    \n    // Convert Spacing objects to CSS strings\n    if (baseStyle.padding && typeof baseStyle.padding === 'object') {\n      baseStyle.padding = convertSpacing(baseStyle.padding);\n    }\n    if (baseStyle.margin && typeof baseStyle.margin === 'object') {\n      baseStyle.margin = convertSpacing(baseStyle.margin);\n    }\n    \n    // Apply responsive overrides\n    if (breakpoint === 'mobile' && widget.responsive?.mobile) {\n      const mobileStyle: any = { ...widget.responsive.mobile };\n      if (mobileStyle.padding && typeof mobileStyle.padding === 'object') {\n        mobileStyle.padding = convertSpacing(mobileStyle.padding);\n      }\n      if (mobileStyle.margin && typeof mobileStyle.margin === 'object') {\n        mobileStyle.margin = convertSpacing(mobileStyle.margin);\n      }\n      return { ...baseStyle, ...mobileStyle };\n    }\n    if (breakpoint === 'tablet' && widget.responsive?.tablet) {\n      const tabletStyle: any = { ...widget.responsive.tablet };\n      if (tabletStyle.padding && typeof tabletStyle.padding === 'object') {\n        tabletStyle.padding = convertSpacing(tabletStyle.padding);\n      }\n      if (tabletStyle.margin && typeof tabletStyle.margin === 'object') {\n        tabletStyle.margin = convertSpacing(tabletStyle.margin);\n      }\n      return { ...baseStyle, ...tabletStyle };\n    }\n    \n    return baseStyle;\n  };\n\n  const style = getResponsiveStyle();\n\n  switch (widget.type) {\n    case 'heading':\n      const level = widget.data.level || 1;\n      const HeadingTag = `h${level}` as keyof JSX.IntrinsicElements;\n      return (\n        <HeadingTag style={style}>\n          {String(widget.data.text || 'Heading')}\n        </HeadingTag>\n      );\n\n    case 'text':\n      return (\n        <p style={style}>\n          {String(widget.data.content || 'Text content')}\n        </p>\n      );\n\n    case 'button':\n      return (\n        <button\n          style={{\n            padding: '12px 24px',\n            backgroundColor: (widget.data.color as string) || '#3b82f6',\n            color: 'white',\n            border: 'none',\n            borderRadius: '6px',\n            fontSize: '16px',\n            fontWeight: '500',\n            cursor: 'pointer',\n            ...style,\n          }}\n          onClick={() => {\n            if (widget.data.url) {\n              window.location.href = widget.data.url as string;\n            }\n          }}\n        >\n          {String(widget.data.text || 'Button')}\n        </button>\n      );\n\n    case 'image':\n      return (\n        <OptimizedImage\n          src={(widget.data.src as string) || 'https://via.placeholder.com/800x400'}\n          alt={(widget.data.alt as string) || 'Image'}\n          style={{\n            width: '100%',\n            height: 'auto',\n            borderRadius: '8px',\n            ...style,\n          }}\n          sizes={{\n            mobile: '100vw',\n            tablet: '50vw',\n            desktop: '33vw',\n          }}\n        />\n      );\n\n    case 'hero':\n      return (\n        <div\n          style={{\n            textAlign: 'center',\n            padding: breakpoint === 'mobile' ? '40px 20px' : '80px 40px',\n            backgroundImage: widget.data.backgroundImage\n              ? `linear-gradient(rgba(0,0,0,0.4), rgba(0,0,0,0.4)), url(${widget.data.backgroundImage})`\n              : undefined,\n            backgroundSize: 'cover',\n            backgroundPosition: 'center',\n            color: 'white',\n            borderRadius: '8px',\n            ...style,\n          }}\n        >\n          <h1\n            style={{\n              fontSize: breakpoint === 'mobile' ? '32px' : '48px',\n              fontWeight: 'bold',\n              marginBottom: '16px',\n            }}\n          >\n            {String(widget.data.heading || 'Hero Heading')}\n          </h1>\n          <p\n            style={{\n              fontSize: breakpoint === 'mobile' ? '16px' : '20px',\n              marginBottom: '32px',\n              maxWidth: '600px',\n              margin: '0 auto 32px',\n            }}\n          >\n            {String(widget.data.subheading || 'Hero subheading')}\n          </p>\n          {(widget.data.buttonText as string) && (\n            <button\n              style={{\n                padding: '16px 32px',\n                backgroundColor: '#3b82f6',\n                color: 'white',\n                border: 'none',\n                borderRadius: '6px',\n                fontSize: '18px',\n                fontWeight: '600',\n                cursor: 'pointer',\n              }}\n              onClick={() => {\n                if (widget.data.buttonUrl) {\n                  window.location.href = String(widget.data.buttonUrl);\n                }\n              }}\n            >\n              {String(widget.data.buttonText)}\n            </button>\n          )}\n        </div>\n      );\n\n    case 'features':\n      const features = (widget.data.features as any[]) || [];\n      return (\n        <div className=\"feature-grid\">\n          {features.map((feature: any, idx: number) => (\n            <div\n              key={idx}\n              style={{\n                padding: '24px',\n                backgroundColor: '#f9fafb',\n                borderRadius: '8px',\n                textAlign: 'center',\n              }}\n            >\n              {feature.icon && (\n                <div style={{ fontSize: '48px', marginBottom: '16px' }}>\n                  {feature.icon}\n                </div>\n              )}\n              <h3 style={{ fontSize: '20px', fontWeight: '600', marginBottom: '12px' }}>\n                {feature.title}\n              </h3>\n              <p style={{ color: '#6b7280', fontSize: '14px' }}>\n                {feature.description}\n              </p>\n            </div>\n          ))}\n        </div>\n      );\n\n    case 'pricing':\n      const plans = (widget.data.plans as any[]) || [];\n      return (\n        <div className=\"pricing-grid\">\n          {plans.map((plan: any, idx: number) => (\n            <div\n              key={idx}\n              style={{\n                padding: '32px',\n                backgroundColor: 'white',\n                border: '2px solid #e5e7eb',\n                borderRadius: '8px',\n                textAlign: 'center',\n              }}\n            >\n              <h3 style={{ fontSize: '24px', fontWeight: '600', marginBottom: '16px' }}>\n                {plan.name}\n              </h3>\n              <div style={{ fontSize: '48px', fontWeight: 'bold', marginBottom: '24px' }}>\n                ${plan.price}\n                <span style={{ fontSize: '16px', fontWeight: 'normal', color: '#6b7280' }}>\n                  /month\n                </span>\n              </div>\n              <button\n                style={{\n                  width: '100%',\n                  padding: '12px',\n                  backgroundColor: plan.featured ? '#3b82f6' : 'white',\n                  color: plan.featured ? 'white' : '#374151',\n                  border: plan.featured ? 'none' : '1px solid #d1d5db',\n                  borderRadius: '6px',\n                  fontSize: '16px',\n                  fontWeight: '500',\n                  cursor: 'pointer',\n                }}\n              >\n                Choose Plan\n              </button>\n            </div>\n          ))}\n        </div>\n      );\n\n    case 'testimonial':\n      return (\n        <div\n          style={{\n            padding: '32px',\n            backgroundColor: '#f9fafb',\n            borderRadius: '8px',\n            textAlign: 'center',\n            ...style,\n          }}\n        >\n          <p\n            style={{\n              fontSize: '18px',\n              fontStyle: 'italic',\n              color: '#374151',\n              marginBottom: '16px',\n            }}\n          >\n            \"{String(widget.data.quote || 'Testimonial quote')}\"\n          </p>\n          <div style={{ fontWeight: '600', color: '#111827' }}>\n            {String(widget.data.author || 'Author Name')}\n          </div>\n          <div style={{ fontSize: '14px', color: '#6b7280' }}>\n            {String(widget.data.role || 'Role / Company')}\n          </div>\n        </div>\n      );\n\n    case 'cta':\n      return (\n        <div\n          style={{\n            textAlign: 'center',\n            padding: breakpoint === 'mobile' ? '40px 20px' : '60px 40px',\n            backgroundColor: '#3b82f6',\n            borderRadius: '8px',\n            color: 'white',\n            ...style,\n          }}\n        >\n          <h2\n            style={{\n              fontSize: breakpoint === 'mobile' ? '24px' : '32px',\n              fontWeight: 'bold',\n              marginBottom: '16px',\n            }}\n          >\n            {String(widget.data.heading || 'Ready to get started?')}\n          </h2>\n          <p style={{ fontSize: '18px', marginBottom: '24px' }}>\n            {String(widget.data.text || 'Join thousands of satisfied customers')}\n          </p>\n          <button\n            style={{\n              padding: '16px 32px',\n              backgroundColor: 'white',\n              color: '#3b82f6',\n              border: 'none',\n              borderRadius: '6px',\n              fontSize: '16px',\n              fontWeight: '600',\n              cursor: 'pointer',\n            }}\n          >\n            {String(widget.data.buttonText || 'Get Started')}\n          </button>\n        </div>\n      );\n\n    case 'logo-grid':\n      const logos = (widget.data.logos as any[]) || [];\n      return (\n        <div className=\"logo-grid\">\n          {logos.map((logo: any, idx: number) => (\n            <div\n              key={idx}\n              style={{\n                display: 'flex',\n                alignItems: 'center',\n                justifyContent: 'center',\n                padding: '20px',\n                backgroundColor: '#f9fafb',\n                borderRadius: '8px',\n              }}\n            >\n              <img\n                src={logo.src}\n                alt={logo.alt}\n                style={{\n                  maxWidth: '120px',\n                  maxHeight: '60px',\n                  opacity: 0.7,\n                }}\n              />\n            </div>\n          ))}\n        </div>\n      );\n\n    default:\n      return (\n        <div\n          style={{\n            padding: '16px',\n            backgroundColor: '#f3f4f6',\n            borderRadius: '6px',\n            color: '#6b7280',\n            ...style,\n          }}\n        >\n          {widget.type} widget\n        </div>\n      );\n  }\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\components\\website-builder\\WidgetRenderer.tsx","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":20,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":20,"endColumn":83},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":445,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":445,"endColumn":94},{"ruleId":"no-duplicate-case","severity":2,"message":"Duplicate case label.","line":473,"column":5,"nodeType":"SwitchCase","messageId":"unexpected","endLine":508,"endColumn":9},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":474,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":474,"endColumn":112}],"suppressedMessages":[],"errorCount":4,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Widget Renderer\n * Renders each widget type based on its data and style\n */\n\n'use client';\n\nimport type { Widget, WidgetStyle, Spacing } from '@/types/website';\n\ninterface WidgetRendererProps {\n  widget: Widget;\n  isEditable?: boolean;\n}\n\nexport default function WidgetRenderer({ widget, isEditable = false }: WidgetRendererProps) {\n  const style = convertWidgetStyleToCSS(widget.style);\n\n  switch (widget.type) {\n    case 'heading':\n      const HeadingTag = (widget.data.tag || 'h2') as keyof JSX.IntrinsicElements;\n      return <HeadingTag style={style}>{String(widget.data.text || 'Heading')}</HeadingTag>;\n\n    case 'text':\n      return <p style={style}>{String(widget.data.content || 'Text content')}</p>;\n\n    case 'button':\n      return (\n        <a \n          href={(widget.data.url as string) || '#'} \n          target={widget.data.openInNewTab ? '_blank' : undefined}\n          rel={widget.data.openInNewTab ? 'noopener noreferrer' : undefined}\n          style={{ ...style, display: 'inline-block', textDecoration: 'none' }}\n        >\n          {String(widget.data.text || 'Button')}\n        </a>\n      );\n\n    case 'link':\n      return (\n        <a \n          href={(widget.data.url as string) || '#'}\n          target={widget.data.openInNewTab ? '_blank' : undefined}\n          rel={widget.data.openInNewTab ? 'noopener noreferrer' : undefined}\n          style={style}\n        >\n          {String(widget.data.text || 'Link')}\n        </a>\n      );\n\n    case 'image':\n      return (\n        <div style={style}>\n          <img \n            src={(widget.data.src as string) || 'https://via.placeholder.com/800x400'} \n            alt={(widget.data.alt as string) || ''}\n            style={{ width: '100%', height: 'auto', display: 'block' }}\n          />\n          {(widget.data.caption as string) && (\n            <p style={{ \n              fontSize: '0.875rem', \n              color: '#6c757d', \n              marginTop: '0.5rem',\n              textAlign: 'center',\n            }}>\n              {String(widget.data.caption)}\n            </p>\n          )}\n        </div>\n      );\n\n    case 'video':\n      return (\n        <div style={style}>\n          <div style={{ \n            position: 'relative', \n            paddingBottom: '56.25%', \n            height: 0,\n            overflow: 'hidden',\n          }}>\n            <iframe\n              src={getVideoEmbedUrl(widget.data.url as string, widget.data.provider as string)}\n              style={{\n                position: 'absolute',\n                top: 0,\n                left: 0,\n                width: '100%',\n                height: '100%',\n                border: 'none',\n              }}\n              allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\n              allowFullScreen\n            />\n          </div>\n        </div>\n      );\n\n    case 'spacer':\n      return <div style={{ height: (widget.data.height as string) || '2rem', ...style }} />;\n\n    case 'divider':\n      return (\n        <hr style={{\n          border: 'none',\n          height: (widget.data.thickness as string) || '1px',\n          backgroundColor: (widget.data.color as string) || '#dee2e6',\n          ...style,\n        }} />\n      );\n\n    case 'hero':\n      return (\n        <div style={{\n          ...style,\n          backgroundImage: widget.data.backgroundImage ? `url(${widget.data.backgroundImage})` : undefined,\n          backgroundSize: 'cover',\n          backgroundPosition: 'center',\n        }}>\n          <h1 style={{ fontSize: '3rem', fontWeight: '700', marginBottom: '1rem' }}>\n            {String(widget.data.heading || 'Welcome')}\n          </h1>\n          {(widget.data.subheading as string) && (\n            <p style={{ fontSize: '1.25rem', marginBottom: '2rem' }}>\n              {String(widget.data.subheading)}\n            </p>\n          )}\n          {(widget.data.buttonText as string) && (\n            <a \n              href={(widget.data.buttonUrl as string) || '#'}\n              style={{\n                display: 'inline-block',\n                padding: '1rem 2rem',\n                background: '#007bff',\n                color: 'white',\n                textDecoration: 'none',\n                borderRadius: '4px',\n                fontSize: '1.125rem',\n                fontWeight: '600',\n              }}\n            >\n              {String(widget.data.buttonText)}\n            </a>\n          )}\n        </div>\n      );\n\n    case 'features':\n      return (\n        <div style={{\n          ...style,\n          display: 'grid',\n          gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))',\n          gap: '2rem',\n        }}>\n          {((widget.data.features as any[]) || []).map((feature: any, i: number) => (\n            <div key={i} style={{ textAlign: 'center' }}>\n              <div style={{ fontSize: '3rem', marginBottom: '1rem' }}>{feature.icon}</div>\n              <h3 style={{ fontSize: '1.25rem', marginBottom: '0.5rem' }}>{feature.title}</h3>\n              <p style={{ color: '#6c757d' }}>{feature.description}</p>\n            </div>\n          ))}\n        </div>\n      );\n\n    case 'pricing':\n      return (\n        <div style={{\n          ...style,\n          display: 'grid',\n          gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))',\n          gap: '2rem',\n        }}>\n          {((widget.data.plans as any[]) || []).map((plan: any, i: number) => (\n            <div \n              key={i} \n              style={{\n                padding: '2rem',\n                background: plan.featured ? '#007bff' : 'white',\n                color: plan.featured ? 'white' : '#212529',\n                border: plan.featured ? 'none' : '1px solid #dee2e6',\n                borderRadius: '8px',\n                textAlign: 'center',\n              }}\n            >\n              <h3 style={{ fontSize: '1.5rem', marginBottom: '1rem' }}>{plan.name}</h3>\n              <div style={{ fontSize: '3rem', fontWeight: '700', marginBottom: '1rem' }}>\n                {plan.price}\n                <span style={{ fontSize: '1rem', fontWeight: '400' }}>/{plan.period}</span>\n              </div>\n              <ul style={{ \n                listStyle: 'none', \n                padding: 0, \n                marginBottom: '2rem',\n                textAlign: 'left',\n              }}>\n                {plan.features.map((feature: string, j: number) => (\n                  <li key={j} style={{ padding: '0.5rem 0' }}>‚úì {feature}</li>\n                ))}\n              </ul>\n              <a \n                href={plan.buttonUrl || '#'}\n                style={{\n                  display: 'inline-block',\n                  padding: '0.75rem 1.5rem',\n                  background: plan.featured ? 'white' : '#007bff',\n                  color: plan.featured ? '#007bff' : 'white',\n                  textDecoration: 'none',\n                  borderRadius: '4px',\n                  fontWeight: '600',\n                }}\n              >\n                {plan.buttonText}\n              </a>\n            </div>\n          ))}\n        </div>\n      );\n\n    case 'testimonial':\n      return (\n        <div style={style}>\n          <p style={{ \n            fontSize: '1.125rem', \n            fontStyle: 'italic', \n            marginBottom: '1.5rem',\n            lineHeight: '1.6',\n          }}>\n            \"{String(widget.data.quote)}\"\n          </p>\n          <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'center', gap: '1rem' }}>\n            {(widget.data.avatar as string) && (\n              <img \n                src={widget.data.avatar as string} \n                alt={(widget.data.author as string) || ''}\n                style={{ \n                  width: '60px', \n                  height: '60px', \n                  borderRadius: '50%',\n                  objectFit: 'cover',\n                }}\n              />\n            )}\n            <div>\n              <div style={{ fontWeight: '600' }}>{String(widget.data.author)}</div>\n              <div style={{ fontSize: '0.875rem', color: '#6c757d' }}>{String(widget.data.role)}</div>\n            </div>\n          </div>\n        </div>\n      );\n\n    case 'cta':\n      return (\n        <div style={style}>\n          <h2 style={{ fontSize: '2rem', marginBottom: '0.5rem' }}>{String(widget.data.heading)}</h2>\n          {(widget.data.subheading as string) && (\n            <p style={{ fontSize: '1.125rem', marginBottom: '1.5rem' }}>{String(widget.data.subheading)}</p>\n          )}\n          <a \n            href={(widget.data.buttonUrl as string) || '#'}\n            style={{\n              display: 'inline-block',\n              padding: '1rem 2rem',\n              background: 'white',\n              color: '#007bff',\n              textDecoration: 'none',\n              borderRadius: '4px',\n              fontSize: '1.125rem',\n              fontWeight: '600',\n            }}\n          >\n            {String(widget.data.buttonText)}\n          </a>\n        </div>\n      );\n\n    case 'stats':\n      return (\n        <div style={{\n          ...style,\n          display: 'grid',\n          gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))',\n          gap: '2rem',\n        }}>\n          {((widget.data.stats as any[]) || []).map((stat: any, i: number) => (\n            <div key={i} style={{ textAlign: 'center' }}>\n              <div style={{ fontSize: '3rem', fontWeight: '700', color: '#007bff', marginBottom: '0.5rem' }}>\n                {stat.number}\n              </div>\n              <div style={{ fontSize: '1.125rem', color: '#6c757d' }}>{stat.label}</div>\n            </div>\n          ))}\n        </div>\n      );\n\n    case 'gallery':\n      return (\n        <div style={{\n          ...style,\n          display: 'grid',\n          gridTemplateColumns: `repeat(${(widget.data.columns as number) || 3}, 1fr)`,\n          gap: (widget.data.gap as string) || '1rem',\n        }}>\n          {((widget.data.images as any[]) || []).map((img: any, i: number) => (\n            <img \n              key={i}\n              src={img.src} \n              alt={img.alt}\n              style={{ \n                width: '100%', \n                height: '250px',\n                objectFit: 'cover',\n                borderRadius: '4px',\n              }}\n            />\n          ))}\n        </div>\n      );\n\n    case 'contact-form':\n      return (\n        <form style={style} onSubmit={(e) => e.preventDefault()}>\n          <div style={{ marginBottom: '1rem' }}>\n            <label style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '500' }}>Name</label>\n            <input type=\"text\" style={inputStyle} placeholder=\"Your name\" />\n          </div>\n          <div style={{ marginBottom: '1rem' }}>\n            <label style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '500' }}>Email</label>\n            <input type=\"email\" style={inputStyle} placeholder=\"your@email.com\" />\n          </div>\n          <div style={{ marginBottom: '1rem' }}>\n            <label style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '500' }}>Message</label>\n            <textarea rows={4} style={{ ...inputStyle, resize: 'vertical' }} placeholder=\"Your message\" />\n          </div>\n          <button type=\"submit\" style={buttonStyle}>\n            {String(widget.data.submitText || 'Send Message')}\n          </button>\n        </form>\n      );\n\n    case 'newsletter':\n      return (\n        <div style={style}>\n          <h3 style={{ marginBottom: '1rem' }}>{String(widget.data.heading)}</h3>\n          <form style={{ display: 'flex', gap: '0.5rem' }} onSubmit={(e) => e.preventDefault()}>\n            <input \n              type=\"email\" \n              placeholder={(widget.data.placeholder as string) || 'Enter your email'}\n              style={{ ...inputStyle, flex: 1 }}\n            />\n            <button type=\"submit\" style={buttonStyle}>\n              {String(widget.data.buttonText || 'Subscribe')}\n            </button>\n          </form>\n        </div>\n      );\n\n    case 'social-icons':\n      return (\n        <div style={{ ...style, display: 'flex', gap: '1rem' }}>\n          {((widget.data.icons as any[]) || []).map((icon: any, i: number) => (\n            <a \n              key={i}\n              href={icon.url}\n              target=\"_blank\"\n              rel=\"noopener noreferrer\"\n              style={{\n                width: '40px',\n                height: '40px',\n                display: 'flex',\n                alignItems: 'center',\n                justifyContent: 'center',\n                background: '#007bff',\n                color: 'white',\n                borderRadius: '50%',\n                textDecoration: 'none',\n                fontSize: '1.25rem',\n              }}\n            >\n              {getSocialIcon(icon.platform)}\n            </a>\n          ))}\n        </div>\n      );\n\n    case 'accordion':\n      return (\n        <div style={style}>\n          {((widget.data.items as any[]) || []).map((item: any, i: number) => (\n            <details key={i} style={{ \n              marginBottom: '0.5rem',\n              border: '1px solid #dee2e6',\n              borderRadius: '4px',\n              padding: '1rem',\n            }}>\n              <summary style={{ fontWeight: '600', cursor: 'pointer' }}>\n                {item.title}\n              </summary>\n              <p style={{ marginTop: '0.75rem', color: '#6c757d' }}>\n                {item.content}\n              </p>\n            </details>\n          ))}\n        </div>\n      );\n\n    case 'icon-box':\n      return (\n        <div style={style}>\n          <div style={{ fontSize: '3rem', marginBottom: '1rem' }}>{String(widget.data.icon)}</div>\n          <h3 style={{ fontSize: '1.25rem', marginBottom: '0.5rem' }}>{String(widget.data.title)}</h3>\n          <p style={{ color: '#6c757d' }}>{String(widget.data.description)}</p>\n        </div>\n      );\n\n    case 'html':\n      return <div style={style} dangerouslySetInnerHTML={{ __html: widget.data.html || '' }} />;\n\n    case 'code':\n      return (\n        <pre style={style}>\n          <code>{String(widget.data.code || '')}</code>\n        </pre>\n      );\n\n    case 'modal':\n      return (\n        <div style={style}>\n          <button\n            style={{\n              padding: '12px 24px',\n              background: (widget.data.buttonColor as string) || '#007bff',\n              color: 'white',\n              border: 'none',\n              borderRadius: '6px',\n              cursor: 'pointer',\n              fontSize: '16px',\n              fontWeight: '500',\n            }}\n          >\n            {String(widget.data.buttonText || 'Open Modal')}\n          </button>\n        </div>\n      );\n\n    case 'tabs':\n      const tabs = (widget.data.tabs as any[]) || [{ title: 'Tab 1', content: 'Content 1' }];\n      return (\n        <div style={style}>\n          <div style={{ borderBottom: '2px solid #dee2e6', display: 'flex' }}>\n            {tabs.map((tab: any, index: number) => (\n              <button\n                key={index}\n                style={{\n                  padding: '12px 24px',\n                  background: index === 0 ? '#007bff' : 'transparent',\n                  color: index === 0 ? 'white' : '#495057',\n                  border: 'none',\n                  cursor: 'pointer',\n                  fontSize: '14px',\n                  fontWeight: '500',\n                  borderBottom: index === 0 ? '2px solid #007bff' : 'none',\n                }}\n              >\n                {tab.title}\n              </button>\n            ))}\n          </div>\n          <div style={{ padding: '20px', background: 'white' }}>\n            {tabs[0]?.content || 'Tab content'}\n          </div>\n        </div>\n      );\n\n    case 'accordion':\n      const accordionItems = (widget.data.items as any[]) || [{ title: 'Accordion Item', content: 'Content' }];\n      return (\n        <div style={style}>\n          {accordionItems.map((item: any, index: number) => (\n            <div\n              key={index}\n              style={{\n                border: '1px solid #dee2e6',\n                borderRadius: '6px',\n                marginBottom: '8px',\n                overflow: 'hidden',\n              }}\n            >\n              <div\n                style={{\n                  padding: '16px',\n                  background: '#f8f9fa',\n                  fontSize: '16px',\n                  fontWeight: '500',\n                  cursor: 'pointer',\n                  display: 'flex',\n                  justifyContent: 'space-between',\n                  alignItems: 'center',\n                }}\n              >\n                {item.title}\n                <span style={{ fontSize: '12px' }}>‚ñº</span>\n              </div>\n              <div style={{ padding: '16px', background: 'white', borderTop: '1px solid #dee2e6' }}>\n                {item.content}\n              </div>\n            </div>\n          ))}\n        </div>\n      );\n\n    default:\n      return (\n        <div style={{\n          ...style,\n          padding: '1rem',\n          background: '#f8f9fa',\n          border: '1px dashed #dee2e6',\n          borderRadius: '4px',\n          textAlign: 'center',\n          color: '#6c757d',\n        }}>\n          {widget.type} widget\n        </div>\n      );\n  }\n}\n\n// Helper functions\nfunction convertWidgetStyleToCSS(widgetStyle?: WidgetStyle): React.CSSProperties {\n  if (!widgetStyle) {return {};}\n\n  return {\n    padding: widgetStyle.padding ? convertSpacingToCSS(widgetStyle.padding) : undefined,\n    margin: widgetStyle.margin ? convertSpacingToCSS(widgetStyle.margin) : undefined,\n    width: widgetStyle.width,\n    height: widgetStyle.height,\n    display: widgetStyle.display,\n    flexDirection: widgetStyle.flexDirection,\n    alignItems: widgetStyle.alignItems,\n    justifyContent: widgetStyle.justifyContent,\n    fontFamily: widgetStyle.fontFamily,\n    fontSize: widgetStyle.fontSize,\n    fontWeight: widgetStyle.fontWeight,\n    lineHeight: widgetStyle.lineHeight,\n    letterSpacing: widgetStyle.letterSpacing,\n    textAlign: widgetStyle.textAlign,\n    textTransform: widgetStyle.textTransform,\n    color: widgetStyle.color,\n    backgroundColor: widgetStyle.backgroundColor,\n    border: widgetStyle.border,\n    borderRadius: widgetStyle.borderRadius,\n    borderWidth: widgetStyle.borderWidth,\n    borderColor: widgetStyle.borderColor,\n    borderStyle: widgetStyle.borderStyle,\n    boxShadow: widgetStyle.boxShadow,\n    opacity: widgetStyle.opacity,\n    transform: widgetStyle.transform,\n    transition: widgetStyle.transition,\n    backgroundImage: widgetStyle.backgroundImage,\n    backgroundSize: widgetStyle.backgroundSize,\n    backgroundPosition: widgetStyle.backgroundPosition,\n    backgroundRepeat: widgetStyle.backgroundRepeat,\n  };\n}\n\nfunction convertSpacingToCSS(spacing: Spacing): string {\n  const top = spacing.top || '0';\n  const right = spacing.right || spacing.top || '0';\n  const bottom = spacing.bottom || spacing.top || '0';\n  const left = spacing.left || spacing.right || spacing.top || '0';\n  return `${top} ${right} ${bottom} ${left}`;\n}\n\nfunction getVideoEmbedUrl(url: string, provider: string): string {\n  if (!url) {return '';}\n  \n  if (provider === 'youtube') {\n    const videoId = url.match(/(?:youtube\\.com\\/watch\\?v=|youtu\\.be\\/)([^&]+)/)?.[1];\n    return videoId ? `https://www.youtube.com/embed/${videoId}` : '';\n  } else if (provider === 'vimeo') {\n    const videoId = url.match(/vimeo\\.com\\/(\\d+)/)?.[1];\n    return videoId ? `https://player.vimeo.com/video/${videoId}` : '';\n  }\n  \n  return url;\n}\n\nfunction getSocialIcon(platform: string): string {\n  const icons: Record<string, string> = {\n    facebook: 'f',\n    twitter: 'ùïè',\n    instagram: 'üì∑',\n    linkedin: 'in',\n    youtube: '‚ñ∂Ô∏è',\n    github: 'üêô',\n  };\n  return icons[platform] || '‚Ä¢';\n}\n\n// Common styles\nconst inputStyle: React.CSSProperties = {\n  width: '100%',\n  padding: '0.75rem',\n  border: '1px solid #ced4da',\n  borderRadius: '4px',\n  fontSize: '1rem',\n};\n\nconst buttonStyle: React.CSSProperties = {\n  padding: '0.75rem 1.5rem',\n  background: '#007bff',\n  color: 'white',\n  border: 'none',\n  borderRadius: '4px',\n  cursor: 'pointer',\n  fontSize: '1rem',\n  fontWeight: '500',\n};\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\analytics\\dashboard\\analytics-engine.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":906,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":906,"endColumn":54}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Advanced Analytics Engine\r\n * \r\n * SOVEREIGN CORPORATE BRAIN - ANALYTICS MODULE\r\n * \r\n * This service aggregates data from all platform features to provide\r\n * comprehensive analytics and insights.\r\n * \r\n * FEATURES:\r\n * - Multi-source data aggregation (workflows, emails, deals, revenue)\r\n * - Intelligent caching (5-minute TTL for performance)\r\n * - Trend calculations (period-over-period comparisons)\r\n * - Time series generation\r\n * - Performance optimization\r\n * \r\n * INTEGRATION:\r\n * - Workflow Engine for automation analytics\r\n * - Email Writer for email analytics\r\n * - Deal Scoring for pipeline insights\r\n * - Revenue Forecasting for revenue predictions\r\n * - DAL for environment-aware data access\r\n */\r\n\r\nimport type {\r\n  DashboardOverview,\r\n  TimePeriod,\r\n  WorkflowOverviewMetrics,\r\n  EmailOverviewMetrics,\r\n  DealOverviewMetrics,\r\n  RevenueOverviewMetrics,\r\n  TeamOverviewMetrics,\r\n  TimeSeriesDataPoint,\r\n  WorkflowPerformanceSummary,\r\n  ActionTypeMetrics,\r\n  EmailTypeMetrics,\r\n  TierDistribution,\r\n  StageMetrics,\r\n  TierMetrics,\r\n  RepPerformanceSummary,\r\n} from './types';\r\n\r\nimport { adminDal } from '@/lib/firebase/admin-dal';\r\nimport type { Workflow, WorkflowExecution } from '@/lib/workflow/types';\r\nimport { emitDashboardGenerated } from './events';\r\n\r\n// ============================================================================\r\n// CACHE CONFIGURATION\r\n// ============================================================================\r\n\r\n/** Cache TTL in seconds (5 minutes) */\r\nconst CACHE_TTL = 300;\r\n\r\n/** In-memory cache */\r\nconst analyticsCache = new Map<string, { data: DashboardOverview; timestamp: Date }>();\r\n\r\n// ============================================================================\r\n// UTILITY FUNCTIONS\r\n// ============================================================================\r\n\r\n/**\r\n * Convert Firestore Timestamp or Date-like object to Date\r\n */\r\nfunction toDate(value: any): Date {\r\n  if (value instanceof Date) {\r\n    return value;\r\n  }\r\n  if (value && typeof value.toDate === 'function') {\r\n    return value.toDate();\r\n  }\r\n  return new Date(value);\r\n}\r\n\r\n// ============================================================================\r\n// MAIN ANALYTICS ENGINE\r\n// ============================================================================\r\n\r\n/**\r\n * Get comprehensive dashboard analytics\r\n * \r\n * @param organizationId - Organization ID\r\n * @param workspaceId - Workspace ID\r\n * @param period - Time period for analytics\r\n * @param startDate - Custom start date (for custom period)\r\n * @param endDate - Custom end date (for custom period)\r\n * @returns Dashboard overview with all metrics\r\n */\r\nexport async function getDashboardAnalytics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  period: TimePeriod,\r\n  startDate?: Date,\r\n  endDate?: Date\r\n): Promise<DashboardOverview> {\r\n  const startTime = Date.now();\r\n  \r\n  // Check cache\r\n  const cacheKey = `${organizationId}:${workspaceId}:${period}:${startDate?.toISOString()}:${endDate?.toISOString()}`;\r\n  const cached = analyticsCache.get(cacheKey);\r\n  \r\n  if (cached) {\r\n    const age = Date.now() - cached.timestamp.getTime();\r\n    if (age < CACHE_TTL * 1000) {\r\n      // Emit event for cached response\r\n      const generationTime = Date.now() - startTime;\r\n      await emitDashboardGenerated(\r\n        organizationId,\r\n        workspaceId,\r\n        period,\r\n        generationTime,\r\n        true,\r\n        cached.data\r\n      );\r\n      return cached.data;\r\n    }\r\n  }\r\n  \r\n  // Calculate date range\r\n  const dateRange = calculateDateRange(period, startDate, endDate);\r\n  const previousDateRange = calculatePreviousDateRange(dateRange.start, dateRange.end);\r\n  \r\n  // Aggregate data from all sources in parallel\r\n  const [workflows, emails, deals, revenue, team] = await Promise.all([\r\n    getWorkflowMetrics(organizationId, workspaceId, dateRange.start, dateRange.end, previousDateRange),\r\n    getEmailMetrics(organizationId, workspaceId, dateRange.start, dateRange.end, previousDateRange),\r\n    getDealMetrics(organizationId, workspaceId, dateRange.start, dateRange.end, previousDateRange),\r\n    getRevenueMetrics(organizationId, workspaceId, dateRange.start, dateRange.end, previousDateRange),\r\n    getTeamMetrics(organizationId, workspaceId, dateRange.start, dateRange.end),\r\n  ]);\r\n  \r\n  const dashboard: DashboardOverview = {\r\n    period,\r\n    startDate: dateRange.start,\r\n    endDate: dateRange.end,\r\n    workflows,\r\n    emails,\r\n    deals,\r\n    revenue,\r\n    team,\r\n  };\r\n  \r\n  // Cache result\r\n  analyticsCache.set(cacheKey, {\r\n    data: dashboard,\r\n    timestamp: new Date(),\r\n  });\r\n  \r\n  // Emit event for new generation\r\n  const generationTime = Date.now() - startTime;\r\n  await emitDashboardGenerated(\r\n    organizationId,\r\n    workspaceId,\r\n    period,\r\n    generationTime,\r\n    false,\r\n    dashboard\r\n  );\r\n  \r\n  return dashboard;\r\n}\r\n\r\n// ============================================================================\r\n// WORKFLOW ANALYTICS\r\n// ============================================================================\r\n\r\n/**\r\n * Get workflow analytics metrics\r\n */\r\nasync function getWorkflowMetrics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date,\r\n  previousDateRange: { start: Date; end: Date }\r\n): Promise<WorkflowOverviewMetrics> {\r\n  if (!adminDal) {\r\n    return {\r\n      totalActiveWorkflows: 0,\r\n      totalExecutions: 0,\r\n      successfulExecutions: 0,\r\n      failedExecutions: 0,\r\n      successRate: 0,\r\n      averageExecutionTime: 0,\r\n      totalActionsExecuted: 0,\r\n      executionsTrend: 0,\r\n      topWorkflows: [],\r\n      executionsByDay: [],\r\n      actionBreakdown: [],\r\n    };\r\n  }\r\n\r\n  // Get all workflows\r\n  const workflows = await adminDal.getAllWorkflows(organizationId, workspaceId);\r\n  const activeWorkflows = workflows.filter((w: Workflow) => w.status === 'active');\r\n  \r\n  // Get executions in current period\r\n  const executions = await adminDal.getWorkflowExecutions(\r\n    organizationId,\r\n    workspaceId,\r\n    startDate,\r\n    endDate\r\n  );\r\n  \r\n  // Get executions in previous period (for trend)\r\n  const previousExecutions = await adminDal.getWorkflowExecutions(\r\n    organizationId,\r\n    workspaceId,\r\n    previousDateRange.start,\r\n    previousDateRange.end\r\n  );\r\n  \r\n  // Calculate basic metrics\r\n  const totalExecutions = executions.length;\r\n  const successfulExecutions = executions.filter((e: WorkflowExecution) => e.status === 'completed').length;\r\n  const failedExecutions = executions.filter((e: WorkflowExecution) => e.status === 'failed').length;\r\n  const successRate = totalExecutions > 0 ? (successfulExecutions / totalExecutions) * 100 : 0;\r\n  \r\n  // Calculate average execution time\r\n  const executionTimes = executions\r\n    .filter((e: WorkflowExecution) => e.completedAt && e.startedAt)\r\n    .map((e: WorkflowExecution) => {\r\n      const start = toDate(e.startedAt);\r\n      const end = toDate(e.completedAt);\r\n      return end.getTime() - start.getTime();\r\n    });\r\n  \r\n  const averageExecutionTime = executionTimes.length > 0\r\n    ? executionTimes.reduce((sum, t) => sum + t, 0) / executionTimes.length\r\n    : 0;\r\n  \r\n  // Calculate total actions\r\n  const totalActionsExecuted = executions.reduce((sum, e: WorkflowExecution) => {\r\n    return sum + (e.actionsExecuted?.length || 0);\r\n  }, 0);\r\n  \r\n  // Calculate trend\r\n  const executionsTrend = previousExecutions.length > 0\r\n    ? ((totalExecutions - previousExecutions.length) / previousExecutions.length) * 100\r\n    : 0;\r\n  \r\n  // Get top workflows\r\n  const topWorkflows = calculateTopWorkflows(workflows, executions);\r\n  \r\n  // Get executions by day\r\n  const executionsByDay = generateTimeSeries(executions, startDate, endDate, (e: WorkflowExecution) => 1);\r\n  \r\n  // Get action breakdown\r\n  const actionBreakdown = calculateActionBreakdown(executions, totalActionsExecuted);\r\n  \r\n  return {\r\n    totalActiveWorkflows: activeWorkflows.length,\r\n    totalExecutions,\r\n    successfulExecutions,\r\n    failedExecutions,\r\n    successRate,\r\n    averageExecutionTime,\r\n    totalActionsExecuted,\r\n    executionsTrend,\r\n    topWorkflows,\r\n    executionsByDay,\r\n    actionBreakdown,\r\n  };\r\n}\r\n\r\n/**\r\n * Calculate top performing workflows\r\n */\r\nfunction calculateTopWorkflows(\r\n  workflows: Workflow[],\r\n  executions: WorkflowExecution[]\r\n): WorkflowPerformanceSummary[] {\r\n  const workflowMap = new Map<string, {\r\n    workflow: Workflow;\r\n    executions: WorkflowExecution[];\r\n  }>();\r\n  \r\n  // Group executions by workflow\r\n  executions.forEach((execution: WorkflowExecution) => {\r\n    const existing = workflowMap.get(execution.workflowId) || {\r\n      workflow: workflows.find((w: Workflow) => w.id === execution.workflowId)!,\r\n      executions: [],\r\n    };\r\n    \r\n    if (existing.workflow) {\r\n      existing.executions.push(execution);\r\n      workflowMap.set(execution.workflowId, existing);\r\n    }\r\n  });\r\n  \r\n  // Calculate metrics for each workflow\r\n  const summaries: WorkflowPerformanceSummary[] = Array.from(workflowMap.entries())\r\n    .map(([workflowId, data]) => {\r\n      const successCount = data.executions.filter(e => e.status === 'completed').length;\r\n      const successRate = data.executions.length > 0\r\n        ? (successCount / data.executions.length) * 100\r\n        : 0;\r\n      \r\n      const executionTimes = data.executions\r\n        .filter(e => e.completedAt && e.startedAt)\r\n        .map(e => {\r\n          const start = toDate(e.startedAt);\r\n          const end = toDate(e.completedAt);\r\n          return end.getTime() - start.getTime();\r\n        });\r\n      \r\n      const averageTime = executionTimes.length > 0\r\n        ? executionTimes.reduce((sum, t) => sum + t, 0) / executionTimes.length\r\n        : 0;\r\n      \r\n      // Estimate time saved (assume each execution saves 10 minutes)\r\n      const timeSaved = (data.executions.length * 10) / 60; // hours\r\n      \r\n      return {\r\n        workflowId,\r\n        name: data.workflow.name,\r\n        executions: data.executions.length,\r\n        successRate,\r\n        averageTime,\r\n        timeSaved,\r\n      };\r\n    })\r\n    .sort((a, b) => b.executions - a.executions)\r\n    .slice(0, 5);\r\n  \r\n  return summaries;\r\n}\r\n\r\n/**\r\n * Calculate action type breakdown\r\n */\r\nfunction calculateActionBreakdown(\r\n  executions: WorkflowExecution[],\r\n  totalActions: number\r\n): ActionTypeMetrics[] {\r\n  const actionMap = new Map<string, {\r\n    count: number;\r\n    success: number;\r\n    times: number[];\r\n  }>();\r\n  \r\n  executions.forEach((execution: WorkflowExecution) => {\r\n    const results = execution.actionsExecuted || [];\r\n    results.forEach((result: any) => {\r\n      const actionType = result.actionType || 'unknown';\r\n      const existing = actionMap.get(actionType) || {\r\n        count: 0,\r\n        success: 0,\r\n        times: [],\r\n      };\r\n      \r\n      actionMap.set(actionType, {\r\n        count: existing.count + 1,\r\n        success: existing.success + (result.status === 'success' ? 1 : 0),\r\n        times: [...existing.times, result.duration || 0],\r\n      });\r\n    });\r\n  });\r\n  \r\n  return Array.from(actionMap.entries())\r\n    .map(([actionType, data]) => ({\r\n      actionType,\r\n      count: data.count,\r\n      successRate: data.count > 0 ? (data.success / data.count) * 100 : 0,\r\n      averageTime: data.times.length > 0\r\n        ? data.times.reduce((sum, t) => sum + t, 0) / data.times.length\r\n        : 0,\r\n      percentage: totalActions > 0 ? (data.count / totalActions) * 100 : 0,\r\n    }))\r\n    .sort((a, b) => b.count - a.count);\r\n}\r\n\r\n// ============================================================================\r\n// EMAIL ANALYTICS\r\n// ============================================================================\r\n\r\n/**\r\n * Get email analytics metrics\r\n */\r\nasync function getEmailMetrics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date,\r\n  previousDateRange: { start: Date; end: Date }\r\n): Promise<EmailOverviewMetrics> {\r\n  if (!adminDal) {\r\n    return {\r\n      totalGenerated: 0,\r\n      totalSent: 0,\r\n      averageGenerationTime: 0,\r\n      mostUsedType: 'sales',\r\n      generationTrend: 0,\r\n      byType: [],\r\n      emailsByDay: [],\r\n      byTier: [],\r\n    };\r\n  }\r\n\r\n  // Get email generation events from Signal Bus or email writer logs\r\n  const emails = await adminDal.getEmailGenerations(\r\n    organizationId,\r\n    workspaceId,\r\n    startDate,\r\n    endDate\r\n  );\r\n  \r\n  const previousEmails = await adminDal.getEmailGenerations(\r\n    organizationId,\r\n    workspaceId,\r\n    previousDateRange.start,\r\n    previousDateRange.end\r\n  );\r\n  \r\n  const totalGenerated = emails.length;\r\n  const totalSent = emails.filter((e: any) => e.sent).length;\r\n  \r\n  // Calculate average generation time\r\n  const generationTimes = emails\r\n    .filter((e: any) => e.generationTime)\r\n    .map((e: any) => e.generationTime);\r\n  \r\n  const averageGenerationTime = generationTimes.length > 0\r\n    ? generationTimes.reduce((sum: number, t: number) => sum + t, 0) / generationTimes.length\r\n    : 0;\r\n  \r\n  // Get most used type\r\n  const typeCount = new Map<string, number>();\r\n  emails.forEach((e: any) => {\r\n    const type = e.type || 'unknown';\r\n    typeCount.set(type, (typeCount.get(type) || 0) + 1);\r\n  });\r\n  \r\n  const mostUsedType = Array.from(typeCount.entries())\r\n    .sort((a, b) => b[1] - a[1])[0]?.[0] || 'intro';\r\n  \r\n  // Calculate trend\r\n  const generationTrend = previousEmails.length > 0\r\n    ? ((totalGenerated - previousEmails.length) / previousEmails.length) * 100\r\n    : 0;\r\n  \r\n  // Get emails by type\r\n  const byType = calculateEmailsByType(emails, totalGenerated);\r\n  \r\n  // Get emails by day\r\n  const emailsByDay = generateTimeSeries(emails, startDate, endDate, () => 1);\r\n  \r\n  // Get emails by tier\r\n  const byTier = calculateEmailsByTier(emails, totalGenerated);\r\n  \r\n  return {\r\n    totalGenerated,\r\n    totalSent,\r\n    averageGenerationTime,\r\n    mostUsedType,\r\n    generationTrend,\r\n    byType,\r\n    emailsByDay,\r\n    byTier,\r\n  };\r\n}\r\n\r\n/**\r\n * Calculate emails by type\r\n */\r\nfunction calculateEmailsByType(emails: any[], total: number): EmailTypeMetrics[] {\r\n  const typeMap = new Map<string, { count: number; times: number[] }>();\r\n  \r\n  emails.forEach((email: any) => {\r\n    const type = email.type || 'unknown';\r\n    const existing = typeMap.get(type) || { count: 0, times: [] };\r\n    \r\n    typeMap.set(type, {\r\n      count: existing.count + 1,\r\n      times: [...existing.times, email.generationTime || 0],\r\n    });\r\n  });\r\n  \r\n  return Array.from(typeMap.entries())\r\n    .map(([type, data]) => ({\r\n      type,\r\n      count: data.count,\r\n      percentage: total > 0 ? (data.count / total) * 100 : 0,\r\n      averageTime: data.times.length > 0\r\n        ? data.times.reduce((sum, t) => sum + t, 0) / data.times.length\r\n        : 0,\r\n    }))\r\n    .sort((a, b) => b.count - a.count);\r\n}\r\n\r\n/**\r\n * Calculate emails by tier\r\n */\r\nfunction calculateEmailsByTier(emails: any[], total: number): TierDistribution[] {\r\n  const tierMap = new Map<string, number>();\r\n  \r\n  emails.forEach((email: any) => {\r\n    const tier = email.dealTier || 'unknown';\r\n    tierMap.set(tier, (tierMap.get(tier) || 0) + 1);\r\n  });\r\n  \r\n  return Array.from(tierMap.entries())\r\n    .map(([tier, count]) => ({\r\n      tier,\r\n      count,\r\n      percentage: total > 0 ? (count / total) * 100 : 0,\r\n    }))\r\n    .sort((a, b) => b.count - a.count);\r\n}\r\n\r\n// ============================================================================\r\n// DEAL ANALYTICS\r\n// ============================================================================\r\n\r\n/**\r\n * Get deal analytics metrics\r\n */\r\nasync function getDealMetrics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date,\r\n  previousDateRange: { start: Date; end: Date }\r\n): Promise<DealOverviewMetrics> {\r\n  if (!adminDal) {\r\n    return {\r\n      totalActiveDeals: 0,\r\n      totalValue: 0,\r\n      averageValue: 0,\r\n      hotDeals: 0,\r\n      atRiskDeals: 0,\r\n      dealsTrend: 0,\r\n      byStage: [],\r\n      byTier: [],\r\n      averageVelocity: 0,\r\n      pipelineByDay: [],\r\n    };\r\n  }\r\n\r\n  // Get all active deals\r\n  const deals = await adminDal.getActiveDeals(organizationId, workspaceId);\r\n  const previousDeals = await adminDal.getDealsSnapshot(\r\n    organizationId,\r\n    workspaceId,\r\n    previousDateRange.end\r\n  );\r\n  \r\n  const totalActiveDeals = deals.length;\r\n  const totalValue = deals.reduce((sum: number, d: any) => sum + (d.value || 0), 0);\r\n  const averageValue = totalActiveDeals > 0 ? totalValue / totalActiveDeals : 0;\r\n  \r\n  // Count hot and at-risk deals\r\n  const hotDeals = deals.filter((d: any) => d.tier === 'hot').length;\r\n  const atRiskDeals = deals.filter((d: any) => d.tier === 'at-risk').length;\r\n  \r\n  // Calculate trend\r\n  const dealsTrend = previousDeals.length > 0\r\n    ? ((totalActiveDeals - previousDeals.length) / previousDeals.length) * 100\r\n    : 0;\r\n  \r\n  // Get deals by stage\r\n  const byStage = calculateDealsByStage(deals);\r\n  \r\n  // Get deals by tier\r\n  const byTier = calculateDealsByTier(deals);\r\n  \r\n  // Calculate average velocity\r\n  const closedDeals = await adminDal.getClosedDeals(\r\n    organizationId,\r\n    workspaceId,\r\n    startDate,\r\n    endDate\r\n  );\r\n  const averageVelocity = calculateAverageVelocity(closedDeals);\r\n  \r\n  // Get pipeline by day\r\n  const pipelineByDay = await generateDealPipelineTimeSeries(\r\n    organizationId,\r\n    workspaceId,\r\n    startDate,\r\n    endDate\r\n  );\r\n  \r\n  return {\r\n    totalActiveDeals,\r\n    totalValue,\r\n    averageValue,\r\n    hotDeals,\r\n    atRiskDeals,\r\n    dealsTrend,\r\n    byStage,\r\n    byTier,\r\n    averageVelocity,\r\n    pipelineByDay,\r\n  };\r\n}\r\n\r\n/**\r\n * Calculate deals by stage\r\n */\r\nfunction calculateDealsByStage(deals: any[]): StageMetrics[] {\r\n  const stageMap = new Map<string, {\r\n    count: number;\r\n    value: number;\r\n    times: number[];\r\n  }>();\r\n  \r\n  deals.forEach((deal: any) => {\r\n    const stage = deal.stage || 'unknown';\r\n    const existing = stageMap.get(stage) || { count: 0, value: 0, times: [] };\r\n    \r\n    stageMap.set(stage, {\r\n      count: existing.count + 1,\r\n      value: existing.value + (deal.value || 0),\r\n      times: [...existing.times, deal.timeInStage || 0],\r\n    });\r\n  });\r\n  \r\n  const total = deals.length;\r\n  \r\n  return Array.from(stageMap.entries())\r\n    .map(([stage, data]) => ({\r\n      stage,\r\n      count: data.count,\r\n      value: data.value,\r\n      percentage: total > 0 ? (data.count / total) * 100 : 0,\r\n      averageTimeInStage: data.times.length > 0\r\n        ? data.times.reduce((sum, t) => sum + t, 0) / data.times.length\r\n        : 0,\r\n    }))\r\n    .sort((a, b) => b.count - a.count);\r\n}\r\n\r\n/**\r\n * Calculate deals by tier\r\n */\r\nfunction calculateDealsByTier(deals: any[]): TierMetrics[] {\r\n  const tierMap = new Map<string, {\r\n    count: number;\r\n    value: number;\r\n    scores: number[];\r\n  }>();\r\n  \r\n  deals.forEach((deal: any) => {\r\n    const tier = deal.tier || 'unknown';\r\n    const existing = tierMap.get(tier) || { count: 0, value: 0, scores: [] };\r\n    \r\n    tierMap.set(tier, {\r\n      count: existing.count + 1,\r\n      value: existing.value + (deal.value || 0),\r\n      scores: [...existing.scores, deal.score || 0],\r\n    });\r\n  });\r\n  \r\n  const total = deals.length;\r\n  \r\n  return Array.from(tierMap.entries())\r\n    .map(([tier, data]) => ({\r\n      tier,\r\n      count: data.count,\r\n      value: data.value,\r\n      percentage: total > 0 ? (data.count / total) * 100 : 0,\r\n      averageScore: data.scores.length > 0\r\n        ? data.scores.reduce((sum, s) => sum + s, 0) / data.scores.length\r\n        : 0,\r\n    }))\r\n    .sort((a, b) => {\r\n      const tierOrder: Record<string, number> = { hot: 0, warm: 1, cold: 2, 'at-risk': 3 };\r\n      return (tierOrder[a.tier] || 99) - (tierOrder[b.tier] || 99);\r\n    });\r\n}\r\n\r\n/**\r\n * Calculate average deal velocity (days to close)\r\n */\r\nfunction calculateAverageVelocity(closedDeals: any[]): number {\r\n  const velocities = closedDeals\r\n    .filter((d: any) => d.createdAt && d.closedAt)\r\n    .map((d: any) => {\r\n      const created = toDate(d.createdAt);\r\n      const closed = toDate(d.closedAt);\r\n      const days = (closed.getTime() - created.getTime()) / (1000 * 60 * 60 * 24);\r\n      return days;\r\n    });\r\n  \r\n  return velocities.length > 0\r\n    ? velocities.reduce((sum, v) => sum + v, 0) / velocities.length\r\n    : 0;\r\n}\r\n\r\n/**\r\n * Generate deal pipeline time series\r\n */\r\nasync function generateDealPipelineTimeSeries(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date\r\n): Promise<TimeSeriesDataPoint[]> {\r\n  // For now, return empty array - would need historical snapshots\r\n  // This could be enhanced with deal history tracking\r\n  return [];\r\n}\r\n\r\n// ============================================================================\r\n// REVENUE ANALYTICS\r\n// ============================================================================\r\n\r\n/**\r\n * Get revenue analytics metrics\r\n */\r\nasync function getRevenueMetrics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date,\r\n  previousDateRange: { start: Date; end: Date }\r\n): Promise<RevenueOverviewMetrics> {\r\n  if (!adminDal) {\r\n    return {\r\n      totalRevenue: 0,\r\n      quota: 0,\r\n      quotaAttainment: 0,\r\n      forecastOptimistic: 0,\r\n      forecastRealistic: 0,\r\n      forecastPessimistic: 0,\r\n      revenueTrend: 0,\r\n      revenueByDay: [],\r\n      winRate: 0,\r\n      averageDealSize: 0,\r\n    };\r\n  }\r\n\r\n  // Get closed/won deals in period\r\n  const wonDeals = await adminDal.getWonDeals(\r\n    organizationId,\r\n    workspaceId,\r\n    startDate,\r\n    endDate\r\n  );\r\n  \r\n  const previousWonDeals = await adminDal.getWonDeals(\r\n    organizationId,\r\n    workspaceId,\r\n    previousDateRange.start,\r\n    previousDateRange.end\r\n  );\r\n  \r\n  const totalRevenue = wonDeals.reduce((sum: number, d: any) => sum + (d.value || 0), 0);\r\n  const previousRevenue = previousWonDeals.reduce((sum: number, d: any) => sum + (d.value || 0), 0);\r\n  \r\n  // Get quota (would come from workspace settings)\r\n  const quota = 100000; // TODO: Get from workspace settings\r\n  const quotaAttainment = quota > 0 ? (totalRevenue / quota) * 100 : 0;\r\n  \r\n  // Get revenue forecast from forecasting engine\r\n  const forecast = await adminDal.getRevenueForecast(organizationId, workspaceId);\r\n  \r\n  // Calculate trend\r\n  const revenueTrend = previousRevenue > 0\r\n    ? ((totalRevenue - previousRevenue) / previousRevenue) * 100\r\n    : 0;\r\n  \r\n  // Get revenue by day\r\n  const revenueByDay = generateTimeSeries(\r\n    wonDeals,\r\n    startDate,\r\n    endDate,\r\n    (d: any) => d.value || 0\r\n  );\r\n  \r\n  // Calculate win rate\r\n  const allDeals = await adminDal.getClosedDeals(organizationId, workspaceId, startDate, endDate);\r\n  const winRate = allDeals.length > 0\r\n    ? (wonDeals.length / allDeals.length) * 100\r\n    : 0;\r\n  \r\n  // Calculate average deal size\r\n  const averageDealSize = wonDeals.length > 0\r\n    ? totalRevenue / wonDeals.length\r\n    : 0;\r\n  \r\n  return {\r\n    totalRevenue,\r\n    quota,\r\n    quotaAttainment,\r\n    forecastOptimistic: forecast?.optimistic || 0,\r\n    forecastRealistic: forecast?.realistic || 0,\r\n    forecastPessimistic: forecast?.pessimistic || 0,\r\n    revenueTrend,\r\n    revenueByDay,\r\n    winRate,\r\n    averageDealSize,\r\n  };\r\n}\r\n\r\n// ============================================================================\r\n// TEAM ANALYTICS\r\n// ============================================================================\r\n\r\n/**\r\n * Get team analytics metrics\r\n */\r\nasync function getTeamMetrics(\r\n  organizationId: string,\r\n  workspaceId: string,\r\n  startDate: Date,\r\n  endDate: Date\r\n): Promise<TeamOverviewMetrics> {\r\n  if (!adminDal) {\r\n    return {\r\n      totalReps: 0,\r\n      topPerformers: [],\r\n      averageDealsPerRep: 0,\r\n      averageQuotaAttainment: 0,\r\n      teamVelocity: 0,\r\n    };\r\n  }\r\n\r\n  const dal = adminDal; // Type narrowing for callbacks\r\n\r\n  // Get all reps (users with role 'sales')\r\n  const reps = await dal.getSalesReps(organizationId, workspaceId);\r\n  \r\n  // Get deals for each rep\r\n  const repDeals = await Promise.all(\r\n    reps.map((rep: any) =>\r\n      dal.getRepDeals(organizationId, workspaceId, rep.id, startDate, endDate)\r\n    )\r\n  );\r\n  \r\n  // Calculate rep performance\r\n  const repPerformance: RepPerformanceSummary[] = reps.map((rep: any, index: number) => {\r\n    const deals = repDeals[index] || [];\r\n    const wonDeals = deals.filter((d: any) => d.status === 'won');\r\n    const revenue = wonDeals.reduce((sum: number, d: any) => sum + (d.value || 0), 0);\r\n    const quota = rep.quota || 100000;\r\n    \r\n    return {\r\n      repId: rep.id,\r\n      repName: rep.name || rep.email,\r\n      deals: deals.length,\r\n      revenue,\r\n      quotaAttainment: quota > 0 ? (revenue / quota) * 100 : 0,\r\n      winRate: deals.length > 0 ? (wonDeals.length / deals.length) * 100 : 0,\r\n      averageDealSize: wonDeals.length > 0 ? revenue / wonDeals.length : 0,\r\n    };\r\n  });\r\n  \r\n  // Get top performers\r\n  const topPerformers = repPerformance\r\n    .sort((a, b) => b.revenue - a.revenue)\r\n    .slice(0, 5);\r\n  \r\n  // Calculate averages\r\n  const totalDeals = repPerformance.reduce((sum, r) => sum + r.deals, 0);\r\n  const averageDealsPerRep = reps.length > 0 ? totalDeals / reps.length : 0;\r\n  \r\n  const totalQuotaAttainment = repPerformance.reduce((sum, r) => sum + r.quotaAttainment, 0);\r\n  const averageQuotaAttainment = reps.length > 0 ? totalQuotaAttainment / reps.length : 0;\r\n  \r\n  // Calculate team velocity\r\n  const allRepDeals = repDeals.flat();\r\n  const teamVelocity = calculateAverageVelocity(allRepDeals);\r\n  \r\n  return {\r\n    totalReps: reps.length,\r\n    topPerformers,\r\n    averageDealsPerRep,\r\n    averageQuotaAttainment,\r\n    teamVelocity,\r\n  };\r\n}\r\n\r\n// ============================================================================\r\n// UTILITY FUNCTIONS\r\n// ============================================================================\r\n\r\n/**\r\n * Calculate date range based on period\r\n */\r\nfunction calculateDateRange(\r\n  period: TimePeriod,\r\n  customStart?: Date,\r\n  customEnd?: Date\r\n): { start: Date; end: Date } {\r\n  const now = new Date();\r\n  const end = customEnd || now;\r\n  let start: Date;\r\n  \r\n  switch (period) {\r\n    case '24h':\r\n      start = new Date(now.getTime() - 24 * 60 * 60 * 1000);\r\n      break;\r\n    case '7d':\r\n      start = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);\r\n      break;\r\n    case '30d':\r\n      start = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);\r\n      break;\r\n    case '90d':\r\n      start = new Date(now.getTime() - 90 * 24 * 60 * 60 * 1000);\r\n      break;\r\n    case 'month':\r\n      start = new Date(now.getFullYear(), now.getMonth(), 1);\r\n      break;\r\n    case 'quarter':\r\n      const quarter = Math.floor(now.getMonth() / 3);\r\n      start = new Date(now.getFullYear(), quarter * 3, 1);\r\n      break;\r\n    case 'year':\r\n      start = new Date(now.getFullYear(), 0, 1);\r\n      break;\r\n    case 'custom':\r\n      start = customStart || new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);\r\n      break;\r\n    default:\r\n      start = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);\r\n  }\r\n  \r\n  return { start, end };\r\n}\r\n\r\n/**\r\n * Calculate previous date range for comparison\r\n */\r\nfunction calculatePreviousDateRange(\r\n  start: Date,\r\n  end: Date\r\n): { start: Date; end: Date } {\r\n  const duration = end.getTime() - start.getTime();\r\n  return {\r\n    start: new Date(start.getTime() - duration),\r\n    end: start,\r\n  };\r\n}\r\n\r\n/**\r\n * Generate time series data\r\n */\r\nfunction generateTimeSeries<T>(\r\n  items: T[],\r\n  startDate: Date,\r\n  endDate: Date,\r\n  valueExtractor: (item: T) => number\r\n): TimeSeriesDataPoint[] {\r\n  const dayMap = new Map<string, number>();\r\n  \r\n  // Initialize all days with 0\r\n  const days = Math.ceil((endDate.getTime() - startDate.getTime()) / (1000 * 60 * 60 * 24));\r\n  for (let i = 0; i <= days; i++) {\r\n    const date = new Date(startDate.getTime() + i * 24 * 60 * 60 * 1000);\r\n    const key = date.toISOString().split('T')[0];\r\n    dayMap.set(key, 0);\r\n  }\r\n  \r\n  // Add item values\r\n  items.forEach((item: any) => {\r\n    const date = item.createdAt || item.startedAt || item.date;\r\n    if (date) {\r\n      const dateObj = toDate(date);\r\n      const key = dateObj.toISOString().split('T')[0];\r\n      const existing = dayMap.get(key) || 0;\r\n      dayMap.set(key, existing + valueExtractor(item));\r\n    }\r\n  });\r\n  \r\n  return Array.from(dayMap.entries())\r\n    .map(([dateKey, value]) => ({\r\n      date: new Date(dateKey),\r\n      value,\r\n    }))\r\n    .sort((a, b) => a.date.getTime() - b.date.getTime());\r\n}\r\n\r\n/**\r\n * Clear analytics cache\r\n */\r\nexport async function clearAnalyticsCache(reason: 'manual' | 'automatic' | 'expired' = 'manual', userId?: string): Promise<void> {\r\n  analyticsCache.clear();\r\n  \r\n  // Emit cache cleared event\r\n  const { emitCacheCleared } = await import('./events');\r\n  await emitCacheCleared(reason, userId);\r\n}\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\coaching\\coaching-analytics-engine.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":933,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":933,"endColumn":56}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Coaching Analytics Engine\n * \n * SOVEREIGN CORPORATE BRAIN - COACHING MODULE\n * \n * Core engine for analyzing sales rep performance across all metrics.\n * Aggregates data from deals, emails, activities, workflows, and revenue.\n * \n * CORE CAPABILITIES:\n * - Multi-source data aggregation (deals, emails, activities, workflows)\n * - Performance metric calculation (conversion, efficiency, skills)\n * - Team benchmarking and percentile rankings\n * - Trend analysis (improving vs declining)\n * - Skill scoring based on behavioral patterns\n * - Performance tier classification\n * \n * INTEGRATION:\n * - Admin DAL for Firestore queries\n * - Deal Scoring system\n * - Email Writer metrics\n * - Workflow Automation tracking\n * - Revenue Forecasting data\n */\n\nimport type { FirestoreAdminDAL } from '@/lib/firebase/admin-dal';\nimport { adminDb } from '@/lib/firebase/admin';\nimport type {\n  RepPerformanceMetrics,\n  DealPerformanceMetrics,\n  CommunicationMetrics,\n  ActivityMetrics,\n  ConversionMetrics,\n  RevenueMetrics,\n  EfficiencyMetrics,\n  SkillScores,\n  PerformanceComparison,\n  PerformanceTier,\n  TeamPerformanceSummary,\n  TimePeriod,\n  CustomDateRange\n} from './types';\nimport { logger } from '@/lib/logger/logger';\n\n// ============================================================================\n// ANALYTICS ENGINE CLASS\n// ============================================================================\n\nexport class CoachingAnalyticsEngine {\n  constructor(private adminDal: FirestoreAdminDAL) {}\n\n  /**\n   * Analyzes performance for a single sales rep\n   */\n  async analyzeRepPerformance(\n    repId: string,\n    period: TimePeriod,\n    customRange?: CustomDateRange\n  ): Promise<RepPerformanceMetrics> {\n    const startTime = Date.now();\n    \n    try {\n      // Get date range for analysis\n      const { startDate, endDate } = this.getDateRange(period, customRange);\n      \n      // Get rep info\n      const repDoc = await this.adminDal.getCollection('USERS').doc(repId).get();\n      if (!repDoc.exists) {\n        throw new Error(`Rep not found: ${repId}`);\n      }\n      \n      const repData = repDoc.data();\n      const repName = repData?.name || 'Unknown';\n      const repEmail = repData?.email ?? '';\n      \n      // Fetch all metrics in parallel\n      const [\n        deals,\n        communication,\n        activity,\n        conversion,\n        revenue,\n        efficiency,\n        teamMetrics\n      ] = await Promise.all([\n        this.analyzeDealMetrics(repId, startDate, endDate),\n        this.analyzeCommunicationMetrics(repId, startDate, endDate),\n        this.analyzeActivityMetrics(repId, startDate, endDate),\n        this.analyzeConversionMetrics(repId, startDate, endDate),\n        this.analyzeRevenueMetrics(repId, startDate, endDate),\n        this.analyzeEfficiencyMetrics(repId, startDate, endDate),\n        this.getTeamAverageMetrics(startDate, endDate)\n      ]);\n      \n      // Calculate skill scores\n      const skills = this.calculateSkillScores({\n        deals,\n        communication,\n        activity,\n        conversion,\n        revenue,\n        efficiency\n      });\n      \n      // Calculate overall performance score (weighted average)\n      const overallScore = this.calculateOverallScore({\n        deals,\n        communication,\n        activity,\n        conversion,\n        revenue,\n        efficiency,\n        skills\n      });\n      \n      // Determine performance tier\n      const tier = this.determinePerformanceTier(overallScore, deals.winRate, revenue.quotaAttainment);\n      \n      // Calculate comparison to team average\n      const vsTeamAverage = this.calculateTeamComparison(\n        { overallScore, deals, communication, activity, revenue, efficiency },\n        teamMetrics\n      );\n      \n      logger.info('Rep performance analysis completed', {\n        repId,\n        period,\n        overallScore,\n        tier,\n        durationMs: Date.now() - startTime\n      });\n      \n      return {\n        repId,\n        repName,\n        repEmail,\n        period,\n        startDate,\n        endDate,\n        deals,\n        communication,\n        activity,\n        conversion,\n        revenue,\n        efficiency,\n        skills,\n        overallScore,\n        tier,\n        vsTeamAverage\n      };\n    } catch (error) {\n      logger.error('Error analyzing rep performance', { repId, error });\n      throw error;\n    }\n  }\n\n  /**\n   * Analyzes deal performance metrics\n   */\n  private async analyzeDealMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<DealPerformanceMetrics> {\n    try {\n      // Query deals for this rep in the time period\n      const dealsRef = this.adminDal.getCollection('DEALS');\n      const snapshot = await dealsRef\n        .where('ownerId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const deals = snapshot.docs.map(doc => ({ id: doc.id, ...doc.data() } as any));\n      \n      const totalDeals = deals.length;\n      const activeDeals = deals.filter((d: any) => !['won', 'lost', 'closed'].includes(d.status ?? '')).length;\n      const dealsWon = deals.filter((d: any) => d.status === 'won').length;\n      const dealsLost = deals.filter((d: any) => d.status === 'lost').length;\n      const closedDeals = dealsWon + dealsLost;\n      const winRate = closedDeals > 0 ? dealsWon / closedDeals : 0;\n      \n      // Calculate average deal size\n      const wonDeals = deals.filter((d: any) => d.status === 'won');\n      const totalValue = wonDeals.reduce((sum: number, d: any) => sum + (d.value ?? 0), 0);\n      const averageDealSize = wonDeals.length > 0 ? totalValue / wonDeals.length : 0;\n      \n      // Calculate average deal cycle\n      const cycleTimes = wonDeals\n        .filter((d: any) => d.createdAt && d.closedAt)\n        .map((d: any) => {\n          const created = d.createdAt.toDate ? d.createdAt.toDate() : new Date(d.createdAt);\n          const closed = d.closedAt.toDate ? d.closedAt.toDate() : new Date(d.closedAt);\n          return (closed.getTime() - created.getTime()) / (1000 * 60 * 60 * 24);\n        });\n      const averageCycleDays = cycleTimes.length > 0\n        ? cycleTimes.reduce((sum, t) => sum + t, 0) / cycleTimes.length\n        : 0;\n      \n      // Calculate deal velocity (deals per week)\n      const periodDays = (endDate.getTime() - startDate.getTime()) / (1000 * 60 * 60 * 24);\n      const dealVelocity = periodDays > 0 ? (totalDeals / periodDays) * 7 : 0;\n      \n      // Count at-risk deals (using deal scoring data if available)\n      const atRiskDeals = deals.filter((d: any) => \n        d.healthScore !== undefined && d.healthScore < 50\n      ).length;\n      \n      // Health distribution\n      const healthDistribution = {\n        healthy: deals.filter((d: any) => d.healthScore >= 70).length,\n        warning: deals.filter((d: any) => d.healthScore >= 50 && d.healthScore < 70).length,\n        critical: deals.filter((d: any) => d.healthScore < 50).length\n      };\n      \n      return {\n        totalDeals,\n        activeDeals,\n        dealsWon,\n        dealsLost,\n        winRate,\n        averageDealSize,\n        averageCycleDays,\n        dealVelocity,\n        atRiskDeals,\n        healthDistribution\n      };\n    } catch (error) {\n      logger.error('Error analyzing deal metrics', { repId, error });\n      // Return zero metrics on error\n      return {\n        totalDeals: 0,\n        activeDeals: 0,\n        dealsWon: 0,\n        dealsLost: 0,\n        winRate: 0,\n        averageDealSize: 0,\n        averageCycleDays: 0,\n        dealVelocity: 0,\n        atRiskDeals: 0,\n        healthDistribution: { healthy: 0, warning: 0, critical: 0 }\n      };\n    }\n  }\n\n  /**\n   * Analyzes communication quality metrics\n   */\n  private async analyzeCommunicationMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<CommunicationMetrics> {\n    if (!adminDb) {\n      return {\n        emailsGenerated: 0,\n        emailsSent: 0,\n        emailResponseRate: 0,\n        averageResponseTime: 0,\n        aiEmailUsageRate: 0,\n        personalizationScore: 0,\n        followUpConsistency: 0,\n      };\n    }\n\n    try {\n      // Query email activities (using organization sub-collection pattern)\n      // This data may not exist yet, so we handle gracefully\n      const prefix = process.env.NODE_ENV === 'production' ? '' : 'test_';\n      const emailsRef = adminDb.collection(`${prefix}email_activities`);\n      const snapshot = await emailsRef\n        .where('userId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const emails = snapshot.docs.map(doc => doc.data() as any);\n      \n      const emailsGenerated = emails.filter((e: any) => e.type === 'generated').length;\n      const emailsSent = emails.filter((e: any) => e.type === 'sent').length;\n      \n      // Calculate response rate\n      const sentEmails = emails.filter((e: any) => e.type === 'sent');\n      const repliedEmails = sentEmails.filter((e: any) => e.replied === true).length;\n      const emailResponseRate = sentEmails.length > 0 ? repliedEmails / sentEmails.length : 0;\n      \n      // Calculate average response time (hours)\n      const responseTimes = emails\n        .filter((e: any) => e.sentAt && e.repliedAt)\n        .map((e: any) => {\n          const sent = e.sentAt.toDate ? e.sentAt.toDate() : new Date(e.sentAt);\n          const replied = e.repliedAt.toDate ? e.repliedAt.toDate() : new Date(e.repliedAt);\n          return (replied.getTime() - sent.getTime()) / (1000 * 60 * 60);\n        });\n      const averageResponseTime = responseTimes.length > 0\n        ? responseTimes.reduce((sum, t) => sum + t, 0) / responseTimes.length\n        : 0;\n      \n      // AI email usage rate\n      const aiEmailUsageRate = emailsSent > 0 ? emailsGenerated / emailsSent : 0;\n      \n      // Personalization score (based on custom instructions usage)\n      const personalizedEmails = emails.filter((e: any) => e.customInstructions && e.customInstructions.length > 10).length;\n      const personalizationScore = emailsSent > 0 ? (personalizedEmails / emailsSent) * 100 : 0;\n      \n      // Follow-up consistency (percentage of emails that are follow-ups)\n      const followUpEmails = emails.filter((e: any) => e.isFollowUp === true).length;\n      const followUpConsistency = emailsSent > 0 ? (followUpEmails / emailsSent) * 100 : 0;\n      \n      return {\n        emailsGenerated,\n        emailsSent,\n        emailResponseRate,\n        averageResponseTime,\n        aiEmailUsageRate,\n        personalizationScore,\n        followUpConsistency\n      };\n    } catch (error) {\n      logger.error('Error analyzing communication metrics', { repId, error });\n      return {\n        emailsGenerated: 0,\n        emailsSent: 0,\n        emailResponseRate: 0,\n        averageResponseTime: 0,\n        aiEmailUsageRate: 0,\n        personalizationScore: 0,\n        followUpConsistency: 0\n      };\n    }\n  }\n\n  /**\n   * Analyzes activity level metrics\n   */\n  private async analyzeActivityMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<ActivityMetrics> {\n    if (!adminDb) {\n      return {\n        totalActivities: 0,\n        activitiesPerDay: 0,\n        callsMade: 0,\n        meetingsHeld: 0,\n        tasksCompleted: 0,\n        taskCompletionRate: 0,\n        workflowsTriggered: 0,\n        crmUpdates: 0,\n      };\n    }\n\n    try {\n      // Query activities (using direct collection reference as ACTIVITIES may not be in enum)\n      const prefix = process.env.NODE_ENV === 'production' ? '' : 'test_';\n      const activitiesRef = adminDb.collection(`${prefix}activities`);\n      const snapshot = await activitiesRef\n        .where('userId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const activities = snapshot.docs.map(doc => doc.data() as any);\n      \n      const totalActivities = activities.length;\n      const periodDays = (endDate.getTime() - startDate.getTime()) / (1000 * 60 * 60 * 24);\n      const activitiesPerDay = periodDays > 0 ? totalActivities / periodDays : 0;\n      \n      const callsMade = activities.filter((a: any) => a.type === 'call').length;\n      const meetingsHeld = activities.filter((a: any) => a.type === 'meeting').length;\n      const tasksCompleted = activities.filter((a: any) => a.type === 'task' && a.completed).length;\n      const totalTasks = activities.filter((a: any) => a.type === 'task').length;\n      const taskCompletionRate = totalTasks > 0 ? tasksCompleted / totalTasks : 0;\n      \n      // Query workflow executions (reuse prefix from above)\n      const workflowsRef = adminDb.collection(`${prefix}workflow_executions`);\n      const workflowSnapshot = await workflowsRef\n        .where('triggeredBy', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      const workflowsTriggered = workflowSnapshot.size;\n      \n      // CRM updates (deal updates + contact updates)\n      const crmUpdates = activities.filter((a: any) => \n        ['deal_update', 'contact_update', 'note_added'].includes(a.type ?? '')\n      ).length;\n      \n      return {\n        totalActivities,\n        activitiesPerDay,\n        callsMade,\n        meetingsHeld,\n        tasksCompleted,\n        taskCompletionRate,\n        workflowsTriggered,\n        crmUpdates\n      };\n    } catch (error) {\n      logger.error('Error analyzing activity metrics', { repId, error });\n      return {\n        totalActivities: 0,\n        activitiesPerDay: 0,\n        callsMade: 0,\n        meetingsHeld: 0,\n        tasksCompleted: 0,\n        taskCompletionRate: 0,\n        workflowsTriggered: 0,\n        crmUpdates: 0\n      };\n    }\n  }\n\n  /**\n   * Analyzes conversion funnel metrics\n   */\n  private async analyzeConversionMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<ConversionMetrics> {\n    try {\n      // Query deals for conversion analysis\n      const dealsRef = this.adminDal.getCollection('DEALS');\n      const snapshot = await dealsRef\n        .where('ownerId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const deals = snapshot.docs.map(doc => doc.data() as any);\n      \n      // Count deals at each stage\n      const leadCount = deals.filter((d: any) => d.stage === 'lead' || d.stage === 'prospecting').length;\n      const opportunityCount = deals.filter((d: any) => \n        ['qualification', 'needs_analysis', 'discovery'].includes(d.stage ?? '')\n      ).length;\n      const proposalCount = deals.filter((d: any) => \n        ['proposal', 'negotiation'].includes(d.stage ?? '')\n      ).length;\n      const closedCount = deals.filter((d: any) => d.status === 'won').length;\n      \n      // Calculate conversion rates\n      const totalLeads = leadCount + opportunityCount + proposalCount + closedCount;\n      const leadToOpportunity = totalLeads > 0 \n        ? (opportunityCount + proposalCount + closedCount) / totalLeads \n        : 0;\n      const opportunityToProposal = (opportunityCount + proposalCount + closedCount) > 0\n        ? (proposalCount + closedCount) / (opportunityCount + proposalCount + closedCount)\n        : 0;\n      const proposalToClose = (proposalCount + closedCount) > 0\n        ? closedCount / (proposalCount + closedCount)\n        : 0;\n      const overallConversion = totalLeads > 0 ? closedCount / totalLeads : 0;\n      \n      // Identify drop-off points\n      const dropOffPoints = [\n        {\n          stage: 'Lead ‚Üí Opportunity',\n          dropOffRate: 1 - leadToOpportunity\n        },\n        {\n          stage: 'Opportunity ‚Üí Proposal',\n          dropOffRate: 1 - opportunityToProposal\n        },\n        {\n          stage: 'Proposal ‚Üí Close',\n          dropOffRate: 1 - proposalToClose\n        }\n      ].filter(point => point.dropOffRate > 0.3); // Only show significant drop-offs\n      \n      return {\n        leadToOpportunity,\n        opportunityToProposal,\n        proposalToClose,\n        overallConversion,\n        dropOffPoints\n      };\n    } catch (error) {\n      logger.error('Error analyzing conversion metrics', { repId, error });\n      return {\n        leadToOpportunity: 0,\n        opportunityToProposal: 0,\n        proposalToClose: 0,\n        overallConversion: 0,\n        dropOffPoints: []\n      };\n    }\n  }\n\n  /**\n   * Analyzes revenue performance metrics\n   */\n  private async analyzeRevenueMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<RevenueMetrics> {\n    try {\n      // Query deals for revenue analysis\n      const dealsRef = this.adminDal.getCollection('DEALS');\n      const snapshot = await dealsRef\n        .where('ownerId', '==', repId)\n        .get();\n      \n      const allDeals = snapshot.docs.map(doc => doc.data() as any);\n      \n      // Total revenue (won deals in period)\n      const wonDeals = allDeals.filter((d: any) => \n        d.status === 'won' && \n        d.closedAt &&\n        new Date(d.closedAt.toDate ? d.closedAt.toDate() : d.closedAt) >= startDate &&\n        new Date(d.closedAt.toDate ? d.closedAt.toDate() : d.closedAt) <= endDate\n      );\n      const totalRevenue = wonDeals.reduce((sum: number, d: any) => sum + (d.value ?? 0), 0);\n      \n      // Get quota from user profile\n      const repDoc = await this.adminDal.getCollection('USERS').doc(repId).get();\n      const quota = repDoc.data()?.quota ?? 0;\n      const quotaAttainment = quota > 0 ? totalRevenue / quota : 0;\n      \n      // Pipeline value (active deals)\n      const activeDeals = allDeals.filter((d: any) => \n        !['won', 'lost', 'closed'].includes(d.status ?? '')\n      );\n      const pipelineValue = activeDeals.reduce((sum: number, d: any) => sum + (d.value ?? 0), 0);\n      \n      // Weighted pipeline (value * probability)\n      const weightedPipeline = activeDeals.reduce((sum: number, d: any) => {\n        const value = d.value ?? 0;\n        const probability = d.winProbability ?? 0.5;\n        return sum + (value * probability);\n      }, 0);\n      \n      // Forecast accuracy (compare previous forecasts to actual)\n      const forecastAccuracy = 0.85; // Placeholder - would need historical forecast data\n      \n      // Average contract value\n      const acv = wonDeals.length > 0 ? totalRevenue / wonDeals.length : 0;\n      \n      // Growth rate (compare to previous period)\n      const previousPeriodStart = new Date(startDate);\n      previousPeriodStart.setTime(startDate.getTime() - (endDate.getTime() - startDate.getTime()));\n      const previousWonDeals = allDeals.filter((d: any) =>\n        d.status === 'won' &&\n        d.closedAt &&\n        new Date(d.closedAt.toDate ? d.closedAt.toDate() : d.closedAt) >= previousPeriodStart &&\n        new Date(d.closedAt.toDate ? d.closedAt.toDate() : d.closedAt) < startDate\n      );\n      const previousRevenue = previousWonDeals.reduce((sum: number, d: any) => sum + (d.value ?? 0), 0);\n      const growthRate = previousRevenue > 0 ? (totalRevenue - previousRevenue) / previousRevenue : 0;\n      \n      return {\n        totalRevenue,\n        quota,\n        quotaAttainment,\n        pipelineValue,\n        weightedPipeline,\n        forecastAccuracy,\n        acv,\n        growthRate\n      };\n    } catch (error) {\n      logger.error('Error analyzing revenue metrics', { repId, error });\n      return {\n        totalRevenue: 0,\n        quota: 0,\n        quotaAttainment: 0,\n        pipelineValue: 0,\n        weightedPipeline: 0,\n        forecastAccuracy: 0,\n        acv: 0,\n        growthRate: 0\n      };\n    }\n  }\n\n  /**\n   * Analyzes efficiency metrics\n   */\n  private async analyzeEfficiencyMetrics(\n    repId: string,\n    startDate: Date,\n    endDate: Date\n  ): Promise<EfficiencyMetrics> {\n    if (!adminDb || !this.adminDal) {\n      return {\n        timeToFirstContact: 0,\n        timeToProposal: 0,\n        timeToClose: 0,\n        meetingsPerDeal: 0,\n        emailsPerDeal: 0,\n        touchPointsPerDeal: 0,\n        automationUsage: 0,\n        hoursSaved: 0,\n      };\n    }\n\n    try {\n      // Get environment prefix once for all queries\n      const prefix = process.env.NODE_ENV === 'production' ? '' : 'test_';\n      \n      // Query deals for efficiency analysis\n      const dealsRef = this.adminDal.getCollection('DEALS');\n      const snapshot = await dealsRef\n        .where('ownerId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const deals = snapshot.docs.map(doc => doc.data() as any);\n      \n      // Time to first contact\n      const firstContactTimes = deals\n        .filter((d: any) => d.createdAt && d.firstContactAt)\n        .map((d: any) => {\n          const created = d.createdAt.toDate ? d.createdAt.toDate() : new Date(d.createdAt);\n          const contacted = d.firstContactAt.toDate ? d.firstContactAt.toDate() : new Date(d.firstContactAt);\n          return (contacted.getTime() - created.getTime()) / (1000 * 60 * 60);\n        });\n      const timeToFirstContact = firstContactTimes.length > 0\n        ? firstContactTimes.reduce((sum, t) => sum + t, 0) / firstContactTimes.length\n        : 0;\n      \n      // Time to proposal\n      const proposalTimes = deals\n        .filter((d: any) => d.createdAt && d.proposalSentAt)\n        .map((d: any) => {\n          const created = d.createdAt.toDate ? d.createdAt.toDate() : new Date(d.createdAt);\n          const proposal = d.proposalSentAt.toDate ? d.proposalSentAt.toDate() : new Date(d.proposalSentAt);\n          return (proposal.getTime() - created.getTime()) / (1000 * 60 * 60 * 24);\n        });\n      const timeToProposal = proposalTimes.length > 0\n        ? proposalTimes.reduce((sum, t) => sum + t, 0) / proposalTimes.length\n        : 0;\n      \n      // Time to close\n      const closeTimes = deals\n        .filter((d: any) => d.createdAt && d.closedAt && d.status === 'won')\n        .map((d: any) => {\n          const created = d.createdAt.toDate ? d.createdAt.toDate() : new Date(d.createdAt);\n          const closed = d.closedAt.toDate ? d.closedAt.toDate() : new Date(d.closedAt);\n          return (closed.getTime() - created.getTime()) / (1000 * 60 * 60 * 24);\n        });\n      const timeToClose = closeTimes.length > 0\n        ? closeTimes.reduce((sum, t) => sum + t, 0) / closeTimes.length\n        : 0;\n      \n      // Touch points per deal (meetings + emails)\n      const activitiesRef = adminDb.collection(`${prefix}activities`);\n      const activitiesSnapshot = await activitiesRef\n        .where('userId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      \n      const activities = activitiesSnapshot.docs.map(doc => doc.data() as any);\n      const meetingsPerDeal = deals.length > 0 \n        ? activities.filter((a: any) => a.type === 'meeting').length / deals.length \n        : 0;\n      const emailsPerDeal = deals.length > 0\n        ? activities.filter((a: any) => a.type === 'email').length / deals.length\n        : 0;\n      const touchPointsPerDeal = meetingsPerDeal + emailsPerDeal;\n      \n      // AI automation usage\n      const workflowsRef = adminDb.collection(`${prefix}workflow_executions`);\n      const workflowSnapshot = await workflowsRef\n        .where('triggeredBy', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      const workflowExecutions = workflowSnapshot.size;\n      const totalActivities = activities.length;\n      const automationUsage = totalActivities > 0 ? workflowExecutions / totalActivities : 0;\n      \n      // Hours saved (estimate: 5 min per workflow, 10 min per AI email)\n      const emailActivities = await adminDb.collection(`${prefix}email_activities`)\n        .where('userId', '==', repId)\n        .where('createdAt', '>=', startDate)\n        .where('createdAt', '<=', endDate)\n        .get();\n      const aiEmails = emailActivities.docs.filter(doc => (doc.data() as any).type === 'generated').length;\n      const hoursSaved = (workflowExecutions * 5 + aiEmails * 10) / 60;\n      \n      return {\n        timeToFirstContact,\n        timeToProposal,\n        timeToClose,\n        meetingsPerDeal,\n        emailsPerDeal,\n        touchPointsPerDeal,\n        automationUsage,\n        hoursSaved\n      };\n    } catch (error) {\n      logger.error('Error analyzing efficiency metrics', { repId, error });\n      return {\n        timeToFirstContact: 0,\n        timeToProposal: 0,\n        timeToClose: 0,\n        meetingsPerDeal: 0,\n        emailsPerDeal: 0,\n        touchPointsPerDeal: 0,\n        automationUsage: 0,\n        hoursSaved: 0\n      };\n    }\n  }\n\n  /**\n   * Calculates skill scores based on performance metrics\n   */\n  private calculateSkillScores(metrics: {\n    deals: DealPerformanceMetrics;\n    communication: CommunicationMetrics;\n    activity: ActivityMetrics;\n    conversion: ConversionMetrics;\n    revenue: RevenueMetrics;\n    efficiency: EfficiencyMetrics;\n  }): SkillScores {\n    const { deals, communication, activity, conversion, revenue, efficiency } = metrics;\n    \n    return {\n      // Prospecting: based on deal velocity and pipeline value\n      prospecting: Math.min(100, (deals.dealVelocity * 10 + (revenue.pipelineValue / 100000) * 20)),\n      \n      // Discovery: based on qualification and conversion\n      discovery: Math.min(100, conversion.leadToOpportunity * 100),\n      \n      // Needs analysis: based on conversion to proposal\n      needsAnalysis: Math.min(100, conversion.opportunityToProposal * 100),\n      \n      // Presentation: based on proposal to close rate\n      presentation: Math.min(100, conversion.proposalToClose * 100),\n      \n      // Objection handling: inferred from win rate\n      objectionHandling: Math.min(100, deals.winRate * 100),\n      \n      // Negotiation: based on average deal size vs pipeline\n      negotiation: Math.min(100, (deals.averageDealSize / 100000) * 50 + deals.winRate * 50),\n      \n      // Closing: based on win rate and quota attainment\n      closing: Math.min(100, (deals.winRate * 50 + revenue.quotaAttainment * 50)),\n      \n      // Relationship building: based on email response rate and follow-up\n      relationshipBuilding: Math.min(100, \n        communication.emailResponseRate * 50 + communication.followUpConsistency * 0.5\n      ),\n      \n      // Product knowledge: inferred from presentation and objection handling\n      productKnowledge: Math.min(100, (conversion.proposalToClose * 60 + deals.winRate * 40)),\n      \n      // CRM hygiene: based on activity logging\n      crmHygiene: Math.min(100, Math.min(activity.activitiesPerDay * 10, 100)),\n      \n      // Time management: based on efficiency metrics\n      timeManagement: Math.min(100, (1 / Math.max(efficiency.timeToClose / 30, 0.1)) * 50),\n      \n      // AI tool adoption: based on automation usage\n      aiToolAdoption: Math.min(100, \n        efficiency.automationUsage * 50 + communication.aiEmailUsageRate * 50\n      )\n    };\n  }\n\n  /**\n   * Calculates overall performance score (weighted average)\n   */\n  private calculateOverallScore(metrics: {\n    deals: DealPerformanceMetrics;\n    communication: CommunicationMetrics;\n    activity: ActivityMetrics;\n    conversion: ConversionMetrics;\n    revenue: RevenueMetrics;\n    efficiency: EfficiencyMetrics;\n    skills: SkillScores;\n  }): number {\n    const { deals, revenue, skills } = metrics;\n    \n    // Weighted score components\n    const components = [\n      { value: revenue.quotaAttainment * 100, weight: 0.30 }, // Quota attainment: 30%\n      { value: deals.winRate * 100, weight: 0.20 },           // Win rate: 20%\n      { value: Object.values(skills).reduce((a, b) => a + b, 0) / 12, weight: 0.30 }, // Skills avg: 30%\n      { value: Math.min(deals.dealVelocity * 20, 100), weight: 0.10 }, // Velocity: 10%\n      { value: Math.min(revenue.growthRate * 50 + 50, 100), weight: 0.10 } // Growth: 10%\n    ];\n    \n    const weightedSum = components.reduce((sum, comp) => sum + (comp.value * comp.weight), 0);\n    return Math.min(100, Math.max(0, weightedSum));\n  }\n\n  /**\n   * Determines performance tier based on overall score and key metrics\n   */\n  private determinePerformanceTier(\n    overallScore: number,\n    winRate: number,\n    quotaAttainment: number\n  ): PerformanceTier {\n    // Top performer: 85+ score AND (80%+ win rate OR 120%+ quota)\n    if (overallScore >= 85 && (winRate >= 0.8 || quotaAttainment >= 1.2)) {\n      return 'top_performer';\n    }\n    \n    // High performer: 70+ score AND (60%+ win rate OR 100%+ quota)\n    if (overallScore >= 70 && (winRate >= 0.6 || quotaAttainment >= 1.0)) {\n      return 'high_performer';\n    }\n    \n    // Average: 50-70 score\n    if (overallScore >= 50) {\n      return 'average';\n    }\n    \n    // Needs improvement: 30-50 score\n    if (overallScore >= 30) {\n      return 'needs_improvement';\n    }\n    \n    // At risk: < 30 score\n    return 'at_risk';\n  }\n\n  /**\n   * Gets team average metrics for benchmarking\n   */\n  private async getTeamAverageMetrics(\n    startDate: Date,\n    endDate: Date\n  ): Promise<any> {\n    try {\n      // Query all users with sales role\n      const usersRef = this.adminDal.getCollection('USERS');\n      const snapshot = await usersRef\n        .where('role', '==', 'sales')\n        .get();\n      \n      const userIds = snapshot.docs.map(doc => doc.id);\n      \n      if (userIds.length === 0) {\n        return this.getDefaultTeamMetrics();\n      }\n      \n      // Calculate metrics for all reps (simplified - in production, would cache these)\n      const metrics = {\n        overallScore: 65,\n        winRate: 0.45,\n        revenue: 50000,\n        activityPerDay: 12,\n        efficiency: 0.6\n      };\n      \n      return metrics;\n    } catch (error) {\n      logger.error('Error getting team average metrics', { error });\n      return this.getDefaultTeamMetrics();\n    }\n  }\n\n  /**\n   * Returns default team metrics\n   */\n  private getDefaultTeamMetrics() {\n    return {\n      overallScore: 60,\n      winRate: 0.40,\n      revenue: 40000,\n      activityPerDay: 10,\n      efficiency: 0.50\n    };\n  }\n\n  /**\n   * Calculates comparison to team average\n   */\n  private calculateTeamComparison(\n    repMetrics: any,\n    teamMetrics: any\n  ): PerformanceComparison {\n    const overallScoreDelta = repMetrics.overallScore - teamMetrics.overallScore;\n    const winRateDelta = repMetrics.deals.winRate - teamMetrics.winRate;\n    const revenueDelta = repMetrics.revenue.totalRevenue - teamMetrics.revenue;\n    const activityDelta = repMetrics.activity.activitiesPerDay - teamMetrics.activityPerDay;\n    const efficiencyDelta = repMetrics.efficiency.automationUsage - teamMetrics.efficiency;\n    \n    // Calculate percentile rank (simplified)\n    const percentileRank = Math.min(100, Math.max(0, 50 + overallScoreDelta));\n    \n    return {\n      overallScoreDelta,\n      winRateDelta,\n      revenueDelta,\n      activityDelta,\n      efficiencyDelta,\n      percentileRank\n    };\n  }\n\n  /**\n   * Gets date range for a time period\n   */\n  private getDateRange(\n    period: TimePeriod,\n    customRange?: CustomDateRange\n  ): { startDate: Date; endDate: Date } {\n    const now = new Date();\n    let startDate: Date;\n    const endDate: Date = now;\n    \n    if (period === 'custom' && customRange) {\n      return { startDate: customRange.startDate, endDate: customRange.endDate };\n    }\n    \n    switch (period) {\n      case 'last_7_days':\n        startDate = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);\n        break;\n      case 'last_30_days':\n        startDate = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);\n        break;\n      case 'last_90_days':\n        startDate = new Date(now.getTime() - 90 * 24 * 60 * 60 * 1000);\n        break;\n      case 'last_6_months':\n        startDate = new Date(now.getTime() - 180 * 24 * 60 * 60 * 1000);\n        break;\n      case 'last_12_months':\n        startDate = new Date(now.getTime() - 365 * 24 * 60 * 60 * 1000);\n        break;\n      case 'this_quarter':\n        const quarter = Math.floor(now.getMonth() / 3);\n        startDate = new Date(now.getFullYear(), quarter * 3, 1);\n        break;\n      case 'this_year':\n        startDate = new Date(now.getFullYear(), 0, 1);\n        break;\n      default:\n        startDate = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);\n    }\n    \n    return { startDate, endDate };\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\coaching\\team-coaching-engine.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":803,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":803,"endColumn":60}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Team Coaching Analytics Engine\n * \n * SOVEREIGN CORPORATE BRAIN - TEAM COACHING MODULE\n * \n * Aggregates individual rep performance into team-level insights for managers.\n * Identifies skill gaps, best practices to share, and coaching priorities.\n * \n * CORE CAPABILITIES:\n * - Team performance aggregation across all reps\n * - Skill gap analysis (team avg vs top performers)\n * - Top performer identification and best practice extraction\n * - At-risk rep identification with critical areas\n * - Team coaching priorities based on impact and urgency\n * - Performance distribution and trend analysis\n * \n * INTEGRATION:\n * - Coaching Analytics Engine for individual rep metrics\n * - AI Coaching Generator for insights generation\n * - Signal Bus for team coaching events\n * - Admin DAL for team member queries\n * \n * PERFORMANCE:\n * - Parallel processing of rep insights\n * - Intelligent caching (1-hour TTL)\n * - Batch AI calls to minimize cost\n */\n\nimport type {\n  TeamCoachingInsights,\n  TeamPerformanceSummary,\n  RepPerformanceMetrics,\n  PerformanceTier,\n  BestPractice,\n  SkillScores,\n  GenerateTeamCoachingRequest\n} from './types';\nimport type { CoachingAnalyticsEngine } from './coaching-analytics-engine';\nimport { createTeamInsightsGeneratedEvent } from './events';\nimport type { SignalCoordinator } from '../orchestration/SignalCoordinator';\n\n// ============================================================================\n// TEAM COACHING ENGINE\n// ============================================================================\n\nexport class TeamCoachingEngine {\n  private analyticsEngine: CoachingAnalyticsEngine;\n  private signalCoordinator?: SignalCoordinator;\n  \n  /**\n   * Cache for team insights (1-hour TTL)\n   * Key: `${teamId}:${period}:${startDate}:${endDate}`\n   */\n  private insightsCache: Map<string, {\n    insights: TeamCoachingInsights;\n    cachedAt: Date;\n  }> = new Map();\n  \n  /**\n   * Cache TTL in milliseconds (1 hour)\n   */\n  private readonly CACHE_TTL_MS = 60 * 60 * 1000;\n  \n  constructor(\n    analyticsEngine: CoachingAnalyticsEngine,\n    signalCoordinator?: SignalCoordinator\n  ) {\n    this.analyticsEngine = analyticsEngine;\n    this.signalCoordinator = signalCoordinator;\n  }\n  \n  // ============================================================================\n  // TEAM INSIGHTS GENERATION\n  // ============================================================================\n  \n  /**\n   * Generates team coaching insights for a manager\n   * @param request - Team coaching request\n   * @param teamMemberIds - Array of rep IDs on the team\n   * @param teamName - Name of the team\n   * @returns Team coaching insights\n   */\n  async generateTeamInsights(\n    request: GenerateTeamCoachingRequest,\n    teamMemberIds: string[],\n    teamName: string\n  ): Promise<TeamCoachingInsights> {\n    const startTime = Date.now();\n    \n    // Check cache first\n    const cacheKey = this.getCacheKey(\n      request.teamId,\n      request.period,\n      request.customRange?.startDate,\n      request.customRange?.endDate\n    );\n    \n    const cached = this.insightsCache.get(cacheKey);\n    if (cached && this.isCacheValid(cached.cachedAt)) {\n      console.log('[TeamCoachingEngine] Returning cached team insights');\n      return cached.insights;\n    }\n    \n    // Get date range\n    const { startDate, endDate } = this.getDateRange(\n      request.period,\n      request.customRange\n    );\n    \n    // Generate individual rep insights in parallel\n    console.log(`[TeamCoachingEngine] Generating insights for ${teamMemberIds.length} team members`);\n    const repInsights = await this.generateRepInsights(\n      teamMemberIds,\n      request.period,\n      { startDate, endDate }\n    );\n    \n    // Aggregate team metrics\n    const teamSummary = this.aggregateTeamMetrics(repInsights);\n    \n    // Identify top performers\n    const topPerformers = this.identifyTopPerformers(repInsights);\n    \n    // Identify reps needing support\n    const needsSupport = this.identifyRepsNeedingSupport(repInsights);\n    \n    // Analyze skill gaps\n    const skillGaps = this.analyzeSkillGaps(repInsights, topPerformers);\n    \n    // Extract best practices from top performers\n    const bestPracticesToShare = this.extractBestPractices(\n      repInsights,\n      topPerformers\n    );\n    \n    // Determine team coaching priorities\n    const teamPriorities = this.determineTeamPriorities(\n      skillGaps,\n      needsSupport,\n      teamSummary\n    );\n    \n    // Identify team-wide strengths and weaknesses\n    const teamStrengths = this.identifyTeamStrengths(repInsights, teamSummary);\n    const teamWeaknesses = this.identifyTeamWeaknesses(repInsights, teamSummary);\n    \n    // Build team insights\n    const teamInsights: TeamCoachingInsights = {\n      teamId: request.teamId,\n      teamName,\n      period: request.period,\n      startDate,\n      endDate,\n      generatedAt: new Date(),\n      teamSummary,\n      repInsights: request.includeRepDetails ? repInsights : [],\n      topPerformers,\n      needsSupport,\n      teamStrengths,\n      teamWeaknesses,\n      skillGaps,\n      bestPracticesToShare,\n      teamPriorities\n    };\n    \n    // Cache the results\n    this.insightsCache.set(cacheKey, {\n      insights: teamInsights,\n      cachedAt: new Date()\n    });\n    \n    // Emit Signal Bus event\n    const processingTimeMs = Date.now() - startTime;\n    if (this.signalCoordinator) {\n      const event = createTeamInsightsGeneratedEvent(\n        teamInsights,\n        'gpt-4o',\n        processingTimeMs\n      );\n      // Signal coordinator expects the full event object\n      await this.signalCoordinator.emitSignal(event as any);\n    }\n    \n    console.log(`[TeamCoachingEngine] Team insights generated in ${processingTimeMs}ms`);\n    return teamInsights;\n  }\n  \n  // ============================================================================\n  // REP INSIGHTS GENERATION\n  // ============================================================================\n  \n  /**\n   * Generates performance metrics for all reps on the team\n   * @param repIds - Array of rep IDs\n   * @param period - Time period\n   * @param dateRange - Date range\n   * @returns Array of rep performance metrics\n   */\n  private async generateRepInsights(\n    repIds: string[],\n    period: string,\n    dateRange: { startDate: Date; endDate: Date }\n  ): Promise<RepPerformanceMetrics[]> {\n    // Generate insights in parallel (with concurrency limit to avoid overwhelming API)\n    const BATCH_SIZE = 5;\n    const results: RepPerformanceMetrics[] = [];\n    \n    for (let i = 0; i < repIds.length; i += BATCH_SIZE) {\n      const batch = repIds.slice(i, i + BATCH_SIZE);\n      const batchResults = await Promise.all(\n        batch.map(repId =>\n          this.analyticsEngine.analyzeRepPerformance(\n            repId,\n            period as any,\n            dateRange\n          )\n        )\n      );\n      results.push(...batchResults);\n    }\n    \n    return results;\n  }\n  \n  // ============================================================================\n  // TEAM METRICS AGGREGATION\n  // ============================================================================\n  \n  /**\n   * Aggregates individual rep metrics into team summary\n   * @param repInsights - Array of rep performance metrics\n   * @returns Team performance summary\n   */\n  private aggregateTeamMetrics(\n    repInsights: RepPerformanceMetrics[]\n  ): TeamPerformanceSummary {\n    const totalReps = repInsights.length;\n    \n    // Calculate performance distribution\n    const tierCounts = new Map<PerformanceTier, number>();\n    for (const rep of repInsights) {\n      tierCounts.set(rep.tier, (tierCounts.get(rep.tier) || 0) + 1);\n    }\n    \n    const performanceDistribution = [\n      'top_performer',\n      'high_performer',\n      'average',\n      'needs_improvement',\n      'at_risk'\n    ].map((tier) => ({\n      tier: tier as PerformanceTier,\n      count: tierCounts.get(tier as PerformanceTier) || 0,\n      percentage: ((tierCounts.get(tier as PerformanceTier) || 0) / totalReps) * 100\n    }));\n    \n    // Calculate team averages\n    const teamAverages = {\n      overallScore: this.calculateAverage(repInsights.map(r => r.overallScore)),\n      winRate: this.calculateAverage(repInsights.map(r => r.deals.winRate)),\n      quotaAttainment: this.calculateAverage(repInsights.map(r => r.revenue.quotaAttainment)),\n      dealVelocity: this.calculateAverage(repInsights.map(r => r.deals.dealVelocity)),\n      emailResponseRate: this.calculateAverage(repInsights.map(r => r.communication.emailResponseRate))\n    };\n    \n    // Calculate trends (comparing to hypothetical previous period)\n    // In a real implementation, you would compare to actual historical data\n    const trends = [\n      {\n        metric: 'Overall Score',\n        direction: 'stable' as const,\n        change: 0\n      },\n      {\n        metric: 'Win Rate',\n        direction: 'stable' as const,\n        change: 0\n      },\n      {\n        metric: 'Quota Attainment',\n        direction: 'stable' as const,\n        change: 0\n      }\n    ];\n    \n    // Count at-risk reps\n    const atRiskCount = tierCounts.get('at_risk') || 0;\n    \n    // Calculate top performer benchmarks\n    const topPerformers = repInsights.filter(r =>\n      r.tier === 'top_performer' || r.tier === 'high_performer'\n    );\n    \n    const topPerformerBenchmarks = topPerformers.length > 0 ? [\n      {\n        metric: 'Overall Score',\n        value: this.calculateAverage(topPerformers.map(r => r.overallScore))\n      },\n      {\n        metric: 'Win Rate',\n        value: this.calculateAverage(topPerformers.map(r => r.deals.winRate))\n      },\n      {\n        metric: 'Quota Attainment',\n        value: this.calculateAverage(topPerformers.map(r => r.revenue.quotaAttainment))\n      },\n      {\n        metric: 'Deal Velocity',\n        value: this.calculateAverage(topPerformers.map(r => r.deals.dealVelocity))\n      },\n      {\n        metric: 'Email Response Rate',\n        value: this.calculateAverage(topPerformers.map(r => r.communication.emailResponseRate))\n      }\n    ] : [];\n    \n    return {\n      totalReps,\n      performanceDistribution,\n      teamAverages,\n      trends,\n      atRiskCount,\n      topPerformerBenchmarks\n    };\n  }\n  \n  // ============================================================================\n  // TOP PERFORMERS & AT-RISK IDENTIFICATION\n  // ============================================================================\n  \n  /**\n   * Identifies top performers on the team\n   * @param repInsights - Array of rep performance metrics\n   * @returns Top performers with their strengths\n   */\n  private identifyTopPerformers(\n    repInsights: RepPerformanceMetrics[]\n  ): Array<{ repId: string; repName: string; score: number; strengths: string[] }> {\n    return repInsights\n      .filter(r => r.tier === 'top_performer' || r.tier === 'high_performer')\n      .sort((a, b) => b.overallScore - a.overallScore)\n      .slice(0, 10) // Top 10\n      .map(rep => ({\n        repId: rep.repId,\n        repName: rep.repName,\n        score: rep.overallScore,\n        strengths: this.identifyRepStrengths(rep)\n      }));\n  }\n  \n  /**\n   * Identifies reps needing support\n   * @param repInsights - Array of rep performance metrics\n   * @returns Reps needing support with critical areas\n   */\n  private identifyRepsNeedingSupport(\n    repInsights: RepPerformanceMetrics[]\n  ): Array<{ repId: string; repName: string; score: number; criticalAreas: string[] }> {\n    return repInsights\n      .filter(r => r.tier === 'needs_improvement' || r.tier === 'at_risk')\n      .sort((a, b) => a.overallScore - b.overallScore)\n      .map(rep => ({\n        repId: rep.repId,\n        repName: rep.repName,\n        score: rep.overallScore,\n        criticalAreas: this.identifyRepWeaknesses(rep)\n      }));\n  }\n  \n  /**\n   * Identifies rep's key strengths based on skill scores\n   * @param rep - Rep performance metrics\n   * @returns Array of strength areas\n   */\n  private identifyRepStrengths(rep: RepPerformanceMetrics): string[] {\n    const skillEntries = Object.entries(rep.skills) as [keyof SkillScores, number][];\n    return skillEntries\n      .filter(([_, score]) => score >= 80)\n      .sort((a, b) => b[1] - a[1])\n      .slice(0, 3)\n      .map(([skill, _]) => this.formatSkillName(skill));\n  }\n  \n  /**\n   * Identifies rep's key weaknesses based on skill scores\n   * @param rep - Rep performance metrics\n   * @returns Array of weakness areas\n   */\n  private identifyRepWeaknesses(rep: RepPerformanceMetrics): string[] {\n    const skillEntries = Object.entries(rep.skills) as [keyof SkillScores, number][];\n    return skillEntries\n      .filter(([_, score]) => score < 60)\n      .sort((a, b) => a[1] - b[1])\n      .slice(0, 3)\n      .map(([skill, _]) => this.formatSkillName(skill));\n  }\n  \n  // ============================================================================\n  // SKILL GAP ANALYSIS\n  // ============================================================================\n  \n  /**\n   * Analyzes skill gaps across the team\n   * @param repInsights - Array of rep performance metrics\n   * @param topPerformers - Top performers data\n   * @returns Skill gaps with team avg vs top performer avg\n   */\n  private analyzeSkillGaps(\n    repInsights: RepPerformanceMetrics[],\n    topPerformers: Array<{ repId: string; repName: string; score: number; strengths: string[] }>\n  ): Array<{\n    skill: string;\n    teamAverage: number;\n    topPerformerAverage: number;\n    gap: number;\n    repsAffected: number;\n  }> {\n    const skills: (keyof SkillScores)[] = [\n      'prospecting',\n      'discovery',\n      'needsAnalysis',\n      'presentation',\n      'objectionHandling',\n      'negotiation',\n      'closing',\n      'relationshipBuilding',\n      'productKnowledge',\n      'crmHygiene',\n      'timeManagement',\n      'aiToolAdoption'\n    ];\n    \n    const topPerformerReps = repInsights.filter(r =>\n      topPerformers.some(tp => tp.repId === r.repId)\n    );\n    \n    return skills\n      .map(skill => {\n        const teamAverage = this.calculateAverage(\n          repInsights.map(r => r.skills[skill])\n        );\n        \n        const topPerformerAverage = topPerformerReps.length > 0\n          ? this.calculateAverage(topPerformerReps.map(r => r.skills[skill]))\n          : teamAverage;\n        \n        const gap = topPerformerAverage - teamAverage;\n        \n        const repsAffected = repInsights.filter(\n          r => r.skills[skill] < topPerformerAverage - 10\n        ).length;\n        \n        return {\n          skill: this.formatSkillName(skill),\n          teamAverage,\n          topPerformerAverage,\n          gap,\n          repsAffected\n        };\n      })\n      .filter(gap => gap.gap > 10) // Only include significant gaps\n      .sort((a, b) => b.gap - a.gap);\n  }\n  \n  // ============================================================================\n  // BEST PRACTICES EXTRACTION\n  // ============================================================================\n  \n  /**\n   * Extracts best practices from top performers\n   * @param repInsights - Array of rep performance metrics\n   * @param topPerformers - Top performers data\n   * @returns Best practices to share across team\n   */\n  private extractBestPractices(\n    repInsights: RepPerformanceMetrics[],\n    topPerformers: Array<{ repId: string; repName: string; score: number; strengths: string[] }>\n  ): BestPractice[] {\n    const practices: BestPractice[] = [];\n    \n    const topPerformerReps = repInsights.filter(r =>\n      topPerformers.some(tp => tp.repId === r.repId)\n    );\n    \n    if (topPerformerReps.length === 0) {return practices;}\n    \n    // Email response rate best practice\n    const avgEmailResponseRate = this.calculateAverage(\n      repInsights.map(r => r.communication.emailResponseRate)\n    );\n    const topEmailResponseRate = this.calculateAverage(\n      topPerformerReps.map(r => r.communication.emailResponseRate)\n    );\n    \n    if (topEmailResponseRate > avgEmailResponseRate + 0.1) {\n      practices.push({\n        title: 'Rapid Email Response Protocol',\n        description: 'Top performers respond to emails significantly faster, maintaining momentum in deals.',\n        category: 'communication',\n        topPerformers: topPerformers.slice(0, 3).map(tp => tp.repName),\n        successMetrics: [{\n          metric: 'Email Response Rate',\n          topPerformerAverage: topEmailResponseRate,\n          repCurrent: avgEmailResponseRate,\n          gap: topEmailResponseRate - avgEmailResponseRate\n        }],\n        implementationSteps: [\n          'Set up email notifications for high-priority deals',\n          'Block 2-3 time slots per day for email responses',\n          'Use AI email writer for faster replies',\n          'Respond within 2 hours for hot leads'\n        ],\n        expectedImpact: 'Improve email response rate by 15-20%, leading to faster deal progression'\n      });\n    }\n    \n    // Deal velocity best practice\n    const avgDealVelocity = this.calculateAverage(\n      repInsights.map(r => r.deals.dealVelocity)\n    );\n    const topDealVelocity = this.calculateAverage(\n      topPerformerReps.map(r => r.deals.dealVelocity)\n    );\n    \n    if (topDealVelocity > avgDealVelocity * 1.2) {\n      practices.push({\n        title: 'High-Velocity Deal Management',\n        description: 'Top performers move deals through the pipeline faster through disciplined qualification and follow-up.',\n        category: 'pipeline_management',\n        topPerformers: topPerformers.slice(0, 3).map(tp => tp.repName),\n        successMetrics: [{\n          metric: 'Deal Velocity',\n          topPerformerAverage: topDealVelocity,\n          repCurrent: avgDealVelocity,\n          gap: topDealVelocity - avgDealVelocity\n        }],\n        implementationSteps: [\n          'Qualify leads rigorously in first meeting',\n          'Set clear next steps at end of every meeting',\n          'Use workflow automation for timely follow-ups',\n          'Disqualify poor-fit deals early'\n        ],\n        expectedImpact: 'Increase deal velocity by 20-30%, closing more deals per quarter'\n      });\n    }\n    \n    // Win rate best practice\n    const avgWinRate = this.calculateAverage(\n      repInsights.map(r => r.deals.winRate)\n    );\n    const topWinRate = this.calculateAverage(\n      topPerformerReps.map(r => r.deals.winRate)\n    );\n    \n    if (topWinRate > avgWinRate + 0.15) {\n      practices.push({\n        title: 'Strategic Deal Qualification',\n        description: 'Top performers achieve higher win rates through better qualification and deal selection.',\n        category: 'discovery',\n        topPerformers: topPerformers.slice(0, 3).map(tp => tp.repName),\n        successMetrics: [{\n          metric: 'Win Rate',\n          topPerformerAverage: topWinRate,\n          repCurrent: avgWinRate,\n          gap: topWinRate - avgWinRate\n        }],\n        implementationSteps: [\n          'Use BANT/MEDDIC framework for qualification',\n          'Identify economic buyer early',\n          'Understand competitive landscape before presenting',\n          'Walk away from deals with poor fit'\n        ],\n        expectedImpact: 'Improve win rate by 10-15 percentage points, focusing effort on winnable deals'\n      });\n    }\n    \n    return practices.slice(0, 5); // Return top 5 practices\n  }\n  \n  // ============================================================================\n  // TEAM PRIORITIES\n  // ============================================================================\n  \n  /**\n   * Determines team coaching priorities based on skill gaps and at-risk reps\n   * @param skillGaps - Skill gaps across team\n   * @param needsSupport - Reps needing support\n   * @param teamSummary - Team performance summary\n   * @returns Prioritized coaching areas\n   */\n  private determineTeamPriorities(\n    skillGaps: Array<{ skill: string; teamAverage: number; topPerformerAverage: number; gap: number; repsAffected: number }>,\n    needsSupport: Array<{ repId: string; repName: string; score: number; criticalAreas: string[] }>,\n    teamSummary: TeamPerformanceSummary\n  ): Array<{\n    area: string;\n    importance: number;\n    repsAffected: number;\n    potentialImpact: string;\n  }> {\n    const priorities: Array<{\n      area: string;\n      importance: number;\n      repsAffected: number;\n      potentialImpact: string;\n    }> = [];\n    \n    // Priority 1: Support at-risk reps\n    if (teamSummary.atRiskCount > 0) {\n      priorities.push({\n        area: 'At-Risk Rep Support',\n        importance: 100,\n        repsAffected: teamSummary.atRiskCount,\n        potentialImpact: `${teamSummary.atRiskCount} rep(s) at risk of missing quota. Immediate 1-on-1 coaching required.`\n      });\n    }\n    \n    // Priority 2: Address largest skill gaps\n    skillGaps.slice(0, 3).forEach(gap => {\n      const importance = Math.min(100, 60 + gap.gap);\n      priorities.push({\n        area: gap.skill,\n        importance,\n        repsAffected: gap.repsAffected,\n        potentialImpact: `${gap.repsAffected} rep(s) below top performer benchmark. Gap of ${gap.gap.toFixed(1)} points could improve team ${gap.skill.toLowerCase()} significantly.`\n      });\n    });\n    \n    // Priority 3: Low quota attainment\n    if (teamSummary.teamAverages.quotaAttainment < 0.8) {\n      const repsBelow = Math.floor(teamSummary.totalReps * 0.6);\n      priorities.push({\n        area: 'Quota Attainment',\n        importance: 90,\n        repsAffected: repsBelow,\n        potentialImpact: `Team at ${(teamSummary.teamAverages.quotaAttainment * 100).toFixed(0)}% quota attainment. Focus on pipeline building and deal acceleration.`\n      });\n    }\n    \n    // Priority 4: Low win rate\n    if (teamSummary.teamAverages.winRate < 0.25) {\n      const repsBelow = Math.floor(teamSummary.totalReps * 0.5);\n      priorities.push({\n        area: 'Win Rate Improvement',\n        importance: 85,\n        repsAffected: repsBelow,\n        potentialImpact: `Team win rate at ${(teamSummary.teamAverages.winRate * 100).toFixed(0)}%. Better qualification and discovery needed.`\n      });\n    }\n    \n    return priorities.sort((a, b) => b.importance - a.importance).slice(0, 5);\n  }\n  \n  // ============================================================================\n  // TEAM STRENGTHS & WEAKNESSES\n  // ============================================================================\n  \n  /**\n   * Identifies team-wide strengths\n   * @param repInsights - Array of rep performance metrics\n   * @param teamSummary - Team performance summary\n   * @returns Team strengths\n   */\n  private identifyTeamStrengths(\n    repInsights: RepPerformanceMetrics[],\n    teamSummary: TeamPerformanceSummary\n  ): string[] {\n    const strengths: string[] = [];\n    \n    // High win rate\n    if (teamSummary.teamAverages.winRate > 0.35) {\n      strengths.push(`Strong Win Rate (${(teamSummary.teamAverages.winRate * 100).toFixed(0)}%)`);\n    }\n    \n    // High quota attainment\n    if (teamSummary.teamAverages.quotaAttainment > 0.9) {\n      strengths.push(`Excellent Quota Attainment (${(teamSummary.teamAverages.quotaAttainment * 100).toFixed(0)}%)`);\n    }\n    \n    // High email response rate\n    if (teamSummary.teamAverages.emailResponseRate > 0.7) {\n      strengths.push(`Responsive Communication (${(teamSummary.teamAverages.emailResponseRate * 100).toFixed(0)}% response rate)`);\n    }\n    \n    // High overall performance\n    if (teamSummary.teamAverages.overallScore > 75) {\n      strengths.push(`High Overall Performance (${teamSummary.teamAverages.overallScore.toFixed(0)} average score)`);\n    }\n    \n    // Strong top performers\n    const topPerformerPercentage = teamSummary.performanceDistribution\n      .filter(d => d.tier === 'top_performer' || d.tier === 'high_performer')\n      .reduce((sum, d) => sum + d.percentage, 0);\n    \n    if (topPerformerPercentage > 40) {\n      strengths.push(`${topPerformerPercentage.toFixed(0)}% of team are top/high performers`);\n    }\n    \n    return strengths;\n  }\n  \n  /**\n   * Identifies team-wide weaknesses\n   * @param repInsights - Array of rep performance metrics\n   * @param teamSummary - Team performance summary\n   * @returns Team weaknesses\n   */\n  private identifyTeamWeaknesses(\n    repInsights: RepPerformanceMetrics[],\n    teamSummary: TeamPerformanceSummary\n  ): string[] {\n    const weaknesses: string[] = [];\n    \n    // Low win rate\n    if (teamSummary.teamAverages.winRate < 0.25) {\n      weaknesses.push(`Low Win Rate (${(teamSummary.teamAverages.winRate * 100).toFixed(0)}%)`);\n    }\n    \n    // Low quota attainment\n    if (teamSummary.teamAverages.quotaAttainment < 0.7) {\n      weaknesses.push(`Below Quota Attainment (${(teamSummary.teamAverages.quotaAttainment * 100).toFixed(0)}%)`);\n    }\n    \n    // High at-risk count\n    if (teamSummary.atRiskCount > teamSummary.totalReps * 0.2) {\n      weaknesses.push(`${teamSummary.atRiskCount} rep(s) at risk (${((teamSummary.atRiskCount / teamSummary.totalReps) * 100).toFixed(0)}% of team)`);\n    }\n    \n    // Low email response rate\n    if (teamSummary.teamAverages.emailResponseRate < 0.5) {\n      weaknesses.push(`Poor Email Response Rate (${(teamSummary.teamAverages.emailResponseRate * 100).toFixed(0)}%)`);\n    }\n    \n    // Low deal velocity\n    if (teamSummary.teamAverages.dealVelocity < 0.5) {\n      weaknesses.push(`Low Deal Velocity (${teamSummary.teamAverages.dealVelocity.toFixed(1)} deals/week)`);\n    }\n    \n    return weaknesses;\n  }\n  \n  // ============================================================================\n  // UTILITY METHODS\n  // ============================================================================\n  \n  /**\n   * Calculates average of an array of numbers\n   * @param values - Array of numbers\n   * @returns Average value\n   */\n  private calculateAverage(values: number[]): number {\n    if (values.length === 0) {return 0;}\n    const sum = values.reduce((acc, val) => acc + val, 0);\n    return sum / values.length;\n  }\n  \n  /**\n   * Formats skill name for display\n   * @param skill - Skill key\n   * @returns Formatted skill name\n   */\n  private formatSkillName(skill: string): string {\n    return skill\n      .replace(/([A-Z])/g, ' $1')\n      .replace(/^./, str => str.toUpperCase())\n      .trim();\n  }\n  \n  /**\n   * Gets date range for a time period\n   * @param period - Time period\n   * @param customRange - Custom date range (if period is 'custom')\n   * @returns Start and end dates\n   */\n  private getDateRange(\n    period: string,\n    customRange?: { startDate: Date; endDate: Date }\n  ): { startDate: Date; endDate: Date } {\n    const endDate = new Date();\n    let startDate = new Date();\n    \n    if (period === 'custom' && customRange) {\n      return customRange;\n    }\n    \n    switch (period) {\n      case 'last_7_days':\n        startDate.setDate(endDate.getDate() - 7);\n        break;\n      case 'last_30_days':\n        startDate.setDate(endDate.getDate() - 30);\n        break;\n      case 'last_90_days':\n        startDate.setDate(endDate.getDate() - 90);\n        break;\n      case 'last_6_months':\n        startDate.setMonth(endDate.getMonth() - 6);\n        break;\n      case 'last_12_months':\n        startDate.setFullYear(endDate.getFullYear() - 1);\n        break;\n      case 'this_quarter':\n        const quarter = Math.floor(endDate.getMonth() / 3);\n        startDate = new Date(endDate.getFullYear(), quarter * 3, 1);\n        break;\n      case 'this_year':\n        startDate = new Date(endDate.getFullYear(), 0, 1);\n        break;\n      default:\n        startDate.setDate(endDate.getDate() - 30);\n    }\n    \n    return { startDate, endDate };\n  }\n  \n  /**\n   * Generates cache key for team insights\n   * @param teamId - Team ID\n   * @param period - Time period\n   * @param startDate - Start date (optional)\n   * @param endDate - End date (optional)\n   * @returns Cache key\n   */\n  private getCacheKey(\n    teamId: string,\n    period: string,\n    startDate?: Date,\n    endDate?: Date\n  ): string {\n    if (period === 'custom' && startDate && endDate) {\n      return `${teamId}:${period}:${startDate.toISOString()}:${endDate.toISOString()}`;\n    }\n    return `${teamId}:${period}`;\n  }\n  \n  /**\n   * Checks if cached insights are still valid\n   * @param cachedAt - When insights were cached\n   * @returns True if cache is valid\n   */\n  private isCacheValid(cachedAt: Date): boolean {\n    const age = Date.now() - cachedAt.getTime();\n    return age < this.CACHE_TTL_MS;\n  }\n  \n  /**\n   * Clears the insights cache\n   */\n  clearCache(): void {\n    this.insightsCache.clear();\n    console.log('[TeamCoachingEngine] Cache cleared');\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\conversation\\conversation-engine.ts","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\[.","line":631,"column":33,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":631,"endColumn":34,"suggestions":[{"messageId":"removeEscape","fix":{"range":[19856,19857],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[19856,19856],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\(.","line":631,"column":35,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":631,"endColumn":36,"suggestions":[{"messageId":"removeEscape","fix":{"range":[19858,19859],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[19858,19858],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\).","line":631,"column":45,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":631,"endColumn":46,"suggestions":[{"messageId":"removeEscape","fix":{"range":[19868,19869],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[19868,19868],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\).","line":631,"column":53,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":631,"endColumn":54,"suggestions":[{"messageId":"removeEscape","fix":{"range":[19876,19877],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[19876,19876],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\-.","line":631,"column":62,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":631,"endColumn":63,"suggestions":[{"messageId":"removeEscape","fix":{"range":[19885,19886],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[19885,19885],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":5,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Conversation Intelligence - Analysis Engine\n * \n * AI-powered analysis of sales conversations using GPT-4o.\n * Provides comprehensive insights including sentiment, talk ratio,\n * topics, objections, coaching, and follow-up recommendations.\n * \n * FEATURES:\n * - Transcript analysis with AI\n * - Sentiment tracking and critical moments\n * - Talk ratio calculation and assessment\n * - Topic extraction and coverage mapping\n * - Objection detection and handling evaluation\n * - Competitor mention tracking\n * - Coaching insights generation\n * - Follow-up action recommendations\n * \n * @module lib/conversation\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport { sendUnifiedChatMessage } from '@/lib/ai/unified-ai-service';\nimport { getServerSignalCoordinator } from '@/lib/orchestration/coordinator-factory-server';\nimport type {\n  Conversation,\n  ConversationAnalysis,\n  AnalyzeConversationRequest,\n  AnalyzeTranscriptRequest,\n  BatchAnalysisRequest,\n  BatchAnalysisResponse,\n  SentimentAnalysis,\n  TalkRatioAnalysis,\n  TopicAnalysis,\n  ObjectionAnalysis,\n  CompetitorMention,\n  KeyMoment,\n  CoachingInsight,\n  FollowUpAction,\n  ConversationScores,\n  QualityIndicator,\n  RedFlag,\n  PositiveSignal,\n  ConversationEngineConfig,\n  Participant,\n  ConversationType,\n  AnalysisSummary,\n} from './types';\nimport { DEFAULT_CONVERSATION_CONFIG } from './types';\n\n// ============================================================================\n// MAIN ANALYSIS FUNCTION\n// ============================================================================\n\n/**\n * Analyze a conversation and generate comprehensive insights\n * \n * @param request - Analysis request\n * @param config - Optional engine configuration\n * @returns Complete conversation analysis\n */\nexport async function analyzeConversation(\n  request: AnalyzeConversationRequest,\n  config: Partial<ConversationEngineConfig> = {}\n): Promise<ConversationAnalysis> {\n  const startTime = Date.now();\n  const fullConfig: ConversationEngineConfig = { ...DEFAULT_CONVERSATION_CONFIG, ...config };\n  \n  try {\n    logger.info('Analyzing conversation', {\n      conversationId: request.conversationId,\n      organizationId: request.organizationId,\n      includeCoaching: request.includeCoaching,\n    });\n    \n    // 1. Get conversation data\n    const conversation = await getConversation(\n      request.organizationId,\n      request.conversationId,\n      request.workspaceId || 'default'\n    );\n    \n    if (!conversation) {\n      throw new Error(`Conversation not found: ${request.conversationId}`);\n    }\n    \n    if (!conversation.transcript || conversation.transcript.length < fullConfig.minTranscriptLength) {\n      throw new Error('Conversation transcript is missing or too short');\n    }\n    \n    // 2. Perform AI-powered analysis\n    const analysis = await analyzeTranscript({\n      organizationId: request.organizationId,\n      workspaceId: request.workspaceId,\n      transcript: conversation.transcript,\n      conversationType: conversation.type,\n      participants: conversation.participants,\n      repId: conversation.repId,\n      duration: conversation.duration,\n      dealId: conversation.dealId,\n      leadId: conversation.leadId,\n      title: conversation.title,\n      includeCoaching: request.includeCoaching,\n      includeFollowUps: request.includeFollowUps,\n      customContext: request.customContext,\n    }, fullConfig);\n    \n    logger.info('Conversation analysis complete', {\n      conversationId: request.conversationId,\n      overallScore: analysis.scores.overall,\n      processingTime: Date.now() - startTime,\n    });\n    \n    // 3. Emit signal for analysis completion\n    await emitAnalysisSignal(analysis, conversation);\n    \n    return analysis;\n    \n  } catch (error: any) {\n    logger.error('Conversation analysis failed', error, {\n      conversationId: request.conversationId,\n      organizationId: request.organizationId,\n    });\n    throw new Error(`Conversation analysis failed: ${error.message}`);\n  }\n}\n\n/**\n * Analyze raw transcript directly\n * \n * @param request - Transcript analysis request\n * @param config - Engine configuration\n * @returns Conversation analysis\n */\nexport async function analyzeTranscript(\n  request: AnalyzeTranscriptRequest,\n  config: ConversationEngineConfig = DEFAULT_CONVERSATION_CONFIG\n): Promise<ConversationAnalysis> {\n  const startTime = Date.now();\n  \n  try {\n    // 1. Build AI prompt\n    const prompt = buildAnalysisPrompt(request);\n    \n    // 2. Call AI for comprehensive analysis\n    const response = await sendUnifiedChatMessage({\n      model: config.aiModel,\n      messages: [{ role: 'user', content: prompt }],\n      temperature: config.temperature,\n      maxTokens: config.maxTokens,\n    });\n    \n    // 3. Parse AI response\n    const aiAnalysis = parseAIAnalysis(response.text);\n    \n    // 4. Calculate talk ratio (deterministic, not AI-based)\n    const talkRatio = calculateTalkRatio(\n      request.transcript,\n      request.participants,\n      request.repId,\n      request.duration,\n      config\n    );\n    \n    // 5. Calculate scores\n    const scores = calculateScores(aiAnalysis, talkRatio);\n    \n    // 6. Identify quality indicators\n    const qualityIndicators = identifyQualityIndicators(\n      aiAnalysis,\n      talkRatio,\n      scores\n    );\n    \n    // 7. Extract red flags and positive signals\n    const redFlags = extractRedFlags(aiAnalysis, qualityIndicators);\n    const positiveSignals = extractPositiveSignals(aiAnalysis);\n    \n    // 8. Generate coaching insights (if requested)\n    let coachingInsights: CoachingInsight[] = [];\n    if (request.includeCoaching) {\n      coachingInsights = await generateCoachingInsights(\n        aiAnalysis,\n        talkRatio,\n        scores,\n        request.customContext,\n        config\n      );\n    }\n    \n    // 9. Generate follow-up actions (if requested)\n    let followUpActions: FollowUpAction[] = [];\n    if (request.includeFollowUps) {\n      followUpActions = await generateFollowUpActions(\n        aiAnalysis,\n        request.conversationType,\n        request.customContext,\n        config\n      );\n    }\n    \n    // 10. Build complete analysis\n    const analysis: ConversationAnalysis = {\n      conversationId: `analysis_${Date.now()}`, // Will be updated if saving\n      organizationId: request.organizationId,\n      workspaceId: request.workspaceId || 'default',\n      \n      sentiment: aiAnalysis.sentiment,\n      talkRatio,\n      topics: aiAnalysis.topics,\n      objections: aiAnalysis.objections,\n      competitors: aiAnalysis.competitors,\n      \n      keyMoments: aiAnalysis.keyMoments,\n      coachingInsights,\n      followUpActions,\n      \n      scores,\n      qualityIndicators,\n      redFlags,\n      positiveSignals,\n      \n      summary: aiAnalysis.summary,\n      highlights: aiAnalysis.highlights,\n      \n      confidence: aiAnalysis.confidence,\n      analyzedAt: new Date(),\n      analysisVersion: '1.0.0',\n      aiModel: config.aiModel,\n      tokensUsed: response.usage?.totalTokens ?? 0,\n      processingTime: Date.now() - startTime,\n    };\n    \n    return analysis;\n    \n  } catch (error: any) {\n    logger.error('Transcript analysis failed', error, {\n      organizationId: request.organizationId,\n    });\n    throw new Error(`Transcript analysis failed: ${error.message}`);\n  }\n}\n\n/**\n * Analyze multiple conversations in batch\n */\nexport async function analyzeBatchConversations(\n  request: BatchAnalysisRequest,\n  config: Partial<ConversationEngineConfig> = {}\n): Promise<BatchAnalysisResponse> {\n  const startTime = Date.now();\n  \n  try {\n    logger.info('Batch conversation analysis started', {\n      conversationCount: request.conversationIds.length,\n      organizationId: request.organizationId,\n    });\n    \n    const analyses = new Map<string, ConversationAnalysis>();\n    \n    // Analyze each conversation\n    for (const conversationId of request.conversationIds) {\n      try {\n        const analysis = await analyzeConversation(\n          {\n            conversationId,\n            organizationId: request.organizationId,\n            workspaceId: request.workspaceId,\n            includeCoaching: request.includeCoaching,\n            includeFollowUps: request.includeFollowUps,\n          },\n          config\n        );\n        \n        analyses.set(conversationId, analysis);\n      } catch (error: any) {\n        logger.warn('Failed to analyze conversation', {\n          conversationId,\n          error: error.message,\n        });\n      }\n    }\n    \n    // Calculate summary\n    const summary = calculateAnalysisSummary(analyses);\n    \n    logger.info('Batch conversation analysis complete', {\n      totalConversations: request.conversationIds.length,\n      successful: analyses.size,\n      duration: Date.now() - startTime,\n    });\n    \n    return {\n      analyses,\n      summary,\n      analyzedAt: new Date(),\n    };\n    \n  } catch (error: any) {\n    logger.error('Batch conversation analysis failed', error, {\n      organizationId: request.organizationId,\n    });\n    throw new Error(`Batch conversation analysis failed: ${error.message}`);\n  }\n}\n\n// ============================================================================\n// AI PROMPT BUILDING\n// ============================================================================\n\n/**\n * Build AI prompt for conversation analysis\n */\nfunction buildAnalysisPrompt(request: AnalyzeTranscriptRequest): string {\n  const repInfo = request.participants.find(p => p.id === request.repId);\n  const prospects = request.participants.filter(p => \n    p.role === 'prospect' || p.role === 'decision_maker' || p.role === 'influencer'\n  );\n  \n  return `You are an expert sales conversation analyst. Analyze this sales conversation and provide comprehensive insights.\n\nCONVERSATION METADATA:\n- Type: ${request.conversationType}\n- Title: ${request.title || 'Untitled'}\n- Duration: ${Math.floor(request.duration / 60)} minutes\n- Sales Rep: ${repInfo?.name || 'Unknown'}\n- Prospects: ${prospects.map(p => `${p.name} (${p.role}${p.title ? `, ${  p.title}` : ''})`).join(', ')}\n${request.customContext ? `\\nADDITIONAL CONTEXT:\\n${request.customContext}\\n` : ''}\n\nTRANSCRIPT:\n${request.transcript}\n\nAnalyze this conversation and provide a JSON response with the following structure:\n\n{\n  \"sentiment\": {\n    \"overall\": {\n      \"polarity\": \"positive\" | \"negative\" | \"neutral\" | \"very_positive\" | \"very_negative\",\n      \"score\": -1 to 1,\n      \"confidence\": 0-100,\n      \"tone\": [\"professional\", \"enthusiastic\", \"hesitant\", etc.]\n    },\n    \"byParticipant\": {\n      \"participantName\": { /* same as overall */ }\n    },\n    \"timeline\": [\n      { \"timestamp\": seconds, \"sentiment\": -1 to 1, \"speaker\": \"name\", \"context\": \"...\" }\n    ],\n    \"trendDirection\": \"improving\" | \"declining\" | \"stable\",\n    \"criticalMoments\": [\n      {\n        \"timestamp\": seconds,\n        \"type\": \"spike\" | \"drop\",\n        \"magnitude\": number,\n        \"speaker\": \"name\",\n        \"quote\": \"...\",\n        \"context\": \"...\",\n        \"impact\": \"high\" | \"medium\" | \"low\"\n      }\n    ]\n  },\n  \n  \"topics\": {\n    \"mainTopics\": [\n      {\n        \"name\": \"topic name\",\n        \"category\": \"pain_points\" | \"business_value\" | \"pricing\" | \"timeline\" | \"competition\" | \"stakeholders\" | \"decision_process\" | etc.,\n        \"mentions\": number,\n        \"duration\": seconds,\n        \"sentiment\": -1 to 1,\n        \"importance\": \"critical\" | \"high\" | \"medium\" | \"low\",\n        \"quotes\": [\"relevant quote 1\", \"relevant quote 2\"]\n      }\n    ],\n    \"coverageMap\": { \"topic\": durationInSeconds },\n    \"uncoveredTopics\": [\"expected topic that wasn't discussed\"],\n    \"timeAllocation\": [\n      {\n        \"topic\": \"name\",\n        \"duration\": seconds,\n        \"percentage\": 0-100,\n        \"isAppropriate\": boolean,\n        \"recommendation\": \"...\"\n      }\n    ]\n  },\n  \n  \"objections\": [\n    {\n      \"id\": \"unique_id\",\n      \"type\": \"pricing\" | \"timing\" | \"authority\" | \"competition\" | \"technical\" | \"trust\" | \"need\" | \"urgency\",\n      \"objection\": \"summary\",\n      \"quote\": \"exact quote\",\n      \"timestamp\": seconds,\n      \"speaker\": \"name\",\n      \"severity\": \"critical\" | \"high\" | \"medium\" | \"low\",\n      \"wasAddressed\": boolean,\n      \"repResponse\": \"...\",\n      \"responseQuality\": \"excellent\" | \"good\" | \"poor\" | \"none\",\n      \"recommendedResponse\": \"...\"\n    }\n  ],\n  \n  \"competitors\": [\n    {\n      \"competitor\": \"name\",\n      \"mentions\": number,\n      \"context\": [\"quote 1\", \"quote 2\"],\n      \"sentiment\": -1 to 1,\n      \"concernLevel\": \"high\" | \"medium\" | \"low\",\n      \"recommendedResponse\": \"...\"\n    }\n  ],\n  \n  \"keyMoments\": [\n    {\n      \"id\": \"unique_id\",\n      \"timestamp\": seconds,\n      \"type\": \"buying_signal\" | \"objection\" | \"commitment\" | \"concern\" | \"decision_maker_engagement\" | \"competitor_mention\" | \"timeline_discussed\" | \"budget_revealed\" | \"next_steps_agreed\" | \"red_flag\",\n      \"title\": \"brief title\",\n      \"description\": \"detailed description\",\n      \"speaker\": \"name\",\n      \"quote\": \"exact quote\",\n      \"impact\": \"positive\" | \"negative\" | \"neutral\",\n      \"significance\": \"critical\" | \"high\" | \"medium\" | \"low\"\n    }\n  ],\n  \n  \"summary\": \"2-3 sentence summary of the conversation\",\n  \"highlights\": [\"key highlight 1\", \"key highlight 2\", \"key highlight 3\"],\n  \"confidence\": 0-100 (how confident you are in this analysis)\n}\n\nFocus on actionable insights. Be specific and use exact quotes. Identify both strengths and areas for improvement.`;\n}\n\n// ============================================================================\n// AI RESPONSE PARSING\n// ============================================================================\n\n/**\n * Parse AI analysis response\n */\nfunction parseAIAnalysis(aiResponse: string): any {\n  try {\n    // Extract JSON from response\n    const jsonMatch = aiResponse.match(/\\{[\\s\\S]*\\}/);\n    if (!jsonMatch) {\n      throw new Error('No JSON found in AI response');\n    }\n    \n    const parsed = JSON.parse(jsonMatch[0]);\n    \n    // Validate required fields\n    if (!parsed.sentiment || !parsed.topics || !parsed.summary) {\n      throw new Error('Missing required fields in AI response');\n    }\n    \n    return {\n      sentiment: parsed.sentiment,\n      topics: parsed.topics,\n      objections: parsed.objections ?? [],\n      competitors: parsed.competitors ?? [],\n      keyMoments: parsed.keyMoments ?? [],\n      summary: parsed.summary,\n      highlights: parsed.highlights ?? [],\n      confidence: parsed.confidence || 75,\n    };\n    \n  } catch (error: any) {\n    logger.error('Failed to parse AI analysis', { error: error.message });\n    \n    // Return minimal fallback\n    return {\n      sentiment: {\n        overall: {\n          polarity: 'neutral',\n          score: 0,\n          confidence: 50,\n          tone: ['unknown'],\n        },\n        byParticipant: {},\n        timeline: [],\n        trendDirection: 'stable',\n        criticalMoments: [],\n      },\n      topics: {\n        mainTopics: [],\n        coverageMap: {},\n        uncoveredTopics: [],\n        timeAllocation: [],\n      },\n      objections: [],\n      competitors: [],\n      keyMoments: [],\n      summary: 'Analysis failed to parse AI response',\n      highlights: [],\n      confidence: 30,\n    };\n  }\n}\n\n// ============================================================================\n// TALK RATIO CALCULATION\n// ============================================================================\n\n/**\n * Calculate talk ratio from transcript\n */\nfunction calculateTalkRatio(\n  transcript: string,\n  participants: Participant[],\n  repId: string,\n  duration: number,\n  config: ConversationEngineConfig\n): TalkRatioAnalysis {\n  try {\n    // Parse transcript into turns\n    const turns = parseTranscriptTurns(transcript, participants);\n    \n    // Calculate per-participant stats\n    const byParticipant: Record<string, any> = {};\n    let repTalkTime = 0;\n    let prospectTalkTime = 0;\n    \n    participants.forEach(participant => {\n      const participantTurns = turns.filter(t => t.speakerId === participant.id);\n      const totalTime = participantTurns.reduce((sum, turn) => sum + turn.duration, 0);\n      const questionCount = participantTurns.filter(t => t.isQuestion).length;\n      \n      const stats = {\n        totalTime,\n        percentage: duration > 0 ? Math.round((totalTime / duration) * 100) : 0,\n        turnCount: participantTurns.length,\n        avgTurnDuration: participantTurns.length > 0 ? totalTime / participantTurns.length : 0,\n        longestTurn: Math.max(0, ...participantTurns.map(t => t.duration)),\n        interruptionCount: participantTurns.filter(t => t.wasInterruption).length,\n        questionCount,\n      };\n      \n      byParticipant[participant.id] = stats;\n      \n      // Track rep vs prospect time\n      if (participant.id === repId || participant.role === 'sales_rep' || participant.role === 'sales_manager') {\n        repTalkTime += totalTime;\n      } else if (participant.role === 'prospect' || participant.role === 'decision_maker' || participant.role === 'influencer') {\n        prospectTalkTime += totalTime;\n      }\n    });\n    \n    // Calculate overall ratio\n    const totalTalkTime = repTalkTime + prospectTalkTime;\n    const repPercentage = totalTalkTime > 0 ? Math.round((repTalkTime / totalTalkTime) * 100) : 0;\n    const prospectPercentage = totalTalkTime > 0 ? Math.round((prospectTalkTime / totalTalkTime) * 100) : 0;\n    const ratio = prospectTalkTime > 0 ? repTalkTime / prospectTalkTime : 1;\n    \n    // Assess talk ratio\n    const repRatio = totalTalkTime > 0 ? repTalkTime / totalTalkTime : 0.5;\n    let assessment: any;\n    let recommendation: string;\n    \n    if (repRatio >= config.idealTalkRatioMin && repRatio <= config.idealTalkRatioMax) {\n      assessment = 'ideal';\n      recommendation = 'Excellent talk ratio! Continue listening actively and asking thoughtful questions.';\n    } else if (repRatio > 0.5) {\n      assessment = 'rep_dominating';\n      recommendation = 'You\\'re talking too much. Focus on asking more questions and letting the prospect share their challenges.';\n    } else if (repRatio < 0.2) {\n      assessment = 'prospect_dominating';\n      recommendation = 'Good listening, but try to guide the conversation more. Ask clarifying questions and share relevant insights.';\n    } else if (repRatio >= 0.4 && repRatio <= 0.5) {\n      assessment = 'balanced';\n      recommendation = 'Good balance. Aim for slightly more listening to reach the ideal 30-40% talk time.';\n    } else {\n      assessment = 'needs_improvement';\n      recommendation = 'Work on finding the right talk/listen balance. Aim for 30-40% of the conversation.';\n    }\n    \n    return {\n      overall: {\n        speakerTime: repTalkTime,\n        listenerTime: prospectTalkTime,\n        ratio,\n        isIdeal: assessment === 'ideal',\n      },\n      byParticipant,\n      repTalkTime,\n      prospectTalkTime,\n      repPercentage,\n      prospectPercentage,\n      assessment,\n      recommendation,\n    };\n    \n  } catch (error: any) {\n    logger.error('Talk ratio calculation failed', { error: error.message });\n    \n    // Return default/fallback\n    return {\n      overall: {\n        speakerTime: 0,\n        listenerTime: 0,\n        ratio: 1,\n        isIdeal: false,\n      },\n      byParticipant: {},\n      repTalkTime: 0,\n      prospectTalkTime: 0,\n      repPercentage: 50,\n      prospectPercentage: 50,\n      assessment: 'needs_improvement',\n      recommendation: 'Unable to calculate talk ratio from transcript',\n    };\n  }\n}\n\n/**\n * Parse transcript into individual speaking turns\n */\nfunction parseTranscriptTurns(transcript: string, participants: Participant[]): any[] {\n  const turns: any[] = [];\n  \n  // Common transcript formats:\n  // \"Speaker Name: text\"\n  // \"[Speaker Name]: text\"\n  // \"Speaker Name - text\"\n  \n  const lines = transcript.split('\\n').filter(line => line.trim().length > 0);\n  \n  lines.forEach((line, index) => {\n    // Try to extract speaker name\n    const match = line.match(/^[\\[\\(]?([^:\\]\\)]+)[\\]\\)]?\\s*[:\\-]\\s*(.+)$/);\n    \n    if (match) {\n      const speakerName = match[1].trim();\n      const text = match[2].trim();\n      \n      // Find matching participant\n      const participant = participants.find(p => \n        p.name.toLowerCase().includes(speakerName.toLowerCase()) ||\n        speakerName.toLowerCase().includes(p.name.toLowerCase())\n      );\n      \n      if (participant) {\n        // Estimate duration (rough: ~150 words per minute, ~2.5 words per second)\n        const wordCount = text.split(/\\s+/).length;\n        const estimatedDuration = wordCount / 2.5;\n        \n        turns.push({\n          speakerId: participant.id,\n          speakerName: participant.name,\n          text,\n          wordCount,\n          duration: estimatedDuration,\n          isQuestion: text.includes('?'),\n          wasInterruption: false, // Hard to detect from transcript alone\n        });\n      }\n    }\n  });\n  \n  return turns;\n}\n\n// ============================================================================\n// SCORING\n// ============================================================================\n\n/**\n * Calculate conversation scores\n */\nfunction calculateScores(aiAnalysis: any, talkRatio: TalkRatioAnalysis): ConversationScores {\n  // Overall sentiment score (convert -1 to 1 ‚Üí 0 to 100)\n  const sentimentScore = Math.round(((aiAnalysis.sentiment.overall.score + 1) / 2) * 100);\n  \n  // Talk ratio score\n  const talkRatioScore = talkRatio.assessment === 'ideal' ? 95 :\n                         talkRatio.assessment === 'balanced' ? 80 :\n                         talkRatio.assessment === 'needs_improvement' ? 60 :\n                         talkRatio.assessment === 'rep_dominating' ? 40 : 50;\n  \n  // Discovery score (based on questions and topics covered)\n  const questioningScore = 70; // Would analyze question quality from transcript\n  const topicsCovered = aiAnalysis.topics.mainTopics.length;\n  const discoveryScore = Math.min(100, Math.round((topicsCovered * 10) + (questioningScore * 0.7)));\n  \n  // Objection handling score\n  const totalObjections = aiAnalysis.objections.length;\n  const addressedObjections = aiAnalysis.objections.filter((obj: any) => obj.wasAddressed).length;\n  const objectionScore = totalObjections > 0 \n    ? Math.round((addressedObjections / totalObjections) * 100)\n    : 80; // No objections = good\n  \n  // Closing score (based on next steps and commitments)\n  const hasNextSteps = aiAnalysis.keyMoments.some((m: any) => m.type === 'next_steps_agreed');\n  const hasCommitment = aiAnalysis.keyMoments.some((m: any) => m.type === 'commitment');\n  const closingScore = hasNextSteps && hasCommitment ? 90 :\n                       hasNextSteps ? 75 :\n                       hasCommitment ? 70 : 50;\n  \n  // Rapport score (based on sentiment and engagement)\n  const rapportScore = Math.max(50, sentimentScore);\n  \n  // Engagement score (positive signals - red flags)\n  const positiveSignals = aiAnalysis.keyMoments.filter((m: any) => m.impact === 'positive').length;\n  const negativeSignals = aiAnalysis.keyMoments.filter((m: any) => m.impact === 'negative').length;\n  const engagementScore = Math.min(100, Math.max(30, 70 + (positiveSignals * 5) - (negativeSignals * 10)));\n  \n  // Overall score (weighted average)\n  const overallScore = Math.round(\n    discoveryScore * 0.25 +\n    objectionScore * 0.2 +\n    closingScore * 0.2 +\n    rapportScore * 0.15 +\n    engagementScore * 0.1 +\n    talkRatioScore * 0.1\n  );\n  \n  return {\n    overall: overallScore,\n    discovery: discoveryScore,\n    valueArticulation: 75, // Would need more specific analysis\n    objectionHandling: objectionScore,\n    closing: closingScore,\n    rapport: rapportScore,\n    engagement: engagementScore,\n  };\n}\n\n// ============================================================================\n// QUALITY INDICATORS\n// ============================================================================\n\n/**\n * Identify quality indicators\n */\nfunction identifyQualityIndicators(\n  aiAnalysis: any,\n  talkRatio: TalkRatioAnalysis,\n  scores: ConversationScores\n): QualityIndicator[] {\n  const indicators: QualityIndicator[] = [];\n  \n  // Talk ratio indicator\n  indicators.push({\n    type: 'talk_ratio',\n    status: talkRatio.assessment === 'ideal' ? 'excellent' :\n            talkRatio.assessment === 'balanced' ? 'good' :\n            talkRatio.assessment === 'needs_improvement' ? 'needs_improvement' : 'poor',\n    score: talkRatio.overall.isIdeal ? 95 : 60,\n    description: `Rep spoke ${talkRatio.repPercentage}% of the time`,\n    recommendation: talkRatio.recommendation,\n  });\n  \n  // Discovery depth indicator\n  const topicCount = aiAnalysis.topics.mainTopics.length;\n  indicators.push({\n    type: 'discovery_depth',\n    status: topicCount >= 5 ? 'excellent' :\n            topicCount >= 3 ? 'good' :\n            topicCount >= 2 ? 'needs_improvement' : 'poor',\n    score: Math.min(100, topicCount * 20),\n    description: `Covered ${topicCount} key topics`,\n    recommendation: topicCount < 3 ? 'Ask more open-ended questions to uncover additional pain points and requirements' : undefined,\n  });\n  \n  // Next steps clarity indicator\n  const hasNextSteps = aiAnalysis.keyMoments.some((m: any) => m.type === 'next_steps_agreed');\n  indicators.push({\n    type: 'next_steps_clarity',\n    status: hasNextSteps ? 'excellent' : 'poor',\n    score: hasNextSteps ? 100 : 30,\n    description: hasNextSteps ? 'Clear next steps defined' : 'No clear next steps',\n    recommendation: hasNextSteps ? undefined : 'Always end calls with specific next steps and timeline',\n  });\n  \n  // Objection handling indicator\n  const objectionCount = aiAnalysis.objections.length;\n  const handledCount = aiAnalysis.objections.filter((obj: any) => obj.wasAddressed).length;\n  if (objectionCount > 0) {\n    indicators.push({\n      type: 'objection_handling',\n      status: handledCount === objectionCount ? 'excellent' :\n              handledCount >= objectionCount * 0.7 ? 'good' :\n              handledCount >= objectionCount * 0.5 ? 'needs_improvement' : 'poor',\n      score: Math.round((handledCount / objectionCount) * 100),\n      description: `Addressed ${handledCount}/${objectionCount} objections`,\n      recommendation: handledCount < objectionCount ? 'Acknowledge and address all objections before moving forward' : undefined,\n    });\n  }\n  \n  return indicators;\n}\n\n// ============================================================================\n// RED FLAGS & POSITIVE SIGNALS\n// ============================================================================\n\n/**\n * Extract red flags from analysis\n */\nfunction extractRedFlags(aiAnalysis: any, qualityIndicators: QualityIndicator[]): RedFlag[] {\n  const redFlags: RedFlag[] = [];\n  \n  // No next steps\n  const hasNextSteps = aiAnalysis.keyMoments.some((m: any) => m.type === 'next_steps_agreed');\n  if (!hasNextSteps) {\n    redFlags.push({\n      type: 'no_next_steps',\n      severity: 'critical',\n      description: 'Call ended without clear next steps',\n      recommendation: 'Always establish concrete next actions and timeline before ending the call',\n    });\n  }\n  \n  // Multiple unaddressed objections\n  const unaddressedObjections = aiAnalysis.objections.filter((obj: any) => !obj.wasAddressed);\n  if (unaddressedObjections.length >= 2) {\n    redFlags.push({\n      type: 'multiple_objections',\n      severity: 'high',\n      description: `${unaddressedObjections.length} objections left unaddressed`,\n      recommendation: 'Circle back to acknowledge and address all concerns',\n    });\n  }\n  \n  // Competitor preference\n  const competitorConcerns = aiAnalysis.competitors.filter((c: any) => c.concernLevel === 'high');\n  if (competitorConcerns.length > 0) {\n    redFlags.push({\n      type: 'competitor_preference',\n      severity: 'high',\n      description: `Strong preference indicated for: ${competitorConcerns.map((c: any) => c.competitor).join(', ')}`,\n      recommendation: 'Use battlecard to differentiate and highlight unique value proposition',\n    });\n  }\n  \n  // Negative sentiment trend\n  if (aiAnalysis.sentiment.trendDirection === 'declining') {\n    redFlags.push({\n      type: 'low_engagement',\n      severity: 'medium',\n      description: 'Prospect engagement declined during conversation',\n      recommendation: 'Re-engage by asking about their specific challenges and desired outcomes',\n    });\n  }\n  \n  return redFlags;\n}\n\n/**\n * Extract positive signals from analysis\n */\nfunction extractPositiveSignals(aiAnalysis: any): PositiveSignal[] {\n  const signals: PositiveSignal[] = [];\n  \n  // Buying intent\n  const buyingSignals = aiAnalysis.keyMoments.filter((m: any) => m.type === 'buying_signal');\n  buyingSignals.forEach((signal: any) => {\n    signals.push({\n      type: 'buying_intent',\n      strength: signal.significance === 'critical' ? 'strong' : \n                signal.significance === 'high' ? 'moderate' : 'weak',\n      description: signal.description,\n      quote: signal.quote,\n      timestamp: signal.timestamp,\n      impact: 'Strong indicator of purchase intent',\n    });\n  });\n  \n  // Decision maker engaged\n  const dmEngagement = aiAnalysis.keyMoments.filter((m: any) => m.type === 'decision_maker_engagement');\n  if (dmEngagement.length > 0) {\n    signals.push({\n      type: 'decision_maker_engaged',\n      strength: 'strong',\n      description: 'Decision maker actively participated',\n      impact: 'Direct access to economic buyer increases close probability',\n    });\n  }\n  \n  // Clear pain point\n  const painTopics = aiAnalysis.topics.mainTopics.filter((t: any) => t.category === 'pain_points');\n  if (painTopics.length > 0) {\n    signals.push({\n      type: 'clear_pain_point',\n      strength: painTopics.length >= 2 ? 'strong' : 'moderate',\n      description: `Identified ${painTopics.length} clear pain point(s)`,\n      impact: 'Strong pain points drive purchase urgency',\n    });\n  }\n  \n  // Positive sentiment\n  if (aiAnalysis.sentiment.overall.score > 0.5) {\n    signals.push({\n      type: 'value_acknowledged',\n      strength: 'moderate',\n      description: 'Overall positive sentiment throughout conversation',\n      impact: 'Prospect is receptive to the solution',\n    });\n  }\n  \n  return signals;\n}\n\n// ============================================================================\n// COACHING INSIGHTS GENERATION\n// ============================================================================\n\n/**\n * Generate coaching insights with AI\n */\nasync function generateCoachingInsights(\n  aiAnalysis: any,\n  talkRatio: TalkRatioAnalysis,\n  scores: ConversationScores,\n  customContext: string | undefined,\n  config: ConversationEngineConfig\n): Promise<CoachingInsight[]> {\n  try {\n    const prompt = buildCoachingPrompt(aiAnalysis, talkRatio, scores, customContext);\n    \n    const response = await sendUnifiedChatMessage({\n      model: config.aiModel,\n      messages: [{ role: 'user', content: prompt }],\n      temperature: 0.7,\n      maxTokens: 2000,\n    });\n    \n    const insights = parseCoachingInsights(response.text, config.maxCoachingInsights);\n    \n    return insights;\n    \n  } catch (error: any) {\n    logger.error('Coaching insights generation failed', { error: error.message });\n    return [];\n  }\n}\n\n/**\n * Build coaching prompt\n */\nfunction buildCoachingPrompt(\n  aiAnalysis: any,\n  talkRatio: TalkRatioAnalysis,\n  scores: ConversationScores,\n  customContext?: string\n): string {\n  return `You are a sales coaching expert. Analyze this conversation and provide actionable coaching insights.\n\nCONVERSATION ANALYSIS:\n- Overall Score: ${scores.overall}/100\n- Discovery Score: ${scores.discovery}/100\n- Objection Handling: ${scores.objectionHandling}/100\n- Closing Score: ${scores.closing}/100\n- Talk Ratio: ${talkRatio.repPercentage}% rep, ${talkRatio.prospectPercentage}% prospect (${talkRatio.assessment})\n- Sentiment: ${aiAnalysis.sentiment.overall.polarity} (${aiAnalysis.sentiment.overall.score})\n- Topics Covered: ${aiAnalysis.topics.mainTopics.length}\n- Objections: ${aiAnalysis.objections.length}\n- Key Moments: ${aiAnalysis.keyMoments.length}\n${customContext ? `\\nCONTEXT:\\n${customContext}\\n` : ''}\n\nProvide 3-5 coaching insights as a JSON array:\n\n[\n  {\n    \"id\": \"unique_id\",\n    \"category\": \"discovery\" | \"listening\" | \"objection_handling\" | \"value_articulation\" | \"questioning\" | \"closing\" | \"rapport_building\" | \"time_management\",\n    \"priority\": \"critical\" | \"high\" | \"medium\" | \"low\",\n    \"insight\": \"One sentence insight\",\n    \"whatWentWell\": \"What the rep did well (if applicable)\",\n    \"whatToImprove\": \"Specific improvement area\",\n    \"specificExample\": \"Quote or specific moment from conversation\",\n    \"recommendedAction\": \"Concrete action to take\",\n    \"skillArea\": \"Specific skill to develop\",\n    \"impact\": 0-100 (potential impact of improvement)\n  }\n]\n\nFocus on the highest-impact improvements. Be specific and actionable.`;\n}\n\n/**\n * Parse coaching insights from AI response\n */\nfunction parseCoachingInsights(aiResponse: string, maxInsights: number): CoachingInsight[] {\n  try {\n    const jsonMatch = aiResponse.match(/\\[[\\s\\S]*\\]/);\n    if (!jsonMatch) {\n      return [];\n    }\n    \n    const parsed = JSON.parse(jsonMatch[0]);\n    return parsed.slice(0, maxInsights);\n    \n  } catch (error) {\n    logger.warn('Failed to parse coaching insights', { error });\n    return [];\n  }\n}\n\n// ============================================================================\n// FOLLOW-UP ACTIONS GENERATION\n// ============================================================================\n\n/**\n * Generate follow-up action recommendations\n */\nasync function generateFollowUpActions(\n  aiAnalysis: any,\n  conversationType: ConversationType,\n  customContext: string | undefined,\n  config: ConversationEngineConfig\n): Promise<FollowUpAction[]> {\n  try {\n    const prompt = buildFollowUpPrompt(aiAnalysis, conversationType, customContext);\n    \n    const response = await sendUnifiedChatMessage({\n      model: config.aiModel,\n      messages: [{ role: 'user', content: prompt }],\n      temperature: 0.7,\n      maxTokens: 1500,\n    });\n    \n    const actions = parseFollowUpActions(response.text, config.maxFollowUpActions);\n    \n    return actions;\n    \n  } catch (error: any) {\n    logger.error('Follow-up actions generation failed', { error: error.message });\n    return [];\n  }\n}\n\n/**\n * Build follow-up actions prompt\n */\nfunction buildFollowUpPrompt(\n  aiAnalysis: any,\n  conversationType: ConversationType,\n  customContext?: string\n): string {\n  return `Generate follow-up actions based on this conversation analysis.\n\nCONVERSATION TYPE: ${conversationType}\nSUMMARY: ${aiAnalysis.summary}\nKEY MOMENTS: ${aiAnalysis.keyMoments.map((m: any) => `- ${m.description}`).join('\\n')}\nOBJECTIONS: ${aiAnalysis.objections.map((o: any) => `- ${o.objection}`).join('\\n')}\n${customContext ? `\\nCONTEXT:\\n${customContext}\\n` : ''}\n\nProvide 3-5 follow-up actions as a JSON array:\n\n[\n  {\n    \"id\": \"unique_id\",\n    \"type\": \"send_follow_up_email\" | \"schedule_meeting\" | \"send_proposal\" | \"share_resources\" | \"introduce_stakeholder\" | \"address_concern\" | \"provide_pricing\" | \"schedule_demo\" | \"send_case_study\",\n    \"priority\": \"critical\" | \"high\" | \"medium\" | \"low\",\n    \"title\": \"Short title\",\n    \"description\": \"Detailed description of the action\",\n    \"reasoning\": \"Why this action is important\",\n    \"deadline\": \"within 24 hours\" | \"within 2 days\" | \"within 1 week\",\n    \"estimatedEffort\": hours (0.5 to 8)\n  }\n]\n\nPrioritize based on what will most advance the deal.`;\n}\n\n/**\n * Parse follow-up actions from AI response\n */\nfunction parseFollowUpActions(aiResponse: string, maxActions: number): FollowUpAction[] {\n  try {\n    const jsonMatch = aiResponse.match(/\\[[\\s\\S]*\\]/);\n    if (!jsonMatch) {\n      return [];\n    }\n    \n    const parsed = JSON.parse(jsonMatch[0]);\n    return parsed.slice(0, maxActions);\n    \n  } catch (error) {\n    logger.warn('Failed to parse follow-up actions', { error });\n    return [];\n  }\n}\n\n// ============================================================================\n// SUMMARY CALCULATION\n// ============================================================================\n\n/**\n * Calculate analysis summary for batch results\n */\nfunction calculateAnalysisSummary(\n  analyses: Map<string, ConversationAnalysis>\n): AnalysisSummary {\n  if (analyses.size === 0) {\n    return {\n      totalConversations: 0,\n      avgOverallScore: 0,\n      avgSentiment: 0,\n      avgTalkRatio: 0,\n      topCoachingAreas: [],\n      commonObjections: [],\n      topCompetitors: [],\n      sentimentTrend: 'stable',\n      scoreTrend: 'stable',\n    };\n  }\n  \n  let totalScore = 0;\n  let totalSentiment = 0;\n  let totalTalkRatio = 0;\n  \n  const coachingMap = new Map<string, { count: number; impact: number }>();\n  const objectionMap = new Map<string, { count: number; addressed: number }>();\n  const competitorMap = new Map<string, { count: number; sentiment: number }>();\n  \n  analyses.forEach(analysis => {\n    totalScore += analysis.scores.overall;\n    totalSentiment += analysis.sentiment.overall.score;\n    totalTalkRatio += analysis.talkRatio.repPercentage;\n    \n    // Aggregate coaching areas\n    analysis.coachingInsights.forEach(insight => {\n      const existing = coachingMap.get(insight.category) || { count: 0, impact: 0 };\n      coachingMap.set(insight.category, {\n        count: existing.count + 1,\n        impact: existing.impact + insight.impact,\n      });\n    });\n    \n    // Aggregate objections\n    analysis.objections.forEach(objection => {\n      const existing = objectionMap.get(objection.type) || { count: 0, addressed: 0 };\n      objectionMap.set(objection.type, {\n        count: existing.count + 1,\n        addressed: existing.addressed + (objection.wasAddressed ? 1 : 0),\n      });\n    });\n    \n    // Aggregate competitors\n    analysis.competitors.forEach(competitor => {\n      const existing = competitorMap.get(competitor.competitor) || { count: 0, sentiment: 0 };\n      competitorMap.set(competitor.competitor, {\n        count: existing.count + competitor.mentions,\n        sentiment: existing.sentiment + competitor.sentiment,\n      });\n    });\n  });\n  \n  const count = analyses.size;\n  \n  return {\n    totalConversations: count,\n    avgOverallScore: Math.round(totalScore / count),\n    avgSentiment: totalSentiment / count,\n    avgTalkRatio: Math.round(totalTalkRatio / count),\n    \n    topCoachingAreas: Array.from(coachingMap.entries())\n      .map(([area, data]) => ({\n        area,\n        frequency: data.count,\n        avgImpact: Math.round(data.impact / data.count),\n        recommendation: `Focus on improving ${area} skills`,\n      }))\n      .sort((a, b) => b.frequency - a.frequency)\n      .slice(0, 5),\n    \n    commonObjections: Array.from(objectionMap.entries())\n      .map(([type, data]) => ({\n        type: type as any,\n        frequency: data.count,\n        avgSeverity: 50, // Would need more data\n        successRate: Math.round((data.addressed / data.count) * 100),\n        bestResponse: 'Review successful objection handling examples',\n      }))\n      .sort((a, b) => b.frequency - a.frequency)\n      .slice(0, 5),\n    \n    topCompetitors: Array.from(competitorMap.entries())\n      .map(([competitor, data]) => ({\n        competitor,\n        mentions: data.count,\n        avgSentiment: data.sentiment / data.count,\n        winRate: 50, // Would need deal outcome data\n        positioning: 'Use battlecard for competitive differentiation',\n      }))\n      .sort((a, b) => b.mentions - a.mentions)\n      .slice(0, 5),\n    \n    sentimentTrend: 'stable',\n    scoreTrend: 'stable',\n  };\n}\n\n// ============================================================================\n// SIGNAL BUS INTEGRATION\n// ============================================================================\n\n/**\n * Emit analysis signal to Signal Bus\n */\nasync function emitAnalysisSignal(\n  analysis: ConversationAnalysis,\n  conversation: Conversation\n): Promise<void> {\n  try {\n    const coordinator = getServerSignalCoordinator();\n    \n    await coordinator.emitSignal({\n      type: 'conversation.analyzed' as any,\n      leadId: conversation.leadId || 'unknown',\n      orgId: analysis.organizationId,\n      workspaceId: analysis.workspaceId,\n      confidence: analysis.confidence / 100,\n      priority: analysis.scores.overall >= 70 ? 'Low' : analysis.scores.overall >= 50 ? 'Medium' : 'High',\n      metadata: {\n        source: 'conversation-intelligence',\n        conversationId: conversation.id,\n        conversationType: conversation.type,\n        overallScore: analysis.scores.overall,\n        sentiment: analysis.sentiment.overall.polarity,\n        talkRatio: analysis.talkRatio.repPercentage,\n        redFlagsCount: analysis.redFlags.length,\n        coachingInsightsCount: analysis.coachingInsights.length,\n      },\n    });\n    \n    logger.info('Analysis signal emitted', {\n      conversationId: conversation.id,\n      overallScore: analysis.scores.overall,\n    });\n    \n  } catch (error) {\n    logger.error('Failed to emit analysis signal', error, {\n      conversationId: conversation.id,\n    });\n  }\n}\n\n// ============================================================================\n// UTILITY FUNCTIONS\n// ============================================================================\n\n/**\n * Get conversation data (placeholder - would query Firestore)\n */\nasync function getConversation(\n  organizationId: string,\n  conversationId: string,\n  workspaceId: string\n): Promise<Conversation | null> {\n  // TODO: Implement Firestore query\n  // For now, return null to indicate not found\n  return null;\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\crm\\deal-monitor.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":254,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":254,"endColumn":50},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":255,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":255,"endColumn":50}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Deal Monitor Service\n * \n * Real-time deal monitoring using the Signal Bus.\n * Observes deal-related signals and triggers automated recommendations.\n * \n * LIVING LEDGER COMPLIANCE:\n * - Real-time signal observation (deal.created, deal.stage.changed, deal.won, deal.lost)\n * - Automatic health score recalculation on deal changes\n * - Next Best Action recommendations triggered by signals\n * - Signal Bus integration for event-driven architecture\n * \n * Signal Flow:\n * 1. Deal event occurs ‚Üí Signal emitted by deal-service\n * 2. Deal Monitor observes signal ‚Üí Triggers analysis\n * 3. Calculate health score ‚Üí Generate recommendations\n * 4. Emit recommendation signals ‚Üí Frontend/automation consumes\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport { getServerSignalCoordinator } from '@/lib/orchestration/coordinator-factory-server';\nimport { calculateDealHealth } from './deal-health';\nimport { generateNextBestActions } from './next-best-action-engine';\nimport type { SalesSignal } from '@/lib/orchestration/types';\nimport type { Deal } from './deal-service';\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\nexport interface DealMonitorConfig {\n  organizationId: string;\n  workspaceId: string;\n  autoGenerateRecommendations?: boolean; // Default: true\n  autoRecalculateHealth?: boolean; // Default: true\n  signalPriority?: 'High' | 'Medium' | 'Low'; // Default: Medium\n}\n\n// ============================================================================\n// SIGNAL OBSERVATION\n// ============================================================================\n\n/**\n * Start monitoring deal signals\n * \n * Observes deal-related signals and triggers automated actions.\n * \n * @param config - Monitor configuration\n * @returns Unsubscribe function\n * \n * @example\n * ```typescript\n * const unsubscribe = await startDealMonitor({\n *   organizationId: 'org_123',\n *   workspaceId: 'default',\n *   autoGenerateRecommendations: true,\n * });\n * \n * // Later, to stop monitoring:\n * unsubscribe();\n * ```\n */\nexport async function startDealMonitor(\n  config: DealMonitorConfig\n): Promise<() => void> {\n  const {\n    organizationId,\n    workspaceId,\n    autoGenerateRecommendations = true,\n    autoRecalculateHealth = true,\n    signalPriority = 'Medium',\n  } = config;\n\n  logger.info('Starting deal monitor', {\n    organizationId,\n    workspaceId,\n    autoGenerateRecommendations,\n    autoRecalculateHealth,\n  });\n\n  try {\n    const coordinator = getServerSignalCoordinator();\n\n    // Observe deal signals\n    const unsubscribe = coordinator.observeSignals(\n      {\n        types: [\n          'deal.created',\n          'deal.stage.changed',\n          'deal.won',\n          'deal.lost',\n        ],\n        orgId: organizationId,\n        workspaceId,\n      },\n      async (signal: SalesSignal) => {\n        await handleDealSignal(\n          signal,\n          organizationId,\n          workspaceId,\n          autoGenerateRecommendations,\n          autoRecalculateHealth,\n          signalPriority\n        );\n      }\n    );\n\n    logger.info('Deal monitor started successfully', {\n      organizationId,\n      workspaceId,\n    });\n\n    return unsubscribe;\n  } catch (error) {\n    logger.error('Failed to start deal monitor', error, {\n      organizationId,\n      workspaceId,\n    });\n    throw error;\n  }\n}\n\n/**\n * Handle deal signal\n */\nasync function handleDealSignal(\n  signal: SalesSignal,\n  organizationId: string,\n  workspaceId: string,\n  autoGenerateRecommendations: boolean,\n  autoRecalculateHealth: boolean,\n  signalPriority: 'High' | 'Medium' | 'Low'\n): Promise<void> {\n  try {\n    const dealId = signal.metadata?.dealId as string;\n    if (!dealId) {\n      logger.warn('Deal signal missing dealId', { signalType: signal.type });\n      return;\n    }\n\n    logger.info('Processing deal signal', {\n      signalType: signal.type,\n      dealId,\n      organizationId,\n    });\n\n    // Step 1: Recalculate health score\n    let healthScore;\n    if (autoRecalculateHealth && signal.type !== 'deal.created') {\n      try {\n        healthScore = await calculateDealHealth(\n          organizationId,\n          workspaceId,\n          dealId\n        );\n\n        logger.info('Deal health recalculated', {\n          dealId,\n          healthScore: healthScore.overall,\n          status: healthScore.status,\n        });\n\n        // Emit health score update signal\n        await emitHealthScoreSignal(\n          organizationId,\n          workspaceId,\n          dealId,\n          healthScore,\n          signalPriority\n        );\n      } catch (error) {\n        logger.error('Failed to recalculate health score', error, { dealId });\n      }\n    }\n\n    // Step 2: Generate next best action recommendations\n    if (autoGenerateRecommendations) {\n      try {\n        const recommendations = await generateNextBestActions(\n          organizationId,\n          workspaceId,\n          dealId\n        );\n\n        logger.info('Recommendations generated', {\n          dealId,\n          actionCount: recommendations.actions.length,\n          urgency: recommendations.urgency,\n          topAction: recommendations.actions[0]?.type,\n        });\n\n        // Emit recommendations signal\n        await emitRecommendationsSignal(\n          organizationId,\n          workspaceId,\n          dealId,\n          recommendations,\n          signalPriority\n        );\n      } catch (error) {\n        logger.error('Failed to generate recommendations', error, { dealId });\n      }\n    }\n\n    // Step 3: Handle specific signal types\n    await handleSpecificSignalType(\n      signal,\n      organizationId,\n      workspaceId,\n      dealId,\n      signalPriority\n    );\n  } catch (error) {\n    logger.error('Failed to handle deal signal', error, {\n      signalType: signal.type,\n    });\n  }\n}\n\n/**\n * Handle specific signal types\n */\nasync function handleSpecificSignalType(\n  signal: SalesSignal,\n  organizationId: string,\n  workspaceId: string,\n  dealId: string,\n  signalPriority: 'High' | 'Medium' | 'Low'\n): Promise<void> {\n  const coordinator = getServerSignalCoordinator();\n\n  switch (signal.type) {\n    case 'deal.created':\n      // New deal created - emit onboarding recommendations\n      await coordinator.emitSignal({\n        type: 'deal.action.recommended',\n        leadId: signal.metadata?.contactId as string,\n        orgId: organizationId,\n        workspaceId,\n        confidence: 0.9,\n        priority: signalPriority,\n        metadata: {\n          source: 'deal-monitor',\n          dealId,\n          actionType: 'qualification',\n          reason: 'New deal requires qualification call',\n          suggestedTimeline: 'This Week',\n        },\n      });\n      break;\n\n    case 'deal.stage.changed':\n      // Stage changed - recalculate and notify\n      const oldStage = signal.metadata?.oldStage;\n      const newStage = signal.metadata?.newStage;\n\n      logger.info('Deal stage changed', {\n        dealId,\n        oldStage,\n        newStage,\n      });\n\n      // If moved to negotiation, emit high-priority signal\n      if (newStage === 'negotiation') {\n        await coordinator.emitSignal({\n          type: 'deal.action.recommended',\n          orgId: organizationId,\n          workspaceId,\n          confidence: 0.95,\n          priority: 'High',\n          metadata: {\n            source: 'deal-monitor',\n            dealId,\n            actionType: 'negotiate',\n            reason: 'Deal entered negotiation - schedule final terms meeting',\n            suggestedTimeline: 'This Week',\n          },\n        });\n      }\n      break;\n\n    case 'deal.won':\n      // Deal won - emit onboarding signal\n      await coordinator.emitSignal({\n        type: 'deal.action.recommended',\n        orgId: organizationId,\n        workspaceId,\n        confidence: 1.0,\n        priority: 'High',\n        metadata: {\n          source: 'deal-monitor',\n          dealId,\n          actionType: 'onboarding',\n          reason: 'Deal won - initiate customer onboarding',\n          suggestedTimeline: 'Today',\n        },\n      });\n      break;\n\n    case 'deal.lost':\n      // Deal lost - emit post-mortem signal\n      await coordinator.emitSignal({\n        type: 'deal.action.recommended',\n        orgId: organizationId,\n        workspaceId,\n        confidence: 0.7,\n        priority: 'Low',\n        metadata: {\n          source: 'deal-monitor',\n          dealId,\n          actionType: 'postmortem',\n          reason: 'Deal lost - conduct loss analysis',\n          lostReason: signal.metadata?.lostReason,\n          suggestedTimeline: 'Next Week',\n        },\n      });\n      break;\n  }\n}\n\n/**\n * Emit health score update signal\n */\nasync function emitHealthScoreSignal(\n  organizationId: string,\n  workspaceId: string,\n  dealId: string,\n  healthScore: any,\n  priority: 'High' | 'Medium' | 'Low'\n): Promise<void> {\n  try {\n    const coordinator = getServerSignalCoordinator();\n\n    await coordinator.emitSignal({\n      type: 'deal.health.updated',\n      orgId: organizationId,\n      workspaceId,\n      confidence: 0.8, // Health score is deterministic\n      priority:\n        healthScore.status === 'critical'\n          ? 'High'\n          : healthScore.status === 'at-risk'\n          ? 'Medium'\n          : priority,\n      metadata: {\n        source: 'deal-monitor',\n        dealId,\n        healthScore: healthScore.overall,\n        status: healthScore.status,\n        warnings: healthScore.warnings,\n        recommendations: healthScore.recommendations,\n        factors: healthScore.factors.map((f: any) => ({\n          name: f.name,\n          score: f.score,\n          impact: f.impact,\n        })),\n      },\n    });\n\n    logger.info('Health score signal emitted', {\n      dealId,\n      healthScore: healthScore.overall,\n      status: healthScore.status,\n    });\n  } catch (error) {\n    logger.error('Failed to emit health score signal', error, { dealId });\n  }\n}\n\n/**\n * Emit recommendations signal\n */\nasync function emitRecommendationsSignal(\n  organizationId: string,\n  workspaceId: string,\n  dealId: string,\n  recommendations: any,\n  priority: 'High' | 'Medium' | 'Low'\n): Promise<void> {\n  try {\n    const coordinator = getServerSignalCoordinator();\n\n    await coordinator.emitSignal({\n      type: 'deal.recommendations.generated',\n      orgId: organizationId,\n      workspaceId,\n      confidence: recommendations.confidence,\n      priority:\n        recommendations.urgency === 'critical'\n          ? 'High'\n          : recommendations.urgency === 'high'\n          ? 'High'\n          : recommendations.urgency === 'medium'\n          ? 'Medium'\n          : priority,\n      metadata: {\n        source: 'deal-monitor',\n        dealId,\n        actionCount: recommendations.actions.length,\n        urgency: recommendations.urgency,\n        topAction: recommendations.actions[0]\n          ? {\n              type: recommendations.actions[0].type,\n              title: recommendations.actions[0].title,\n              priority: recommendations.actions[0].priority,\n              confidence: recommendations.actions[0].confidence,\n              suggestedTimeline: recommendations.actions[0].suggestedTimeline,\n            }\n          : null,\n        allActions: recommendations.actions.map((action: any) => ({\n          id: action.id,\n          type: action.type,\n          priority: action.priority,\n          title: action.title,\n          confidence: action.confidence,\n        })),\n      },\n    });\n\n    logger.info('Recommendations signal emitted', {\n      dealId,\n      actionCount: recommendations.actions.length,\n      urgency: recommendations.urgency,\n    });\n  } catch (error) {\n    logger.error('Failed to emit recommendations signal', error, { dealId });\n  }\n}\n\n// ============================================================================\n// BATCH MONITORING\n// ============================================================================\n\n/**\n * Monitor all deals and generate recommendations for at-risk deals\n * \n * This is useful for periodic batch processing (e.g., daily health check).\n * \n * @param organizationId - Organization ID\n * @param workspaceId - Workspace ID\n * @returns Summary of monitored deals\n */\nexport async function runDealHealthCheck(\n  organizationId: string,\n  workspaceId: string = 'default'\n): Promise<{\n  total: number;\n  healthy: number;\n  atRisk: number;\n  critical: number;\n  recommendationsGenerated: number;\n}> {\n  try {\n    logger.info('Running deal health check', {\n      organizationId,\n      workspaceId,\n    });\n\n    // Get all active deals\n    const { getDeals } = await import('./deal-service');\n    const { data: deals } = await getDeals(organizationId, workspaceId, {\n      // Filter out closed deals\n    });\n\n    const activeDeals = deals.filter(\n      (d: Deal) => d.stage !== 'closed_won' && d.stage !== 'closed_lost'\n    );\n\n    let healthy = 0;\n    let atRisk = 0;\n    let critical = 0;\n    let recommendationsGenerated = 0;\n\n    // Process each deal\n    for (const deal of activeDeals) {\n      try {\n        // Calculate health\n        const healthScore = await calculateDealHealth(\n          organizationId,\n          workspaceId,\n          deal.id\n        );\n\n        // Count by status\n        if (healthScore.status === 'healthy') {healthy++;}\n        else if (healthScore.status === 'at-risk') {atRisk++;}\n        else if (healthScore.status === 'critical') {critical++;}\n\n        // Generate recommendations for at-risk and critical deals\n        if (\n          healthScore.status === 'at-risk' ||\n          healthScore.status === 'critical'\n        ) {\n          await generateNextBestActions(\n            organizationId,\n            workspaceId,\n            deal.id,\n            deal\n          );\n          recommendationsGenerated++;\n        }\n      } catch (error) {\n        logger.error('Failed to process deal in health check', error, {\n          dealId: deal.id,\n        });\n      }\n    }\n\n    const summary = {\n      total: activeDeals.length,\n      healthy,\n      atRisk,\n      critical,\n      recommendationsGenerated,\n    };\n\n    logger.info('Deal health check complete', summary);\n\n    return summary;\n  } catch (error) {\n    logger.error('Failed to run deal health check', error, {\n      organizationId,\n      workspaceId,\n    });\n    throw error;\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\ecommerce\\payment-service.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":76,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":76,"endColumn":82},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":80,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":80,"endColumn":79},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":84,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":84,"endColumn":76}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Payment Service\n * Handles payment processing via Stripe and other providers\n */\n\nimport { apiKeyService } from '@/lib/api-keys/api-key-service';\nimport type { OrderPayment } from '@/types/ecommerce'\nimport { logger } from '@/lib/logger/logger';;\n\nexport interface PaymentRequest {\n  workspaceId: string;\n  organizationId: string;\n  amount: number; // In cents\n  currency: string;\n  paymentMethod: string;\n  paymentToken?: string; // Stripe payment intent token, etc.\n  customer: {\n    email: string;\n    firstName: string;\n    lastName: string;\n    phone?: string;\n  };\n  metadata?: Record<string, any>;\n}\n\nexport interface PaymentResult {\n  success: boolean;\n  transactionId?: string;\n  provider?: string;\n  cardLast4?: string;\n  cardBrand?: string;\n  processingFee?: number;\n  error?: string;\n}\n\n/**\n * Process payment\n */\nexport async function processPayment(request: PaymentRequest): Promise<PaymentResult> {\n  // Get e-commerce config to determine payment provider\n  const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n  const ecommerceConfig = await FirestoreService.get(\n    `${COLLECTIONS.ORGANIZATIONS}/${request.organizationId}/workspaces/${request.workspaceId}/ecommerce`,\n    'config'\n  );\n  \n  if (!ecommerceConfig) {\n    return {\n      success: false,\n      error: 'E-commerce not configured',\n    };\n  }\n  \n  const paymentConfig = (ecommerceConfig as any).payments;\n  const defaultProvider = paymentConfig?.providers?.find((p: any) => p.isDefault && p.enabled);\n  \n  if (!paymentConfig || !defaultProvider) {\n    return {\n      success: false,\n      error: 'No payment provider configured',\n    };\n  }\n  \n  // Route to appropriate provider\n  switch (defaultProvider.provider) {\n    case 'stripe':\n      return processStripePayment(request, defaultProvider);\n    \n    case 'square':\n      return processSquarePayment(request, defaultProvider);\n    \n    case 'paypal':\n      return processPayPalPayment(request, defaultProvider);\n    \n    case 'authorizenet':\n      const { processAuthorizeNetPayment } = await import('./payment-providers');\n      return processAuthorizeNetPayment(request, defaultProvider);\n    \n    case '2checkout':\n      const { process2CheckoutPayment } = await import('./payment-providers');\n      return process2CheckoutPayment(request, defaultProvider);\n    \n    case 'mollie':\n      const { processMolliePayment } = await import('./payment-providers');\n      return processMolliePayment(request, defaultProvider);\n    \n    default:\n      return {\n        success: false,\n        error: `Payment provider ${defaultProvider.provider} not yet implemented`,\n      };\n  }\n}\n\n/**\n * Process Stripe payment\n */\nasync function processStripePayment(\n  request: PaymentRequest,\n  providerConfig: any\n): Promise<PaymentResult> {\n  try {\n    // Get Stripe API key\n    const orgId = request.organizationId || request.workspaceId.split('/')[0]; // Use org ID directly or extract from workspace\n    const stripeKey = await apiKeyService.getServiceKey(orgId, 'stripe');\n    \n    if (!stripeKey) {\n      return {\n        success: false,\n        error: 'Stripe API key not configured',\n      };\n    }\n    \n    const apiKey = typeof stripeKey === 'string' ? stripeKey : stripeKey.apiKey;\n    if (!apiKey) {\n      return {\n        success: false,\n        error: 'Stripe API key not found',\n      };\n    }\n    \n    // Use Stripe API\n    const stripe = await import('stripe');\n    const stripeClient = new stripe.Stripe(apiKey, {\n      apiVersion: '2023-10-16',\n    });\n    \n    // Create payment intent\n    const paymentIntent = await stripeClient.paymentIntents.create({\n      amount: Math.round(request.amount * 100), // Convert to cents\n      currency: request.currency.toLowerCase(),\n      payment_method: request.paymentToken,\n      confirm: true,\n      return_url: `${process.env.NEXT_PUBLIC_APP_URL}/checkout/complete`,\n      metadata: {\n        workspaceId: request.workspaceId,\n        customerEmail: request.customer.email,\n        ...request.metadata,\n      },\n    });\n    \n    if (paymentIntent.status === 'succeeded') {\n      // Get payment method details if available\n      let cardLast4: string | undefined;\n      let cardBrand: string | undefined;\n      \n      if (paymentIntent.payment_method && typeof paymentIntent.payment_method === 'string') {\n        // Fetch payment method details\n        try {\n          const pm = await stripeClient.paymentMethods.retrieve(paymentIntent.payment_method);\n          cardLast4 = (pm as any).card?.last4;\n          cardBrand = (pm as any).card?.brand;\n        } catch (e) {\n          // Ignore if can't fetch\n        }\n      }\n      \n      return {\n        success: true,\n        transactionId: paymentIntent.id,\n        provider: 'stripe',\n        cardLast4,\n        cardBrand,\n        processingFee: calculateStripeFee(request.amount),\n      };\n    } else {\n      return {\n        success: false,\n        error: `Payment status: ${paymentIntent.status}`,\n      };\n    }\n  } catch (error: any) {\n    logger.error('Stripe payment error:', error, { file: 'payment-service.ts' });\n    return {\n      success: false,\n      error: error.message || 'Payment processing failed',\n    };\n  }\n}\n\n/**\n * Calculate Stripe processing fee\n */\nexport function calculateStripeFee(amount: number): number {\n  // Stripe fee: 2.9% + $0.30\n  return amount * 0.029 + 0.30;\n}\n\n/**\n * Process Square payment\n */\nasync function processSquarePayment(\n  request: PaymentRequest,\n  providerConfig: any\n): Promise<PaymentResult> {\n  try {\n    // Get Square API credentials\n    const orgId = request.workspaceId.split('/')[0];\n    const squareKeys = await apiKeyService.getServiceKey(orgId, 'square');\n    \n    if (!squareKeys) {\n      return {\n        success: false,\n        error: 'Square API credentials not configured',\n      };\n    }\n    \n    const { accessToken, locationId } = squareKeys;\n    \n    if (!accessToken || !locationId) {\n      return {\n        success: false,\n        error: 'Square access token or location ID missing',\n      };\n    }\n    \n    // Use Square API\n    const square = await import('square');\n    const client = new square.SquareClient({\n      token: accessToken,\n      environment: providerConfig.mode === 'production' ? square.SquareEnvironment.Production : square.SquareEnvironment.Sandbox,\n    });\n    \n    // Create payment\n    const response = await client.payments.create({\n      sourceId: request.paymentToken || '', // Square payment token from frontend\n      idempotencyKey: `${request.workspaceId}-${Date.now()}`, // Unique key\n      amountMoney: {\n        amount: BigInt(Math.round(request.amount * 100)), // Convert to cents\n        currency: request.currency.toUpperCase() as any,\n      },\n      locationId,\n      customerId: undefined, // Can link to Square customer\n      referenceId: request.metadata?.orderId,\n      note: `Payment for ${request.customer.email}`,\n      buyerEmailAddress: request.customer.email,\n    });\n    \n    if (response.payment) {\n      const payment = response.payment;\n      \n      return {\n        success: true,\n        transactionId: payment.id || '',\n        provider: 'square',\n        cardLast4: payment.cardDetails?.card?.last4,\n        cardBrand: payment.cardDetails?.card?.cardBrand,\n        processingFee: calculateSquareFee(request.amount),\n      };\n    } else {\n      return {\n        success: false,\n        error: response.errors?.[0]?.detail || 'Square payment failed',\n      };\n    }\n  } catch (error: any) {\n    logger.error('Square payment error:', error, { file: 'payment-service.ts' });\n    return {\n      success: false,\n      error: error.message || 'Square payment processing failed',\n    };\n  }\n}\n\n/**\n * Calculate Square processing fee\n */\nexport function calculateSquareFee(amount: number): number {\n  // Square fee: 2.6% + $0.10 (card present) or 2.9% + $0.30 (card not present)\n  // Using card not present rate\n  return amount * 0.029 + 0.30;\n}\n\n/**\n * Process PayPal payment\n */\nasync function processPayPalPayment(\n  request: PaymentRequest,\n  providerConfig: any\n): Promise<PaymentResult> {\n  try {\n    // Get PayPal API credentials\n    const orgId = request.workspaceId.split('/')[0];\n    const paypalKeys = await apiKeyService.getServiceKey(orgId, 'paypal');\n    \n    if (!paypalKeys) {\n      return {\n        success: false,\n        error: 'PayPal API credentials not configured',\n      };\n    }\n    \n    const { clientId, clientSecret, mode } = paypalKeys;\n    \n    if (!clientId || !clientSecret) {\n      return {\n        success: false,\n        error: 'PayPal client ID or secret missing',\n      };\n    }\n    \n    // PayPal API base URL\n    const baseURL = mode === 'live' \n      ? 'https://api-m.paypal.com'\n      : 'https://api-m.sandbox.paypal.com';\n    \n    // Get access token\n    const authResponse = await fetch(`${baseURL}/v1/oauth2/token`, {\n      method: 'POST',\n      headers: {\n        'Accept': 'application/json',\n        'Accept-Language': 'en_US',\n        'Content-Type': 'application/x-www-form-urlencoded',\n        'Authorization': `Basic ${Buffer.from(`${clientId}:${clientSecret}`).toString('base64')}`,\n      },\n      body: 'grant_type=client_credentials',\n    });\n    \n    if (!authResponse.ok) {\n      return {\n        success: false,\n        error: 'PayPal authentication failed',\n      };\n    }\n    \n    const { access_token } = await authResponse.json();\n    \n    // Create order\n    const orderResponse = await fetch(`${baseURL}/v2/checkout/orders`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${access_token}`,\n      },\n      body: JSON.stringify({\n        intent: 'CAPTURE',\n        purchase_units: [{\n          reference_id: request.metadata?.orderId || 'default',\n          amount: {\n            currency_code: request.currency.toUpperCase(),\n            value: request.amount.toFixed(2),\n          },\n          description: `Payment from ${request.customer.email}`,\n        }],\n        payer: {\n          email_address: request.customer.email,\n          name: {\n            given_name: request.customer.firstName,\n            surname: request.customer.lastName,\n          },\n        },\n      }),\n    });\n    \n    if (!orderResponse.ok) {\n      const error = await orderResponse.json();\n      return {\n        success: false,\n        error: error.message || 'PayPal order creation failed',\n      };\n    }\n    \n    const order = await orderResponse.json();\n    \n    // If we have a payment token (order ID from frontend), capture it\n    if (request.paymentToken) {\n      const captureResponse = await fetch(`${baseURL}/v2/checkout/orders/${request.paymentToken}/capture`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${access_token}`,\n        },\n      });\n      \n      if (!captureResponse.ok) {\n        return {\n          success: false,\n          error: 'PayPal payment capture failed',\n        };\n      }\n      \n      const captureResult = await captureResponse.json();\n      \n      if (captureResult.status === 'COMPLETED') {\n        return {\n          success: true,\n          transactionId: captureResult.id,\n          provider: 'paypal',\n          processingFee: calculatePayPalFee(request.amount),\n        };\n      } else {\n        return {\n          success: false,\n          error: `PayPal payment status: ${captureResult.status}`,\n        };\n      }\n    }\n    \n    // Return order ID for frontend to complete\n    return {\n      success: true,\n      transactionId: order.id,\n      provider: 'paypal',\n    };\n    \n  } catch (error: any) {\n    logger.error('PayPal payment error:', error, { file: 'payment-service.ts' });\n    return {\n      success: false,\n      error: error.message || 'PayPal payment processing failed',\n    };\n  }\n}\n\n/**\n * Calculate PayPal processing fee\n */\nexport function calculatePayPalFee(amount: number): number {\n  // PayPal fee: 2.9% + $0.30 (standard)\n  return amount * 0.029 + 0.30;\n}\n\n/**\n * Calculate Razorpay processing fee (approximate)\n */\nexport function calculateRazorpayFee(amount: number): number {\n  // Razorpay: ~2% + small fixed; use 2% baseline\n  return amount * 0.02;\n}\n\n/**\n * Refund payment\n */\nexport async function refundPayment(\n  workspaceId: string,\n  organizationId: string,\n  transactionId: string,\n  amount?: number\n): Promise<PaymentResult> {\n  // Get provider from transaction\n  const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n  \n  // Find order with this transaction ID\n  const { where } = await import('firebase/firestore');\n  const orders = await FirestoreService.getAll(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/workspaces/${workspaceId}/orders`,\n    [where('payment.transactionId', '==', transactionId)]\n  );\n  \n  if (orders.length === 0) {\n    return {\n      success: false,\n      error: 'Order not found',\n    };\n  }\n  \n  const order = orders[0] as any;\n  const provider = order.payment.provider;\n  \n  // Route to appropriate provider\n  switch (provider) {\n    case 'stripe':\n      return refundStripePayment(transactionId, amount);\n    \n    default:\n      return {\n        success: false,\n        error: `Refund for provider ${provider} not yet implemented`,\n      };\n  }\n}\n\n/**\n * Refund Stripe payment\n */\nasync function refundStripePayment(\n  transactionId: string,\n  amount?: number,\n  workspaceId?: string\n): Promise<PaymentResult> {\n  try {\n    // Get Stripe API key from workspace settings\n    // Note: workspaceId should be passed from the refund() caller\n    if (!workspaceId) {\n      throw new Error('Workspace ID required for Stripe refunds');\n    }\n    \n    const { apiKeyService } = await import('@/lib/api-keys/api-key-service');\n    const apiKeys = await apiKeyService.getKeys(workspaceId);\n    \n    if (!apiKeys?.payments?.stripe?.secretKey) {\n      throw new Error('Stripe not configured. Please add your Stripe API key in Settings > API Keys');\n    }\n    \n    const stripe = await import('stripe');\n    const stripeClient = new stripe.Stripe(apiKeys.payments.stripe.secretKey, {\n      apiVersion: '2023-10-16',\n    });\n    \n    const refund = await stripeClient.refunds.create({\n      payment_intent: transactionId,\n      amount: amount ? Math.round(amount * 100) : undefined, // Partial refund if amount specified\n    });\n    \n    return {\n      success: true,\n      transactionId: refund.id,\n      provider: 'stripe',\n    };\n  } catch (error: any) {\n    return {\n      success: false,\n      error: error.message || 'Refund failed',\n    };\n  }\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\enrichment\\backup-sources.ts","messages":[{"ruleId":"no-empty","severity":2,"message":"Empty block statement.","line":70,"column":17,"nodeType":"BlockStatement","messageId":"unexpected","endLine":70,"endColumn":19,"suggestions":[{"messageId":"suggestComment","data":{"type":"block"},"fix":{"range":[2413,2413],"text":" /* empty */ "},"desc":"Add comment inside empty block statement."}]},{"ruleId":"no-empty","severity":2,"message":"Empty block statement.","line":82,"column":17,"nodeType":"BlockStatement","messageId":"unexpected","endLine":82,"endColumn":19,"suggestions":[{"messageId":"suggestComment","data":{"type":"block"},"fix":{"range":[3118,3118],"text":" /* empty */ "},"desc":"Add comment inside empty block statement."}]}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Free Backup Data Sources\n * When web scraping fails, use these FREE sources to get partial data\n * NO paid APIs - all free tier or public data\n */\n\nimport type { CompanyEnrichmentData } from './types'\nimport { logger } from '../logger/logger';;\n\n/**\n * Get company data from WHOIS (free)\n */\nexport async function getWhoisData(domain: string): Promise<Partial<CompanyEnrichmentData>> {\n  try {\n    logger.info('WHOIS Looking up domain}...', { file: 'backup-sources.ts' });\n    \n    // Use a free WHOIS API\n    const response = await fetch(`https://www.whoisxmlapi.com/whoisserver/WhoisService?domainName=${domain}&apiKey=at_00000000000000000000000000000&outputFormat=JSON`);\n    \n    if (!response.ok) {\n      return {};\n    }\n    \n    const data = await response.json();\n    const registrant = data.WhoisRecord?.registrant || {};\n    \n    return {\n      headquarters: {\n        city: registrant.city,\n        state: registrant.state,\n        country: registrant.country,\n      },\n      contactEmail: registrant.email,\n      contactPhone: registrant.telephone,\n    };\n  } catch (error) {\n    logger.error('[WHOIS] Error:', error, { file: 'backup-sources.ts' });\n    return {};\n  }\n}\n\n/**\n * Get tech stack from DNS records (free)\n * Note: DNS lookups work server-side only (not in browser/edge)\n */\nexport async function getTechStackFromDNS(domain: string): Promise<string[]> {\n  try {\n    logger.info('DNS Checking tech stack for domain}...', { file: 'backup-sources.ts' });\n    \n    const techStack: string[] = [];\n    \n    // Only try DNS if we're in Node.js environment\n    if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n      try {\n        // Dynamic import to avoid edge runtime issues\n        const dns = await import('dns').then(mod => mod.promises);\n        \n        // Check MX records for email provider\n        try {\n          const mxRecords = await dns.resolveMx(domain);\n          \n          if (mxRecords && mxRecords.length > 0) {\n            const mx = mxRecords[0].exchange.toLowerCase();\n            \n            if (mx.includes('google')) {techStack.push('Google Workspace');}\n            if (mx.includes('outlook') || mx.includes('microsoft')) {techStack.push('Microsoft 365');}\n            if (mx.includes('mailgun')) {techStack.push('Mailgun');}\n            if (mx.includes('sendgrid')) {techStack.push('SendGrid');}\n          }\n        } catch {}\n        \n        // Check TXT records for verification codes\n        try {\n          const txtRecords = await dns.resolveTxt(domain);\n          const txtString = txtRecords.flat().join(' ').toLowerCase();\n          \n          if (txtString.includes('google-site-verification')) {techStack.push('Google Analytics');}\n          if (txtString.includes('facebook-domain-verification')) {techStack.push('Facebook Pixel');}\n          if (txtString.includes('stripe-verification')) {techStack.push('Stripe');}\n          if (txtString.includes('v=spf') && txtString.includes('mailchimp')) {techStack.push('Mailchimp');}\n          if (txtString.includes('hubspot')) {techStack.push('HubSpot');}\n        } catch {}\n      } catch (error) {\n        logger.warn('[DNS] DNS module not available in this environment', { file: 'backup-sources.ts' });\n      }\n    }\n    \n    return [...new Set(techStack)];\n  } catch (error) {\n    logger.error('[DNS] Error:', error, { file: 'backup-sources.ts' });\n    return [];\n  }\n}\n\n/**\n * Get company data from Crunchbase public API (free tier: 200/day)\n */\nexport async function getCrunchbaseData(companyName: string): Promise<Partial<CompanyEnrichmentData>> {\n  try {\n    const apiKey = process.env.CRUNCHBASE_API_KEY;\n    \n    if (!apiKey) {\n      logger.warn('[Crunchbase] API key not configured', { file: 'backup-sources.ts' });\n      return {};\n    }\n    \n    logger.info('Crunchbase Looking up companyName}...', { file: 'backup-sources.ts' });\n    \n    const response = await fetch(\n      `https://api.crunchbase.com/api/v4/autocompletes?query=${encodeURIComponent(companyName)}&collection_ids=organizations&user_key=${apiKey}`\n    );\n    \n    if (!response.ok) {\n      return {};\n    }\n    \n    const data = await response.json();\n    const org = data.entities?.[0];\n    \n    if (!org) {\n      return {};\n    }\n    \n    // Get organization details\n    const detailsResponse = await fetch(\n      `https://api.crunchbase.com/api/v4/entities/organizations/${org.identifier.uuid}?user_key=${apiKey}`\n    );\n    \n    if (!detailsResponse.ok) {\n      return {};\n    }\n    \n    const details = await detailsResponse.json();\n    const props = details.properties || {};\n    \n    return {\n      description: props.short_description,\n      foundedYear: props.founded_on?.year,\n      headquarters: {\n        city: props.location_identifiers?.[0]?.value,\n        country: props.location_identifiers?.[0]?.location_type,\n      },\n      employeeCount: props.num_employees_enum,\n      fundingStage: props.funding_stage,\n      revenue: props.revenue_range,\n    };\n  } catch (error) {\n    logger.error('[Crunchbase] Error:', error, { file: 'backup-sources.ts' });\n    return {};\n  }\n}\n\n/**\n * Get company data from Google Knowledge Graph (free)\n */\nexport async function getGoogleKnowledgeGraph(companyName: string): Promise<Partial<CompanyEnrichmentData>> {\n  try {\n    const apiKey = process.env.GOOGLE_KNOWLEDGE_GRAPH_API_KEY;\n    \n    if (!apiKey) {\n      logger.warn('[Google KG] API key not configured', { file: 'backup-sources.ts' });\n      return {};\n    }\n    \n    logger.info('Google KG Looking up companyName}...', { file: 'backup-sources.ts' });\n    \n    const response = await fetch(\n      `https://kgsearch.googleapis.com/v1/entities:search?query=${encodeURIComponent(companyName)}&types=Organization&key=${apiKey}&limit=1`\n    );\n    \n    if (!response.ok) {\n      return {};\n    }\n    \n    const data = await response.json();\n    const entity = data.itemListElement?.[0]?.result;\n    \n    if (!entity) {\n      return {};\n    }\n    \n    return {\n      name: entity.name,\n      description: entity.description || entity.detailedDescription?.articleBody,\n      website: entity.url,\n    };\n  } catch (error) {\n    logger.error('[Google KG] Error:', error, { file: 'backup-sources.ts' });\n    return {};\n  }\n}\n\n/**\n * Get company data from Wikipedia API (free)\n */\nexport async function getWikipediaData(companyName: string): Promise<Partial<CompanyEnrichmentData>> {\n  try {\n    logger.info('Wikipedia Looking up companyName}...', { file: 'backup-sources.ts' });\n    \n    // Search for page\n    const searchResponse = await fetch(\n      `https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch=${encodeURIComponent(companyName)}&format=json&origin=*`\n    );\n    \n    if (!searchResponse.ok) {\n      return {};\n    }\n    \n    const searchData = await searchResponse.json();\n    const pageTitle = searchData.query?.search?.[0]?.title;\n    \n    if (!pageTitle) {\n      return {};\n    }\n    \n    // Get page extract\n    const extractResponse = await fetch(\n      `https://en.wikipedia.org/w/api.php?action=query&titles=${encodeURIComponent(pageTitle)}&prop=extracts&exintro=true&format=json&origin=*`\n    );\n    \n    if (!extractResponse.ok) {\n      return {};\n    }\n    \n    const extractData = await extractResponse.json();\n    const pages = extractData.query?.pages || {};\n    const page = Object.values(pages)[0] as any;\n    \n    if (!page?.extract) {\n      return {};\n    }\n    \n    // Clean HTML from extract\n    const description = page.extract\n      .replace(/<[^>]*>/g, '')\n      .replace(/\\s+/g, ' ')\n      .trim()\n      .substring(0, 500);\n    \n    return {\n      description,\n    };\n  } catch (error) {\n    logger.error('[Wikipedia] Error:', error, { file: 'backup-sources.ts' });\n    return {};\n  }\n}\n\n/**\n * Try all free backup sources and merge data\n */\nexport async function getAllBackupData(\n  companyName: string,\n  domain: string\n): Promise<Partial<CompanyEnrichmentData>> {\n  logger.info('[Backup Sources] Fetching from all free sources...', { file: 'backup-sources.ts' });\n  \n  // Run all in parallel\n  const [whois, dns, crunchbase, google, wikipedia] = await Promise.all([\n    getWhoisData(domain),\n    getTechStackFromDNS(domain),\n    getCrunchbaseData(companyName),\n    getGoogleKnowledgeGraph(companyName),\n    getWikipediaData(companyName),\n  ]);\n  \n  // Merge data (later sources override earlier ones)\n  const merged: Partial<CompanyEnrichmentData> = {\n    ...whois,\n    ...crunchbase,\n    ...google,\n    ...wikipedia,\n  };\n  \n  // Add tech stack from DNS\n  if (dns.length > 0) {\n    merged.techStack = [...(merged.techStack || []), ...dns];\n  }\n  \n  logger.info('[Backup Sources] Merged data from backup sources', { file: 'backup-sources.ts' });\n  \n  return merged;\n}\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\enrichment\\validation-service.ts","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\(.","line":158,"column":39,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":158,"endColumn":40,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4288,4289],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4288,4288],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\).","line":158,"column":41,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":158,"endColumn":42,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4290,4291],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4290,4290],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\+.","line":158,"column":43,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":158,"endColumn":44,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4292,4293],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4292,4292],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\..","line":158,"column":45,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":158,"endColumn":46,"suggestions":[{"messageId":"removeEscape","fix":{"range":[4294,4295],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[4294,4294],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":4,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Data Validation Service\n * Validates enriched data for accuracy and consistency\n * Prevents bad/fake data from being stored\n */\n\nimport type { CompanyEnrichmentData } from './types';\n\nexport interface ValidationResult {\n  isValid: boolean;\n  confidence: number; // 0-100\n  errors: string[];\n  warnings: string[];\n  checks: {\n    domainValid: boolean;\n    emailValid: boolean;\n    phoneValid: boolean;\n    dataConsistent: boolean;\n    sourcesReliable: boolean;\n  };\n}\n\n/**\n * Validate enriched company data\n */\nexport async function validateEnrichmentData(\n  data: CompanyEnrichmentData\n): Promise<ValidationResult> {\n  const errors: string[] = [];\n  const warnings: string[] = [];\n  \n  // Check 1: Domain validation\n  const domainValid = await validateDomain(data.domain);\n  if (!domainValid) {\n    errors.push(`Domain ${data.domain} does not exist or is unreachable`);\n  }\n  \n  // Check 2: Email validation\n  const emailValid = data.contactEmail ? validateEmail(data.contactEmail) : true;\n  if (data.contactEmail && !emailValid) {\n    warnings.push(`Email ${data.contactEmail} format is invalid`);\n  }\n  \n  // Check 3: Phone validation\n  const phoneValid = data.contactPhone ? validatePhone(data.contactPhone) : true;\n  if (data.contactPhone && !phoneValid) {\n    warnings.push(`Phone ${data.contactPhone} format is invalid`);\n  }\n  \n  // Check 4: Data consistency\n  const consistencyChecks = validateConsistency(data);\n  consistencyChecks.errors.forEach(e => errors.push(e));\n  consistencyChecks.warnings.forEach(w => warnings.push(w));\n  \n  // Check 5: Required fields\n  if (!data.name || data.name === 'Unknown') {\n    errors.push('Company name is missing or invalid');\n  }\n  \n  if (!data.website || !data.domain) {\n    errors.push('Website/domain is missing');\n  }\n  \n  // Calculate confidence score\n  let confidence = 100;\n  \n  // Deduct points for errors and warnings\n  confidence -= errors.length * 20;\n  confidence -= warnings.length * 5;\n  \n  // Deduct for missing data\n  if (!data.description || data.description.length < 20) {confidence -= 10;}\n  if (!data.industry || data.industry === 'Unknown') {confidence -= 10;}\n  if (!data.employeeCount && !data.employeeRange) {confidence -= 5;}\n  if (!data.headquarters?.city) {confidence -= 5;}\n  if (!data.socialMedia?.linkedin) {confidence -= 5;}\n  \n  // Add points for extra data\n  if (data.techStack && data.techStack.length > 0) {confidence += 5;}\n  if (data.recentNews && data.recentNews.length > 0) {confidence += 5;}\n  if (data.fundingStage) {confidence += 5;}\n  if (data.revenue) {confidence += 5;}\n  \n  confidence = Math.max(0, Math.min(100, confidence));\n  \n  const isValid = errors.length === 0;\n  \n  return {\n    isValid,\n    confidence,\n    errors,\n    warnings,\n    checks: {\n      domainValid,\n      emailValid,\n      phoneValid,\n      dataConsistent: consistencyChecks.errors.length === 0,\n      sourcesReliable: data.dataSource === 'hybrid' || data.dataSource === 'search-api',\n    },\n  };\n}\n\n/**\n * Validate domain exists and is reachable\n */\nasync function validateDomain(domain: string): Promise<boolean> {\n  try {\n    // Try HTTP request\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), 5000);\n    \n    const response = await fetch(`https://${domain}`, {\n      method: 'HEAD',\n      signal: controller.signal,\n    });\n    \n    clearTimeout(timeoutId);\n    return response.ok || response.status < 500; // Even 404 means domain exists\n  } catch (error: any) {\n    // Domain doesn't exist or is unreachable\n    return false;\n  }\n}\n\n/**\n * Validate email format\n */\nfunction validateEmail(email: string): boolean {\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n  \n  if (!emailRegex.test(email)) {\n    return false;\n  }\n  \n  // Check for common fake/placeholder emails\n  const fakeEmails = [\n    'test@test.com',\n    'admin@admin.com',\n    'info@info.com',\n    'contact@contact.com',\n    'example@example.com',\n    'noreply@',\n  ];\n  \n  const lowerEmail = email.toLowerCase();\n  if (fakeEmails.some(fake => lowerEmail.includes(fake))) {\n    return false;\n  }\n  \n  return true;\n}\n\n/**\n * Validate phone number format\n */\nfunction validatePhone(phone: string): boolean {\n  // Remove common formatting characters\n  const cleaned = phone.replace(/[\\s\\-\\(\\)\\+\\.]/g, '');\n  \n  // Should be 10-15 digits\n  if (cleaned.length < 10 || cleaned.length > 15) {\n    return false;\n  }\n  \n  // Should be all digits\n  if (!/^\\d+$/.test(cleaned)) {\n    return false;\n  }\n  \n  // Check for obviously fake numbers\n  const fakePatterns = [\n    '0000000000',\n    '1111111111',\n    '1234567890',\n    '9999999999',\n  ];\n  \n  if (fakePatterns.includes(cleaned)) {\n    return false;\n  }\n  \n  return true;\n}\n\n/**\n * Validate data consistency\n */\nfunction validateConsistency(data: CompanyEnrichmentData): {\n  errors: string[];\n  warnings: string[];\n} {\n  const errors: string[] = [];\n  const warnings: string[] = [];\n  \n  // Check employee count matches size category\n  if (data.employeeCount) {\n    const count = data.employeeCount;\n    \n    if (data.size === 'startup' && count >= 50) {\n      warnings.push(`Employee count (${count}) doesn't match size category (startup)`);\n    } else if (data.size === 'small' && (count < 50 || count > 200)) {\n      warnings.push(`Employee count (${count}) doesn't match size category (small)`);\n    } else if (data.size === 'medium' && (count < 200 || count > 1000)) {\n      warnings.push(`Employee count (${count}) doesn't match size category (medium)`);\n    } else if (data.size === 'enterprise' && count < 1000) {\n      warnings.push(`Employee count (${count}) doesn't match size category (enterprise)`);\n    }\n  }\n  \n  // Check founded year is reasonable\n  if (data.foundedYear) {\n    const currentYear = new Date().getFullYear();\n    \n    if (data.foundedYear < 1800) {\n      errors.push(`Founded year (${data.foundedYear}) is unrealistically old`);\n    } else if (data.foundedYear > currentYear) {\n      errors.push(`Founded year (${data.foundedYear}) is in the future`);\n    } else if (data.foundedYear > currentYear - 1) {\n      warnings.push(`Company founded very recently (${data.foundedYear})`);\n    }\n  }\n  \n  // Check domain matches website\n  if (data.website && data.domain) {\n    try {\n      const websiteHost = new URL(data.website).hostname.replace('www.', '');\n      const domain = data.domain.replace('www.', '');\n      \n      if (websiteHost !== domain) {\n        warnings.push(`Website hostname (${websiteHost}) doesn't match domain (${domain})`);\n      }\n    } catch {\n      errors.push(`Website URL (${data.website}) is malformed`);\n    }\n  }\n  \n  // Check email domain matches company domain\n  if (data.contactEmail && data.domain) {\n    const emailDomain = data.contactEmail.split('@')[1];\n    \n    if (emailDomain !== data.domain) {\n      // Could be fine (using Gmail, etc.) but worth noting\n      warnings.push(`Email domain (${emailDomain}) doesn't match company domain (${data.domain})`);\n    }\n  }\n  \n  // Check description quality\n  if (data.description) {\n    if (data.description.length < 20) {\n      warnings.push('Description is very short');\n    }\n    \n    // Check for placeholder text\n    const placeholders = ['lorem ipsum', 'coming soon', 'under construction'];\n    if (placeholders.some(p => data.description.toLowerCase().includes(p))) {\n      errors.push('Description contains placeholder text');\n    }\n  }\n  \n  return { errors, warnings };\n}\n\n/**\n * Verify email domain exists (simplified - no DNS dependency)\n */\nexport async function verifyEmailDomain(email: string): Promise<boolean> {\n  try {\n    const domain = email.split('@')[1];\n    \n    // Simple check - verify domain responds to HTTP\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), 3000);\n    \n    const response = await fetch(`https://${domain}`, {\n      method: 'HEAD',\n      signal: controller.signal,\n    });\n    \n    clearTimeout(timeoutId);\n    return true; // Domain exists\n  } catch {\n    return false; // Domain doesn't exist\n  }\n}\n\n/**\n * Check if domain is on a common disposable email list\n */\nexport function isDisposableEmail(email: string): boolean {\n  const domain = email.split('@')[1]?.toLowerCase();\n  \n  const disposableDomains = [\n    'tempmail.com',\n    '10minutemail.com',\n    'guerrillamail.com',\n    'mailinator.com',\n    'throwaway.email',\n    'temp-mail.org',\n  ];\n  \n  return disposableDomains.includes(domain);\n}\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\firebase-admin.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":35,"column":24,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":35,"endColumn":39},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":36,"column":22,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":36,"endColumn":35}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Centralized Firebase Admin SDK Initialization\n * Single source of truth for all Firebase Admin operations\n */\n\nimport * as admin from 'firebase-admin';\nimport { getFirestore } from 'firebase-admin/firestore';\nimport { getAuth } from 'firebase-admin/auth';\n\n// Initialize Firebase Admin SDK once\nif (!admin.apps.length) {\n  try {\n    let credential;\n    \n    // Check for individual environment variables (Vercel format)\n    if (process.env.FIREBASE_ADMIN_PROJECT_ID && \n        process.env.FIREBASE_ADMIN_CLIENT_EMAIL && \n        process.env.FIREBASE_ADMIN_PRIVATE_KEY) {\n      credential = admin.credential.cert({\n        projectId: process.env.FIREBASE_ADMIN_PROJECT_ID,\n        clientEmail: process.env.FIREBASE_ADMIN_CLIENT_EMAIL,\n        privateKey: process.env.FIREBASE_ADMIN_PRIVATE_KEY.replace(/\\\\n/g, '\\n'),\n      });\n    }\n    // In production, use service account from environment (JSON blob)\n    else if (process.env.FIREBASE_SERVICE_ACCOUNT_KEY) {\n      const serviceAccount = JSON.parse(process.env.FIREBASE_SERVICE_ACCOUNT_KEY);\n      credential = admin.credential.cert(serviceAccount);\n    } \n    // In development, use service account file\n    else {\n      try {\n        // Only require in development when file exists\n        if (process.env.NODE_ENV === 'development') {\n          const path = require('path');\n          const fs = require('fs');\n          const keyPath = path.join(process.cwd(), 'serviceAccountKey.json');\n          \n          if (fs.existsSync(keyPath)) {\n            const serviceAccount = JSON.parse(fs.readFileSync(keyPath, 'utf8'));\n            credential = admin.credential.cert(serviceAccount);\n          } else {\n            throw new Error('serviceAccountKey.json not found');\n          }\n        } else {\n          // In production without env var, use application default\n          credential = admin.credential.applicationDefault();\n        }\n      } catch (error) {\n        console.error('[Firebase Admin] Service account error, using application default credentials');\n        credential = admin.credential.applicationDefault();\n      }\n    }\n\n    admin.initializeApp({\n      credential,\n      projectId: process.env.FIREBASE_ADMIN_PROJECT_ID,\n      storageBucket: process.env.FIREBASE_STORAGE_BUCKET,\n    });\n\n    console.log('[Firebase Admin] Initialized successfully');\n    console.log(`[Firebase Admin] üéØ PROJECT ID: ${process.env.FIREBASE_ADMIN_PROJECT_ID || 'NOT SET'}`);\n  } catch (error) {\n    console.error('[Firebase Admin] Initialization failed:', error);\n    throw error;\n  }\n}\n\n// Export commonly used services\nexport const db = getFirestore();\nexport const auth = getAuth();\nexport { admin };\n\n/**\n * Helper to get current user from request\n * TODO: Implement actual user authentication\n */\nexport async function getCurrentUser(request: Request): Promise<{\n  uid: string;\n  email?: string;\n  organizationId?: string;\n} | null> {\n  try {\n    const authHeader = request.headers.get('authorization');\n    if (!authHeader?.startsWith('Bearer ')) {\n      return null;\n    }\n\n    const token = authHeader.split('Bearer ')[1];\n    const decodedToken = await auth.verifyIdToken(token);\n\n    // TODO: Fetch user's organizationId from Firestore\n    // For now, return basic user info\n    return {\n      uid: decodedToken.uid,\n      email: decodedToken.email,\n    };\n  } catch (error) {\n    console.error('[Auth] Failed to verify user:', error);\n    return null;\n  }\n}\n\n/**\n * Verify user has access to organization\n */\nexport async function verifyOrgAccess(\n  userId: string,\n  organizationId: string\n): Promise<boolean> {\n  try {\n    // Use environment-aware collection path via helper\n    const { getOrgSubCollection } = await import('./firebase/collections');\n    const membersPath = getOrgSubCollection(organizationId, 'members');\n    const userOrgRef = db.collection(membersPath).doc(userId);\n\n    const doc = await userOrgRef.get();\n    return doc.exists;\n  } catch (error) {\n    console.error('[Auth] Failed to verify org access:', error);\n    return false;\n  }\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\firebase\\admin.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":60,"column":20,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":60,"endColumn":33},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":61,"column":22,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":61,"endColumn":37}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Firebase Admin SDK Configuration\r\n * Server-side only - for API routes and server actions\r\n */\r\n\r\nimport * as admin from 'firebase-admin'\r\nimport { logger } from '../logger/logger';;\r\n\r\n// Initialize Firebase Admin SDK (singleton)\r\nlet adminApp: admin.app.App | null = null;\r\n\r\nfunction initializeAdmin() {\r\n  // Already initialized\r\n  if (adminApp) {\r\n    return adminApp;\r\n  }\r\n\r\n  // Check if already initialized by another module\r\n  if (admin.apps.length > 0) {\r\n    adminApp = admin.apps[0];\r\n    return adminApp;\r\n  }\r\n\r\n  // Emulator support removed - tests use real dev database with cleanup\r\n\r\n  // For production/development - use service account\r\n  try {\r\n    let serviceAccount: admin.ServiceAccount | undefined;\r\n    \r\n    // Option 1: Full JSON in single env var\r\n    if (process.env.FIREBASE_SERVICE_ACCOUNT_KEY) {\r\n      serviceAccount = JSON.parse(process.env.FIREBASE_SERVICE_ACCOUNT_KEY);\r\n      logger.info('üîë Using FIREBASE_SERVICE_ACCOUNT_KEY env var', { file: 'admin.ts' });\r\n    }\r\n    \r\n    // Option 2: Individual env vars (preferred for Vercel)\r\n    if (!serviceAccount && process.env.FIREBASE_ADMIN_PROJECT_ID && process.env.FIREBASE_ADMIN_PRIVATE_KEY) {\r\n      // Clean up private key: remove surrounding quotes and replace \\n with actual newlines\r\n      let privateKey = process.env.FIREBASE_ADMIN_PRIVATE_KEY;\r\n      \r\n      // Remove surrounding quotes if present (common when copying from JSON)\r\n      if (privateKey.startsWith('\"') && privateKey.endsWith('\"')) {\r\n        privateKey = privateKey.slice(1, -1);\r\n      }\r\n      \r\n      // Replace escaped newlines with actual newlines\r\n      privateKey = privateKey.replace(/\\\\n/g, '\\n');\r\n      \r\n      serviceAccount = {\r\n        projectId: process.env.FIREBASE_ADMIN_PROJECT_ID,\r\n        clientEmail: process.env.FIREBASE_ADMIN_CLIENT_EMAIL,\r\n        privateKey: privateKey,\r\n      };\r\n      logger.info('üîë Using individual Firebase Admin env vars', { file: 'admin.ts' });\r\n    }\r\n\r\n    // Option 3: Try to load from file (local development)\r\n    if (!serviceAccount) {\r\n      try {\r\n        const fs = require('fs');\r\n        const path = require('path');\r\n        const keyPath = path.join(process.cwd(), 'serviceAccountKey.json');\r\n        logger.info('üîç Looking for serviceAccountKey.json', { path: keyPath, file: 'admin.ts' });\r\n        if (fs.existsSync(keyPath)) {\r\n          serviceAccount = JSON.parse(fs.readFileSync(keyPath, 'utf8'));\r\n          logger.info('üîë Loaded serviceAccountKey.json successfully', { file: 'admin.ts' });\r\n        } else {\r\n          logger.warn('‚ö†Ô∏è serviceAccountKey.json not found', { path: keyPath, file: 'admin.ts' });\r\n        }\r\n      } catch (e: any) {\r\n        logger.warn('‚ö†Ô∏è Could not load serviceAccountKey.json', { error: e.message, file: 'admin.ts' });\r\n      }\r\n    }\r\n\r\n    if (serviceAccount) {\r\n      adminApp = admin.initializeApp({\r\n        credential: admin.credential.cert(serviceAccount),\r\n      });\r\n    } else {\r\n      // Use application default credentials (for GCP)\r\n      logger.warn('‚ö†Ô∏è No Firebase credentials found, using default credentials', { file: 'admin.ts' });\r\n      adminApp = admin.initializeApp();\r\n    }\r\n\r\n    logger.info('üî• Firebase Admin initialized', { file: 'admin.ts' });\r\n    return adminApp;\r\n  } catch (error: any) {\r\n    if (error.code === 'app/duplicate-app') {\r\n      adminApp = admin.app();\r\n      return adminApp;\r\n    }\r\n    logger.error('‚ùå Firebase Admin initialization failed', error, { file: 'admin.ts' });\r\n    throw error;\r\n  }\r\n}\r\n\r\n// Initialize on import (server-side only)\r\nif (typeof window === 'undefined') {\r\n  try {\r\n    logger.info('[Firebase Admin] Initializing...', { \r\n      projectId: process.env.FIREBASE_ADMIN_PROJECT_ID ? 'SET' : 'MISSING',\r\n      clientEmail: process.env.FIREBASE_ADMIN_CLIENT_EMAIL ? 'SET' : 'MISSING',\r\n      privateKey: process.env.FIREBASE_ADMIN_PRIVATE_KEY ? `SET (length: ${process.env.FIREBASE_ADMIN_PRIVATE_KEY.length})` : 'MISSING',\r\n      file: 'admin.ts' \r\n    });\r\n    initializeAdmin();\r\n    logger.info('[Firebase Admin] ‚úÖ Initialization complete', { \r\n      adminApp: adminApp ? 'INITIALIZED' : 'NULL',\r\n      file: 'admin.ts' \r\n    });\r\n  } catch (error: any) {\r\n    logger.error('[Firebase Admin] ‚ùå Initialization failed', error, { file: 'admin.ts' });\r\n  }\r\n}\r\n\r\n// Export admin services - only if properly initialized\r\nexport const adminAuth = adminApp ? admin.auth(adminApp) : null;\r\nexport const adminDb = adminApp ? admin.firestore(adminApp) : null;\r\nexport const adminStorage = adminApp ? admin.storage(adminApp) : null;\r\n\r\nexport { admin };\r\nexport default adminApp;\r\n\r\n\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\import\\import-service.ts","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\+.","line":81,"column":35,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":81,"endColumn":36,"suggestions":[{"messageId":"removeEscape","fix":{"range":[2540,2541],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[2540,2540],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\(.","line":81,"column":37,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":81,"endColumn":38,"suggestions":[{"messageId":"removeEscape","fix":{"range":[2542,2543],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[2542,2542],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\).","line":81,"column":39,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":81,"endColumn":40,"suggestions":[{"messageId":"removeEscape","fix":{"range":[2544,2545],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[2544,2544],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * CSV Import Service\n * Handles file parsing, schema detection, and data import\n */\n\nimport type { ImportSession, ColumnMapping, DetectedSchema, DetectedField, FieldTypeDetectionResult } from '@/types/import';\n\nexport class ImportService {\n  /**\n   * Parse CSV file\n   */\n  static parseCSV(file: File): Promise<{ headers: string[]; rows: any[][] }> {\n    return new Promise((resolve, reject) => {\n      const reader = new FileReader();\n      \n      reader.onload = (e) => {\n        try {\n          const text = e.target?.result as string;\n          const lines = text.split('\\n').filter(line => line.trim());\n          \n          if (lines.length === 0) {\n            reject(new Error('File is empty'));\n            return;\n          }\n          \n          // Parse CSV (basic implementation - in production use Papa Parse library)\n          const rows = lines.map(line => {\n            const values: string[] = [];\n            let current = '';\n            let inQuotes = false;\n            \n            for (let i = 0; i < line.length; i++) {\n              const char = line[i];\n              \n              if (char === '\"') {\n                inQuotes = !inQuotes;\n              } else if (char === ',' && !inQuotes) {\n                values.push(current.trim());\n                current = '';\n              } else {\n                current += char;\n              }\n            }\n            values.push(current.trim());\n            \n            return values;\n          });\n          \n          const headers = rows[0];\n          const dataRows = rows.slice(1);\n          \n          resolve({ headers, rows: dataRows });\n        } catch (error: any) {\n          reject(new Error(`Failed to parse CSV: ${  error.message}`));\n        }\n      };\n      \n      reader.onerror = () => reject(new Error('Failed to read file'));\n      reader.readAsText(file);\n    });\n  }\n\n  /**\n   * Auto-detect field types from sample data\n   */\n  static detectFieldType(values: any[]): FieldTypeDetectionResult {\n    const nonEmptyValues = values.filter(v => v !== null && v !== undefined && v !== '');\n    \n    if (nonEmptyValues.length === 0) {\n      return { type: 'text', confidence: 50 };\n    }\n\n    // Email detection\n    const emailPattern = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n    const emailMatches = nonEmptyValues.filter(v => emailPattern.test(String(v))).length;\n    if (emailMatches / nonEmptyValues.length > 0.8) {\n      return { type: 'email', confidence: 90, pattern: 'email' };\n    }\n\n    // Phone detection\n    const phonePattern = /^[\\d\\s\\-\\+\\(\\)]+$/;\n    const phoneMatches = nonEmptyValues.filter(v => {\n      const str = String(v);\n      return phonePattern.test(str) && str.replace(/\\D/g, '').length >= 10;\n    }).length;\n    if (phoneMatches / nonEmptyValues.length > 0.8) {\n      return { type: 'phone', confidence: 85, pattern: 'phone' };\n    }\n\n    // URL detection\n    const urlPattern = /^https?:\\/\\//i;\n    const urlMatches = nonEmptyValues.filter(v => urlPattern.test(String(v))).length;\n    if (urlMatches / nonEmptyValues.length > 0.8) {\n      return { type: 'url', confidence: 90, pattern: 'url' };\n    }\n\n    // Boolean detection\n    const booleanValues = ['true', 'false', 'yes', 'no', '1', '0', 'y', 'n'];\n    const boolMatches = nonEmptyValues.filter(v => \n      booleanValues.includes(String(v).toLowerCase())\n    ).length;\n    if (boolMatches / nonEmptyValues.length > 0.9) {\n      return { type: 'boolean', confidence: 95 };\n    }\n\n    // Number detection\n    const numberMatches = nonEmptyValues.filter(v => !isNaN(Number(v))).length;\n    if (numberMatches / nonEmptyValues.length > 0.9) {\n      // Currency detection\n      const currencyPattern = /^\\$?[\\d,]+\\.?\\d*$/;\n      const currencyMatches = nonEmptyValues.filter(v => currencyPattern.test(String(v))).length;\n      if (currencyMatches / nonEmptyValues.length > 0.8) {\n        return { type: 'currency', confidence: 85, pattern: 'currency' };\n      }\n      return { type: 'number', confidence: 90 };\n    }\n\n    // Date detection\n    const dateMatches = nonEmptyValues.filter(v => {\n      const date = new Date(v);\n      return !isNaN(date.getTime());\n    }).length;\n    if (dateMatches / nonEmptyValues.length > 0.8) {\n      return { type: 'date', confidence: 85, pattern: 'date' };\n    }\n\n    // Select detection (if limited unique values)\n    const uniqueValues = [...new Set(nonEmptyValues)];\n    if (uniqueValues.length <= 10 && uniqueValues.length > 1) {\n      return { type: 'select', confidence: 75, uniqueValues };\n    }\n\n    // Default to text\n    return { type: 'text', confidence: 70 };\n  }\n\n  /**\n   * Auto-detect schema from CSV data\n   */\n  static detectSchema(headers: string[], rows: any[][], entityName: string): DetectedSchema {\n    const fields: DetectedField[] = headers.map((header, index) => {\n      const columnValues = rows.map(row => row[index]).slice(0, 100); // Sample first 100 rows\n      const detection = this.detectFieldType(columnValues);\n      \n      // Clean field name\n      const fieldName = header\n        .toLowerCase()\n        .replace(/[^a-z0-9_]/g, '_')\n        .replace(/_+/g, '_')\n        .replace(/^_|_$/g, '');\n      \n      // Determine if required (less than 10% empty values)\n      const emptyCount = columnValues.filter(v => !v || v === '').length;\n      const required = emptyCount / columnValues.length < 0.1;\n      \n      return {\n        name: fieldName,\n        type: detection.type,\n        required,\n        confidence: detection.confidence,\n        reasoning: `Detected as ${detection.type} based on ${columnValues.length} sample values`,\n        sampleValues: columnValues.slice(0, 5),\n      };\n    });\n\n    // Calculate overall confidence\n    const avgConfidence = fields.reduce((sum, f) => sum + f.confidence, 0) / fields.length;\n\n    // Generate suggestions\n    const suggestions: string[] = [];\n    if (fields.some(f => f.type === 'email')) {\n      suggestions.push('Email field detected - can be used for contact lookup');\n    }\n    if (fields.some(f => f.name.includes('sku') || f.name.includes('id'))) {\n      suggestions.push('Unique identifier detected - can be used to update existing records');\n    }\n    if (fields.some(f => f.type === 'currency')) {\n      suggestions.push('Currency fields detected - will be formatted with $ symbol');\n    }\n\n    return {\n      entityName,\n      fields,\n      confidence: avgConfidence,\n      suggestions,\n    };\n  }\n\n  /**\n   * Generate column mappings\n   */\n  static generateMappings(\n    headers: string[],\n    rows: any[][],\n    existingFields: string[] = []\n  ): ColumnMapping[] {\n    return headers.map((header, index) => {\n      const columnValues = rows.map(row => row[index]).slice(0, 100);\n      const detection = this.detectFieldType(columnValues);\n      \n      const fieldName = header\n        .toLowerCase()\n        .replace(/[^a-z0-9_]/g, '_')\n        .replace(/_+/g, '_')\n        .replace(/^_|_$/g, '');\n\n      // Try to match with existing field\n      const matchedField = existingFields.find(f => \n        f.toLowerCase() === fieldName ||\n        f.toLowerCase().includes(fieldName) ||\n        fieldName.includes(f.toLowerCase())\n      );\n\n      return {\n        csvColumn: header,\n        csvColumnIndex: index,\n        targetField: matchedField || fieldName,\n        fieldType: detection.type,\n        isRequired: false,\n        sampleValues: columnValues.slice(0, 5),\n        detectedType: detection.type,\n        confidence: detection.confidence,\n      };\n    });\n  }\n\n  /**\n   * Validate import data\n   */\n  static validateData(\n    rows: any[][],\n    mappings: ColumnMapping[]\n  ): { valid: boolean; errors: any[] } {\n    const errors: any[] = [];\n\n    rows.forEach((row, rowIndex) => {\n      mappings.forEach(mapping => {\n        const value = row[mapping.csvColumnIndex];\n\n        // Check required fields\n        if (mapping.isRequired && (!value || value === '')) {\n          errors.push({\n            row: rowIndex + 2, // +2 for header and 0-index\n            column: mapping.csvColumn,\n            message: 'Required field is empty',\n            severity: 'error',\n          });\n        }\n\n        // Validate by type\n        if (value && value !== '') {\n          if (mapping.fieldType === 'email' && !this.isValidEmail(value)) {\n            errors.push({\n              row: rowIndex + 2,\n              column: mapping.csvColumn,\n              message: 'Invalid email format',\n              value,\n              severity: 'warning',\n            });\n          }\n          \n          if (mapping.fieldType === 'number' && isNaN(Number(value))) {\n            errors.push({\n              row: rowIndex + 2,\n              column: mapping.csvColumn,\n              message: 'Invalid number format',\n              value,\n              severity: 'error',\n            });\n          }\n        }\n      });\n    });\n\n    return {\n      valid: errors.filter(e => e.severity === 'error').length === 0,\n      errors,\n    };\n  }\n\n  /**\n   * Transform value based on mapping\n   */\n  static transformValue(value: any, mapping: ColumnMapping): any {\n    if (!value || value === '') {return mapping.defaultValue || null;}\n\n    switch (mapping.transform) {\n      case 'trim':\n        return String(value).trim();\n      case 'uppercase':\n        return String(value).toUpperCase();\n      case 'lowercase':\n        return String(value).toLowerCase();\n      case 'phone':\n        return String(value).replace(/\\D/g, '');\n      case 'email':\n        return String(value).toLowerCase().trim();\n      case 'currency':\n        return parseFloat(String(value).replace(/[$,]/g, ''));\n      case 'date':\n        return new Date(value).toISOString();\n      default:\n        return value;\n    }\n  }\n\n  // Helper methods\n  private static isValidEmail(email: string): boolean {\n    return /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(email);\n  }\n}\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\crm\\salesforce.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":30,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":30,"endColumn":76},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":31,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":31,"endColumn":80}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Salesforce Integration\n * CRM functions for Salesforce\n */\n\nimport type { ConnectedIntegration } from '@/types/integrations';\n\n/**\n * Execute a Salesforce function\n */\nexport async function executeSalesforceFunction(\n  functionName: string,\n  parameters: Record<string, any>,\n  integration: ConnectedIntegration\n): Promise<any> {\n  if (!integration.config) {\n    throw new Error('Salesforce configuration missing');\n  }\n  \n  const instanceUrl = integration.config.instanceUrl as string;\n  const accessToken = integration.config.accessToken as string;\n  \n  if (!instanceUrl || !accessToken) {\n    throw new Error('Salesforce credentials not configured');\n  }\n  \n  switch (functionName) {\n    case 'createSalesforceLead':\n      // Validate required parameters\n      const requiredFields = ['firstName', 'lastName', 'email', 'company'];\n      const missingFields = requiredFields.filter(field => !parameters[field]);\n      \n      if (missingFields.length > 0) {\n        throw new Error(`Missing required fields for Salesforce lead: ${missingFields.join(', ')}`);\n      }\n      \n      // Validate types\n      if (typeof parameters.firstName !== 'string' || typeof parameters.lastName !== 'string' || \n          typeof parameters.email !== 'string' || typeof parameters.company !== 'string') {\n        throw new Error('firstName, lastName, email, and company must be strings');\n      }\n      \n      // Optional fields validation\n      if (parameters.phone && typeof parameters.phone !== 'string') {\n        throw new Error('phone must be a string');\n      }\n      if (parameters.notes && typeof parameters.notes !== 'string') {\n        throw new Error('notes must be a string');\n      }\n      \n      return createLead(\n        {\n          firstName: parameters.firstName,\n          lastName: parameters.lastName,\n          email: parameters.email,\n          company: parameters.company,\n          phone: parameters.phone,\n          notes: parameters.notes,\n        },\n        instanceUrl,\n        accessToken\n      );\n      \n    default:\n      throw new Error(`Unknown Salesforce function: ${functionName}`);\n  }\n}\n\n/**\n * Create a lead in Salesforce\n */\nasync function createLead(\n  params: {\n    firstName: string;\n    lastName: string;\n    email: string;\n    company: string;\n    phone?: string;\n    notes?: string;\n  },\n  instanceUrl: string,\n  accessToken: string\n): Promise<{ leadId: string; created: boolean }> {\n  const response = await fetch(`${instanceUrl}/services/data/v58.0/sobjects/Lead`, {\n    method: 'POST',\n    headers: {\n      'Authorization': `Bearer ${accessToken}`,\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      FirstName: params.firstName,\n      LastName: params.lastName,\n      Email: params.email,\n      Company: params.company,\n      Phone: params.phone,\n      Description: params.notes,\n      LeadSource: 'AI Agent',\n    }),\n  });\n  \n  if (!response.ok) {\n    const error = await response.json();\n    throw new Error(`Failed to create lead: ${JSON.stringify(error)}`);\n  }\n  \n  const data = await response.json();\n  \n  return {\n    leadId: data.id,\n    created: data.success,\n  };\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\email\\outlook.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":44,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":44,"endColumn":54},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":45,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":45,"endColumn":50}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Outlook Function Executor\n * Allows AI agent to call Outlook/Microsoft functions\n */\n\nimport type { ConnectedIntegration } from '@/types/integrations';\nimport { sendEmail, listCalendarEvents, createCalendarEvent } from '../outlook-service';\n\n/**\n * Execute an Outlook function\n */\nexport async function executeOutlookFunction(\n  functionName: string,\n  parameters: Record<string, any>,\n  integration: ConnectedIntegration\n): Promise<any> {\n  const accessToken = integration.accessToken || '';\n  \n  if (!accessToken) {\n    throw new Error('Outlook access token not configured');\n  }\n  \n  switch (functionName) {\n    case 'sendEmail':\n      // Validate required parameters\n      if (!parameters.to || typeof parameters.to !== 'string') {\n        throw new Error('to (string) is required for sendEmail');\n      }\n      if (!parameters.subject || typeof parameters.subject !== 'string') {\n        throw new Error('subject (string) is required for sendEmail');\n      }\n      if (!parameters.body || typeof parameters.body !== 'string') {\n        throw new Error('body (string) is required for sendEmail');\n      }\n      \n      return sendEmail(accessToken, {\n        to: parameters.to,\n        subject: parameters.subject,\n        body: parameters.body,\n      });\n      \n    case 'getCalendar':\n      // Optional parameters\n      const startDateTime = parameters.startDateTime;\n      const endDateTime = parameters.endDateTime;\n      \n      return listCalendarEvents(accessToken, {\n        startDateTime,\n        endDateTime,\n      });\n      \n    case 'createCalendarEvent':\n      // Validate required parameters\n      if (!parameters.subject || typeof parameters.subject !== 'string') {\n        throw new Error('subject (string) is required for createCalendarEvent');\n      }\n      if (!parameters.start || typeof parameters.start !== 'string') {\n        throw new Error('start (string) is required for createCalendarEvent');\n      }\n      if (!parameters.end || typeof parameters.end !== 'string') {\n        throw new Error('end (string) is required for createCalendarEvent');\n      }\n      \n      return createCalendarEvent(accessToken, {\n        subject: parameters.subject,\n        body: parameters.body,\n        start: parameters.start,\n        end: parameters.end,\n        attendees: parameters.attendees,\n        location: parameters.location,\n      });\n      \n    default:\n      throw new Error(`Unknown Outlook function: ${functionName}`);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\field-mapper.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":463,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":463,"endColumn":42},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":510,"column":11,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":510,"endColumn":48}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Integration Field Mapper\n * Manages field mappings between internal CRM fields and external integration fields\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport { FieldResolver } from '@/lib/schema/field-resolver';\nimport type { SchemaChangeEvent } from '@/lib/schema/schema-change-tracker';\nimport { executeCustomTransform } from './custom-transforms';\n\n/**\n * Integration Field Mapping\n * Maps internal CRM fields to external system fields\n */\nexport interface IntegrationFieldMapping {\n  id: string;\n  integrationId: string;\n  integrationName: string; // 'salesforce', 'hubspot', 'shopify', etc.\n  organizationId: string;\n  workspaceId: string;\n  \n  // Schema this mapping applies to\n  schemaId: string;\n  schemaName: string;\n  \n  // Field mappings\n  mappings: FieldMappingRule[];\n  \n  // Settings\n  settings: {\n    autoSync: boolean;\n    syncDirection: 'one-way' | 'two-way' | 'inbound' | 'outbound';\n    conflictResolution: 'local_wins' | 'remote_wins' | 'newest_wins' | 'manual';\n  };\n  \n  // Metadata\n  createdAt: string;\n  updatedAt: string;\n  createdBy: string;\n  lastSyncedAt?: string;\n}\n\n/**\n * Field Mapping Rule\n */\nexport interface FieldMappingRule {\n  id: string;\n  \n  // Internal field (CRM)\n  localField: string; // Field key in schema\n  localFieldLabel?: string; // Field label for display\n  \n  // External field (Integration)\n  externalField: string; // Field name in external system\n  externalFieldLabel?: string; // Field label for display\n  \n  // Mapping configuration\n  required: boolean;\n  readonly: boolean; // Don't sync changes to this field\n  \n  // Transformation\n  transform?: FieldTransform;\n  \n  // Validation\n  validationRules?: ValidationRule[];\n}\n\n/**\n * Field Transform\n */\nexport interface FieldTransform {\n  type: 'uppercase' | 'lowercase' | 'trim' | 'phone' | 'currency' | 'date' | 'custom';\n  format?: string; // For date/currency formatting\n  customFunction?: string; // Custom transform function name\n  params?: Record<string, any>; // Parameters for custom transform functions\n  direction?: 'inbound' | 'outbound' | 'both'; // When to apply transform\n}\n\n/**\n * Validation Rule\n */\nexport interface ValidationRule {\n  type: 'regex' | 'min' | 'max' | 'length' | 'enum';\n  value: any;\n  message?: string;\n}\n\n/**\n * Field Mapping Manager\n */\nexport class FieldMappingManager {\n  /**\n   * Create integration field mapping\n   */\n  static async createFieldMapping(\n    mapping: Omit<IntegrationFieldMapping, 'id' | 'createdAt' | 'updatedAt'>\n  ): Promise<IntegrationFieldMapping> {\n    try {\n      const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n      \n      const mappingId = `mapping_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n      \n      const fullMapping: IntegrationFieldMapping = {\n        ...mapping,\n        id: mappingId,\n        createdAt: new Date().toISOString(),\n        updatedAt: new Date().toISOString(),\n      };\n      \n      const mappingsPath = `${COLLECTIONS.ORGANIZATIONS}/${mapping.organizationId}/integrationFieldMappings`;\n      \n      await FirestoreService.set(mappingsPath, mappingId, fullMapping, false);\n      \n      logger.info('[Field Mapper] Created field mapping', {\n        file: 'field-mapper.ts',\n        mappingId,\n        integrationName: mapping.integrationName,\n      });\n      \n      return fullMapping;\n    } catch (error) {\n      logger.error('[Field Mapper] Failed to create field mapping', error, {\n        file: 'field-mapper.ts',\n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * Get field mapping for integration\n   */\n  static async getFieldMapping(\n    organizationId: string,\n    integrationId: string,\n    schemaId?: string\n  ): Promise<IntegrationFieldMapping | null> {\n    try {\n      const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n      const { where } = await import('firebase/firestore');\n      \n      const mappingsPath = `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrationFieldMappings`;\n      \n      const filters: any[] = [\n        where('integrationId', '==', integrationId),\n      ];\n      \n      if (schemaId) {\n        filters.push(where('schemaId', '==', schemaId));\n      }\n      \n      const mappings = await FirestoreService.getAll(mappingsPath, filters);\n      \n      return mappings.length > 0 ? (mappings[0] as IntegrationFieldMapping) : null;\n    } catch (error) {\n      logger.error('[Field Mapper] Failed to get field mapping', error, {\n        file: 'field-mapper.ts',\n        integrationId,\n      });\n      return null;\n    }\n  }\n  \n  /**\n   * Update field mapping\n   */\n  static async updateFieldMapping(\n    organizationId: string,\n    mappingId: string,\n    updates: Partial<IntegrationFieldMapping>\n  ): Promise<void> {\n    try {\n      const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n      \n      const mappingsPath = `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrationFieldMappings`;\n      \n      const existing = await FirestoreService.get(mappingsPath, mappingId);\n      \n      if (!existing) {\n        throw new Error(`Field mapping ${mappingId} not found`);\n      }\n      \n      await FirestoreService.set(\n        mappingsPath,\n        mappingId,\n        {\n          ...existing,\n          ...updates,\n          updatedAt: new Date().toISOString(),\n        },\n        false\n      );\n      \n      logger.info('[Field Mapper] Updated field mapping', {\n        file: 'field-mapper.ts',\n        mappingId,\n      });\n    } catch (error) {\n      logger.error('[Field Mapper] Failed to update field mapping', error, {\n        file: 'field-mapper.ts',\n        mappingId,\n      });\n      throw error;\n    }\n  }\n  \n  /**\n   * Adapt field mapping to schema changes\n   */\n  static async adaptToSchemaChange(\n    event: SchemaChangeEvent\n  ): Promise<void> {\n    try {\n      const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n      const { where } = await import('firebase/firestore');\n      \n      // Get all field mappings for this schema\n      const mappingsPath = `${COLLECTIONS.ORGANIZATIONS}/${event.organizationId}/integrationFieldMappings`;\n      const mappings = await FirestoreService.getAll(mappingsPath, [\n        where('schemaId', '==', event.schemaId),\n      ] as any);\n      \n      if (mappings.length === 0) {\n        logger.info('[Field Mapper] No field mappings found for schema', {\n          file: 'field-mapper.ts',\n          schemaId: event.schemaId,\n        });\n        return;\n      }\n      \n      // Update each mapping\n      for (const mapping of mappings) {\n        const fieldMapping = mapping as IntegrationFieldMapping;\n        let updated = false;\n        \n        switch (event.changeType) {\n          case 'field_renamed':\n          case 'field_key_changed':\n            updated = await this.handleFieldRenameInMapping(\n              fieldMapping,\n              event.oldFieldKey || event.oldFieldName || '',\n              event.newFieldKey || event.newFieldName || ''\n            );\n            break;\n          \n          case 'field_deleted':\n            updated = await this.handleFieldDeletionInMapping(\n              fieldMapping,\n              event.oldFieldKey || event.oldFieldName || ''\n            );\n            break;\n        }\n        \n        if (updated) {\n          await this.updateFieldMapping(\n            event.organizationId,\n            fieldMapping.id,\n            { mappings: fieldMapping.mappings }\n          );\n        }\n      }\n      \n    } catch (error) {\n      logger.error('[Field Mapper] Failed to adapt to schema change', error, {\n        file: 'field-mapper.ts',\n        eventId: event.id,\n      });\n    }\n  }\n  \n  /**\n   * Handle field rename in mapping\n   */\n  private static async handleFieldRenameInMapping(\n    mapping: IntegrationFieldMapping,\n    oldFieldKey: string,\n    newFieldKey: string\n  ): Promise<boolean> {\n    let updated = false;\n    \n    for (const rule of mapping.mappings) {\n      if (rule.localField === oldFieldKey) {\n        rule.localField = newFieldKey;\n        updated = true;\n        \n        logger.info('[Field Mapper] Updated field mapping rule', {\n          file: 'field-mapper.ts',\n          mappingId: mapping.id,\n          ruleId: rule.id,\n          oldKey: oldFieldKey,\n          newKey: newFieldKey,\n        });\n      }\n    }\n    \n    return updated;\n  }\n  \n  /**\n   * Handle field deletion in mapping\n   */\n  private static async handleFieldDeletionInMapping(\n    mapping: IntegrationFieldMapping,\n    deletedFieldKey: string\n  ): Promise<boolean> {\n    let updated = false;\n    \n    // Find rules using the deleted field\n    const affectedRules = mapping.mappings.filter(\n      rule => rule.localField === deletedFieldKey\n    );\n    \n    if (affectedRules.length > 0) {\n      // Mark as needing user action\n      for (const rule of affectedRules) {\n        rule.readonly = true; // Disable sync for this field\n        updated = true;\n        \n        logger.warn('[Field Mapper] Field deleted - mapping disabled', {\n          file: 'field-mapper.ts',\n          mappingId: mapping.id,\n          ruleId: rule.id,\n          deletedField: deletedFieldKey,\n        });\n      }\n    }\n    \n    return updated;\n  }\n  \n  /**\n   * Map local record to external format\n   */\n  static async mapLocalToExternal(\n    localRecord: any,\n    mapping: IntegrationFieldMapping,\n    schema: any\n  ): Promise<Record<string, any>> {\n    const externalRecord: Record<string, any> = {};\n    \n    for (const rule of mapping.mappings) {\n      if (rule.readonly && mapping.settings.syncDirection === 'outbound') {\n        continue; // Skip readonly fields for outbound sync\n      }\n      \n      // Get local value using field resolver\n      const value = FieldResolver.getFieldValue(localRecord, rule.localField, schema);\n      \n      if (value === undefined || value === null) {\n        if (rule.required) {\n          logger.warn('[Field Mapper] Required field missing', {\n            file: 'field-mapper.ts',\n            field: rule.localField,\n          });\n        }\n        continue;\n      }\n      \n      // Apply transformation\n      let transformedValue = value;\n      if (rule.transform && this.shouldApplyTransform(rule.transform, 'outbound')) {\n        transformedValue = await this.applyTransform(value, rule.transform);\n      }\n      \n      // Validate\n      if (rule.validationRules) {\n        const valid = await this.validateValue(transformedValue, rule.validationRules);\n        if (!valid) {\n          logger.warn('[Field Mapper] Validation failed', {\n            file: 'field-mapper.ts',\n            field: rule.localField,\n            value: transformedValue,\n          });\n          continue;\n        }\n      }\n      \n      externalRecord[rule.externalField] = transformedValue;\n    }\n    \n    return externalRecord;\n  }\n  \n  /**\n   * Map external record to local format\n   */\n  static async mapExternalToLocal(\n    externalRecord: any,\n    mapping: IntegrationFieldMapping,\n    schema: any\n  ): Promise<Record<string, any>> {\n    const localRecord: Record<string, any> = {};\n    \n    for (const rule of mapping.mappings) {\n      if (rule.readonly && mapping.settings.syncDirection === 'inbound') {\n        continue; // Skip readonly fields for inbound sync\n      }\n      \n      const value = externalRecord[rule.externalField];\n      \n      if (value === undefined || value === null) {\n        continue;\n      }\n      \n      // Apply transformation\n      let transformedValue = value;\n      if (rule.transform && this.shouldApplyTransform(rule.transform, 'inbound')) {\n        transformedValue = await this.applyTransform(value, rule.transform);\n      }\n      \n      // Resolve local field (in case it was renamed)\n      const resolvedField = await FieldResolver.resolveField(schema, rule.localField);\n      \n      if (!resolvedField) {\n        logger.warn('[Field Mapper] Local field not found', {\n          file: 'field-mapper.ts',\n          field: rule.localField,\n        });\n        continue;\n      }\n      \n      localRecord[resolvedField.fieldKey] = transformedValue;\n    }\n    \n    return localRecord;\n  }\n  \n  /**\n   * Check if transform should be applied for direction\n   */\n  private static shouldApplyTransform(\n    transform: FieldTransform,\n    direction: 'inbound' | 'outbound'\n  ): boolean {\n    if (!transform.direction || transform.direction === 'both') {\n      return true;\n    }\n    return transform.direction === direction;\n  }\n  \n  /**\n   * Apply field transformation\n   */\n  private static async applyTransform(\n    value: any,\n    transform: FieldTransform\n  ): Promise<any> {\n    switch (transform.type) {\n      case 'uppercase':\n        return String(value).toUpperCase();\n      \n      case 'lowercase':\n        return String(value).toLowerCase();\n      \n      case 'trim':\n        return String(value).trim();\n      \n      case 'phone':\n        // Normalize phone number (remove non-digits)\n        return String(value).replace(/\\D/g, '');\n      \n      case 'currency':\n        // Format as currency\n        const amount = parseFloat(value);\n        return isNaN(amount) ? value : amount.toFixed(2);\n      \n      case 'date':\n        // Format date\n        if (transform.format) {\n          // Apply date formatting (would use date-fns or similar)\n          return new Date(value).toISOString();\n        }\n        return value;\n      \n      case 'custom':\n        // Execute custom transform function from registry\n        if (transform.customFunction) {\n          const result = executeCustomTransform(\n            transform.customFunction,\n            value,\n            transform.params\n          );\n          \n          if (result.success) {\n            return result.value;\n          } else {\n            logger.warn('[Field Mapper] Custom transform failed', {\n              function: transform.customFunction,\n              error: result.error,\n              file: 'field-mapper.ts',\n            });\n          }\n        }\n        return value;\n      \n      default:\n        return value;\n    }\n  }\n  \n  /**\n   * Validate value against rules\n   */\n  private static async validateValue(\n    value: any,\n    rules: ValidationRule[]\n  ): Promise<boolean> {\n    for (const rule of rules) {\n      switch (rule.type) {\n        case 'regex':\n          const regex = new RegExp(rule.value);\n          if (!regex.test(String(value))) {\n            return false;\n          }\n          break;\n        \n        case 'min':\n          if (Number(value) < Number(rule.value)) {\n            return false;\n          }\n          break;\n        \n        case 'max':\n          if (Number(value) > Number(rule.value)) {\n            return false;\n          }\n          break;\n        \n        case 'length':\n          if (String(value).length !== Number(rule.value)) {\n            return false;\n          }\n          break;\n        \n        case 'enum':\n          if (!Array.isArray(rule.value) || !rule.value.includes(value)) {\n            return false;\n          }\n          break;\n      }\n    }\n    \n    return true;\n  }\n}\n\n/**\n * Get default field mappings for common integrations\n */\nexport function getDefaultFieldMappings(\n  integrationName: string\n): Partial<Record<string, string>> {\n  const mappings: Record<string, Partial<Record<string, string>>> = {\n    salesforce: {\n      'firstName': 'FirstName',\n      'lastName': 'LastName',\n      'email': 'Email',\n      'phone': 'Phone',\n      'company': 'Company',\n      'title': 'Title',\n      'address': 'Street',\n      'city': 'City',\n      'state': 'State',\n      'zip': 'PostalCode',\n      'country': 'Country',\n    },\n    hubspot: {\n      'firstName': 'firstname',\n      'lastName': 'lastname',\n      'email': 'email',\n      'phone': 'phone',\n      'company': 'company',\n      'title': 'jobtitle',\n      'website': 'website',\n      'address': 'address',\n      'city': 'city',\n      'state': 'state',\n      'zip': 'zip',\n    },\n    shopify: {\n      'name': 'title',\n      'price': 'price',\n      'description': 'body_html',\n      'sku': 'sku',\n      'inventory': 'inventory_quantity',\n      'weight': 'weight',\n      'images': 'images',\n    },\n  };\n  \n  return mappings[integrationName.toLowerCase()] || {};\n}\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\oauth-service.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":236,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":236,"endColumn":62},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":255,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":255,"endColumn":62},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":274,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":274,"endColumn":51},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":294,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":294,"endColumn":61},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":314,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":314,"endColumn":49}],"suppressedMessages":[],"errorCount":5,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * OAuth Service\n * Handles OAuth 2.0 authorization flows for integrations\n */\n\nimport { FirestoreService, COLLECTIONS } from '@/lib/db/firestore-service';\nimport { apiKeyService } from '@/lib/api-keys/api-key-service';\nimport crypto from 'crypto';\n\nexport interface OAuthConfig {\n  provider: 'google' | 'microsoft' | 'slack' | 'quickbooks' | 'xero';\n  clientId: string;\n  clientSecret: string;\n  redirectUri: string;\n  scopes: string[];\n  authorizationUrl: string;\n  tokenUrl: string;\n}\n\n// Lightweight config map for tests and fallback defaults\nexport const OAuthConfig: Record<string, Partial<OAuthConfig>> = {\n  google: { provider: 'google', authorizationUrl: 'https://accounts.google.com/o/oauth2/auth', tokenUrl: 'https://oauth2.googleapis.com/token', scopes: [] },\n  microsoft: { provider: 'microsoft', authorizationUrl: 'https://login.microsoftonline.com/common/oauth2/v2.0/authorize', tokenUrl: 'https://login.microsoftonline.com/common/oauth2/v2.0/token', scopes: [] },\n  quickbooks: { provider: 'quickbooks', authorizationUrl: 'https://appcenter.intuit.com/connect/oauth2', tokenUrl: 'https://oauth.platform.intuit.com/oauth2/v1/tokens/bearer', scopes: [] },\n  xero: { provider: 'xero', authorizationUrl: 'https://login.xero.com/identity/connect/authorize', tokenUrl: 'https://identity.xero.com/connect/token', scopes: [] },\n};\n\nexport interface OAuthState {\n  state: string;\n  organizationId: string;\n  workspaceId?: string;\n  integrationId: string;\n  provider: string;\n  createdAt: Date;\n}\n\n/**\n * Generate OAuth authorization URL\n */\nexport async function generateAuthUrl(\n  organizationId: string,\n  workspaceId: string | undefined,\n  integrationId: string,\n  provider: 'google' | 'microsoft' | 'slack' | 'quickbooks' | 'xero'\n): Promise<string> {\n  // Get OAuth config\n  const config = await getOAuthConfig(organizationId, provider);\n  \n  // Generate state token\n  const state = crypto.randomBytes(32).toString('hex');\n  \n  // Save state to Firestore\n  await FirestoreService.set(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/oauthStates`,\n    state,\n    {\n      state,\n      organizationId,\n      workspaceId,\n      integrationId,\n      provider,\n      createdAt: new Date().toISOString(),\n    },\n    false\n  );\n  \n  // Build authorization URL\n  const params = new URLSearchParams({\n    client_id: config.clientId,\n    redirect_uri: config.redirectUri,\n    response_type: 'code',\n    scope: config.scopes.join(' '),\n    state,\n    access_type: 'offline', // For refresh tokens\n    prompt: 'consent', // Force consent to get refresh token\n  });\n  \n  return `${config.authorizationUrl}?${params.toString()}`;\n}\n\n/**\n * Exchange authorization code for tokens\n */\nexport async function exchangeCodeForTokens(\n  code: string,\n  state: string\n): Promise<{\n  accessToken: string;\n  refreshToken?: string;\n  expiresIn?: number;\n  tokenType?: string;\n  [key: string]: any;\n}> {\n  // Verify state\n  const stateData = await FirestoreService.get<OAuthState>(\n    `${COLLECTIONS.ORGANIZATIONS}/*/oauthStates`,\n    state\n  );\n  \n  if (!stateData) {\n    throw new Error('Invalid state token');\n  }\n  \n  // Check if state is expired (5 minutes)\n  const createdAt = new Date(stateData.createdAt);\n  const now = new Date();\n  if (now.getTime() - createdAt.getTime() > 5 * 60 * 1000) {\n    throw new Error('State token expired');\n  }\n  \n  // Get OAuth config\n  const config = await getOAuthConfig(stateData.organizationId, stateData.provider as any);\n  \n  // Exchange code for tokens\n  const tokenResponse = await fetch(config.tokenUrl, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/x-www-form-urlencoded',\n    },\n    body: new URLSearchParams({\n      client_id: config.clientId,\n      client_secret: config.clientSecret,\n      code,\n      grant_type: 'authorization_code',\n      redirect_uri: config.redirectUri,\n    }),\n  });\n  \n  if (!tokenResponse.ok) {\n    const error = await tokenResponse.text();\n    throw new Error(`Token exchange failed: ${error}`);\n  }\n  \n  const tokens = await tokenResponse.json();\n  \n  // Save tokens to integration\n  await saveIntegrationTokens(\n    stateData.organizationId,\n    stateData.workspaceId,\n    stateData.integrationId,\n    stateData.provider,\n    tokens\n  );\n  \n  // Delete state token\n  await FirestoreService.delete(\n    `${COLLECTIONS.ORGANIZATIONS}/${stateData.organizationId}/oauthStates`,\n    state\n  );\n  \n  return tokens;\n}\n\n/**\n * Refresh access token\n */\nexport async function refreshAccessToken(\n  organizationId: string,\n  integrationId: string,\n  provider: string\n): Promise<string> {\n  // Get integration\n  const integration = await FirestoreService.get(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`,\n    integrationId\n  );\n  \n  if (!integration) {\n    throw new Error('Integration not found');\n  }\n  \n  const refreshToken = (integration as any).refreshToken;\n  if (!refreshToken) {\n    throw new Error('No refresh token available');\n  }\n  \n  // Get OAuth config\n  const config = await getOAuthConfig(organizationId, provider as any);\n  \n  // Refresh token\n  const tokenResponse = await fetch(config.tokenUrl, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/x-www-form-urlencoded',\n    },\n    body: new URLSearchParams({\n      client_id: config.clientId,\n      client_secret: config.clientSecret,\n      refresh_token: refreshToken,\n      grant_type: 'refresh_token',\n    }),\n  });\n  \n  if (!tokenResponse.ok) {\n    throw new Error('Token refresh failed');\n  }\n  \n  const tokens = await tokenResponse.json();\n  \n  // Update integration with new tokens\n  await FirestoreService.set(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`,\n    integrationId,\n    {\n      ...integration,\n      accessToken: tokens.access_token,\n      refreshToken: tokens.refresh_token || refreshToken, // Keep old refresh token if new one not provided\n      tokenExpiresAt: tokens.expires_in\n        ? new Date(Date.now() + tokens.expires_in * 1000).toISOString()\n        : undefined,\n      updatedAt: new Date().toISOString(),\n    },\n    true // Update only\n  );\n  \n  return tokens.access_token;\n}\n\n/**\n * Get OAuth config for provider\n */\nasync function getOAuthConfig(\n  organizationId: string,\n  provider: 'google' | 'microsoft' | 'slack' | 'quickbooks' | 'xero'\n): Promise<OAuthConfig> {\n  const apiKeys = await apiKeyService.getServiceKey(organizationId, 'integrations');\n  \n  if (!apiKeys) {\n    throw new Error('Integration API keys not configured');\n  }\n  \n  const baseUrl = process.env.NEXT_PUBLIC_APP_URL || 'https://app.example.com';\n  \n  switch (provider) {\n    case 'google':\n      const google = (apiKeys).integrations?.googleWorkspace;\n      if (!google?.clientId || !google?.clientSecret) {\n        throw new Error('Google OAuth credentials not configured');\n      }\n      return {\n        provider: 'google',\n        clientId: google.clientId,\n        clientSecret: google.clientSecret,\n        redirectUri: `${baseUrl}/api/integrations/oauth/callback/google`,\n        scopes: [\n          'https://www.googleapis.com/auth/gmail.readonly',\n          'https://www.googleapis.com/auth/calendar',\n          'https://www.googleapis.com/auth/drive.readonly',\n        ],\n        authorizationUrl: 'https://accounts.google.com/o/oauth2/v2/auth',\n        tokenUrl: 'https://oauth2.googleapis.com/token',\n      };\n    \n    case 'microsoft':\n      const microsoft = (apiKeys).integrations?.microsoft365;\n      if (!microsoft?.clientId || !microsoft?.clientSecret) {\n        throw new Error('Microsoft OAuth credentials not configured');\n      }\n      return {\n        provider: 'microsoft',\n        clientId: microsoft.clientId,\n        clientSecret: microsoft.clientSecret,\n        redirectUri: `${baseUrl}/api/integrations/oauth/callback/microsoft`,\n        scopes: [\n          'https://graph.microsoft.com/Mail.Read',\n          'https://graph.microsoft.com/Calendars.ReadWrite',\n          'https://graph.microsoft.com/User.Read',\n        ],\n        authorizationUrl: `https://login.microsoftonline.com/${microsoft.tenantId || 'common'}/oauth2/v2.0/authorize`,\n        tokenUrl: `https://login.microsoftonline.com/${microsoft.tenantId || 'common'}/oauth2/v2.0/token`,\n      };\n    \n    case 'slack':\n      const slack = (apiKeys).integrations?.slack;\n      if (!slack?.clientId || !slack?.clientSecret) {\n        throw new Error('Slack OAuth credentials not configured');\n      }\n      return {\n        provider: 'slack',\n        clientId: slack.clientId,\n        clientSecret: slack.clientSecret,\n        redirectUri: `${baseUrl}/api/integrations/oauth/callback/slack`,\n        scopes: [\n          'channels:read',\n          'chat:write',\n          'users:read',\n          'team:read',\n        ],\n        authorizationUrl: 'https://slack.com/oauth/v2/authorize',\n        tokenUrl: 'https://slack.com/api/oauth.v2.access',\n      };\n    \n    case 'quickbooks':\n      const quickbooks = (apiKeys).integrations?.quickbooks;\n      if (!quickbooks?.clientId || !quickbooks?.clientSecret) {\n        throw new Error('QuickBooks OAuth credentials not configured');\n      }\n      return {\n        provider: 'quickbooks',\n        clientId: quickbooks.clientId,\n        clientSecret: quickbooks.clientSecret,\n        redirectUri: `${baseUrl}/api/integrations/oauth/callback/quickbooks`,\n        scopes: [\n          'com.intuit.quickbooks.accounting',\n          'com.intuit.quickbooks.payment',\n        ],\n        authorizationUrl: quickbooks.environment === 'production'\n          ? 'https://appcenter.intuit.com/connect/oauth2'\n          : 'https://appcenter.intuit.com/connect/oauth2', // Same for both\n        tokenUrl: 'https://oauth.platform.intuit.com/oauth2/v1/tokens/bearer',\n      };\n    \n    case 'xero':\n      const xero = (apiKeys).integrations?.xero;\n      if (!xero?.clientId || !xero?.clientSecret) {\n        throw new Error('Xero OAuth credentials not configured');\n      }\n      return {\n        provider: 'xero',\n        clientId: xero.clientId,\n        clientSecret: xero.clientSecret,\n        redirectUri: `${baseUrl}/api/integrations/oauth/callback/xero`,\n        scopes: [\n          'offline_access',\n          'accounting.transactions',\n          'accounting.contacts',\n          'accounting.settings',\n        ],\n        authorizationUrl: 'https://login.xero.com/identity/connect/authorize',\n        tokenUrl: 'https://identity.xero.com/connect/token',\n      };\n    \n    default:\n      throw new Error(`Unsupported provider: ${provider}`);\n  }\n}\n\n/**\n * Save integration tokens\n */\nasync function saveIntegrationTokens(\n  organizationId: string,\n  workspaceId: string | undefined,\n  integrationId: string,\n  provider: string,\n  tokens: any\n): Promise<void> {\n  // Get or create integration\n  const integration = await FirestoreService.get(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`,\n    integrationId\n  );\n  \n  const integrationData: any = {\n    id: integrationId,\n    organizationId,\n    workspaceId,\n    provider,\n    accessToken: tokens.access_token,\n    refreshToken: tokens.refresh_token,\n    tokenExpiresAt: tokens.expires_in\n      ? new Date(Date.now() + tokens.expires_in * 1000).toISOString()\n      : undefined,\n    status: 'connected',\n    connectedAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n  };\n  \n  // Provider-specific data\n  if (provider === 'google') {\n    // Get user info\n    const userInfo = await fetch('https://www.googleapis.com/oauth2/v2/userinfo', {\n      headers: {\n        Authorization: `Bearer ${tokens.access_token}`,\n      },\n    }).then(r => r.json());\n    \n    integrationData.email = userInfo.email;\n    integrationData.name = userInfo.name;\n  } else if (provider === 'microsoft') {\n    const userInfo = await fetch('https://graph.microsoft.com/v1.0/me', {\n      headers: {\n        Authorization: `Bearer ${tokens.access_token}`,\n      },\n    }).then(r => r.json());\n    \n    integrationData.email = userInfo.mail || userInfo.userPrincipalName;\n    integrationData.name = userInfo.displayName;\n    integrationData.tenantId = userInfo.tenantId;\n  } else if (provider === 'slack') {\n    integrationData.teamId = tokens.team?.id;\n    integrationData.teamName = tokens.team?.name;\n    integrationData.botUserId = tokens.bot_user_id;\n  }\n  \n  await FirestoreService.set(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`,\n    integrationId,\n    integration ? { ...integration, ...integrationData } : integrationData,\n    false\n  );\n}\n\n/**\n * Get valid access token (refresh if needed)\n */\nexport async function getValidAccessToken(\n  organizationId: string,\n  integrationId: string\n): Promise<string> {\n  const integration = await FirestoreService.get(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`,\n    integrationId\n  );\n  \n  if (!integration) {\n    throw new Error('Integration not found');\n  }\n  \n  const accessToken = (integration as any).accessToken;\n  const tokenExpiresAt = (integration as any).tokenExpiresAt;\n  const provider = (integration as any).provider;\n  \n  // Check if token is expired or about to expire (within 5 minutes)\n  if (tokenExpiresAt) {\n    const expiresAt = new Date(tokenExpiresAt);\n    const now = new Date();\n    const fiveMinutesFromNow = new Date(now.getTime() + 5 * 60 * 1000);\n    \n    if (expiresAt <= fiveMinutesFromNow) {\n      // Refresh token\n      return refreshAccessToken(organizationId, integrationId, provider);\n    }\n  }\n  \n  return accessToken;\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\payment\\paypal.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":30,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":34,"endColumn":9}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * PayPal Function Executor\n * Allows AI agent to call PayPal functions\n */\n\nimport type { ConnectedIntegration } from '@/types/integrations';\nimport { createOrder, getOrderDetails, captureOrder } from '../paypal-service';\n\n/**\n * Execute a PayPal function\n */\nexport async function executePayPalFunction(\n  functionName: string,\n  parameters: Record<string, any>,\n  integration: ConnectedIntegration\n): Promise<any> {\n  const organizationId = integration.organizationId || '';\n  \n  if (!organizationId) {\n    throw new Error('Organization ID not configured');\n  }\n  \n  switch (functionName) {\n    case 'createPayment':\n      // Validate required parameters\n      if (typeof parameters.amount !== 'number') {\n        throw new Error('amount (number) is required for createPayment');\n      }\n      \n      const order = await createOrder(\n        organizationId,\n        parameters.amount,\n        parameters.currency || 'USD'\n      );\n      \n      return {\n        orderId: order.id,\n        approvalUrl: order.links?.find((l: any) => l.rel === 'approve')?.href,\n        status: order.status,\n      };\n      \n    case 'getTransaction':\n      // Validate required parameters\n      if (!parameters.orderId || typeof parameters.orderId !== 'string') {\n        throw new Error('orderId (string) is required for getTransaction');\n      }\n      \n      return getOrderDetails(organizationId, parameters.orderId);\n      \n    case 'capturePayment':\n      // Validate required parameters\n      if (!parameters.orderId || typeof parameters.orderId !== 'string') {\n        throw new Error('orderId (string) is required for capturePayment');\n      }\n      \n      return captureOrder(organizationId, parameters.orderId);\n      \n    default:\n      throw new Error(`Unknown PayPal function: ${functionName}`);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\payment\\square.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":49,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":65,"endColumn":10},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":72,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":72,"endColumn":42},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":85,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":99,"endColumn":10},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":106,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":106,"endColumn":58}],"suppressedMessages":[],"errorCount":4,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Square Function Executor\r\n * Allows AI agent to call Square functions\r\n */\r\n\r\nimport type { ConnectedIntegration } from '@/types/integrations';\r\nimport { apiKeyService } from '@/lib/api-keys/api-key-service';\r\n\r\n/**\r\n * Execute a Square function\r\n */\r\nexport async function executeSquareFunction(\r\n  functionName: string,\r\n  parameters: Record<string, any>,\r\n  integration: ConnectedIntegration\r\n): Promise<any> {\r\n  const organizationId = integration.organizationId || '';\r\n  \r\n  if (!organizationId) {\r\n    throw new Error('Organization ID not configured');\r\n  }\r\n  \r\n  // Get Square API keys from organization settings\r\n  const keys = await apiKeyService.getKeys(organizationId);\r\n  const squareConfig = keys?.payments?.square as any;\r\n  const squareAccessToken = squareConfig?.accessToken;\r\n  \r\n  if (!squareAccessToken) {\r\n    throw new Error('Square not configured. Please add your Square access token in Settings > API Keys');\r\n  }\r\n  \r\n  // Check if production mode based on access token prefix or explicit mode setting\r\n  const isProduction = squareAccessToken.startsWith('sq0atp-') || squareConfig?.environment === 'production';\r\n  const baseUrl = isProduction\r\n    ? 'https://connect.squareup.com'\r\n    : 'https://connect.squareupsandbox.com';\r\n  \r\n  switch (functionName) {\r\n    case 'processPayment':\r\n      // Validate required parameters\r\n      if (typeof parameters.amount !== 'number') {\r\n        throw new Error('amount (number) is required for processPayment');\r\n      }\r\n      if (!parameters.sourceId || typeof parameters.sourceId !== 'string') {\r\n        throw new Error('sourceId (string) is required for processPayment');\r\n      }\r\n      \r\n      // Create payment\r\n      const response = await fetch(`${baseUrl}/v2/payments`, {\r\n        method: 'POST',\r\n        headers: {\r\n          'Authorization': `Bearer ${squareAccessToken}`,\r\n          'Content-Type': 'application/json',\r\n          'Square-Version': '2023-10-18',\r\n        },\r\n        body: JSON.stringify({\r\n          source_id: parameters.sourceId,\r\n          idempotency_key: `${Date.now()}-${Math.random()}`,\r\n          amount_money: {\r\n            amount: parameters.amount,\r\n            currency: parameters.currency || 'USD',\r\n          },\r\n          autocomplete: true,\r\n        }),\r\n      });\r\n      \r\n      if (!response.ok) {\r\n        const error = await response.json();\r\n        throw new Error(`Square API error: ${error.errors?.[0]?.detail || response.statusText}`);\r\n      }\r\n      \r\n      const data = await response.json();\r\n      return {\r\n        paymentId: data.payment.id,\r\n        status: data.payment.status,\r\n        receiptUrl: data.payment.receipt_url,\r\n      };\r\n      \r\n    case 'createCustomer':\r\n      // Validate required parameters\r\n      if (!parameters.email || typeof parameters.email !== 'string') {\r\n        throw new Error('email (string) is required for createCustomer');\r\n      }\r\n      \r\n      const customerResponse = await fetch(`${baseUrl}/v2/customers`, {\r\n        method: 'POST',\r\n        headers: {\r\n          'Authorization': `Bearer ${squareAccessToken}`,\r\n          'Content-Type': 'application/json',\r\n          'Square-Version': '2023-10-18',\r\n        },\r\n        body: JSON.stringify({\r\n          idempotency_key: `${Date.now()}-${Math.random()}`,\r\n          email_address: parameters.email,\r\n          given_name: parameters.givenName,\r\n          family_name: parameters.familyName,\r\n          phone_number: parameters.phoneNumber,\r\n        }),\r\n      });\r\n      \r\n      if (!customerResponse.ok) {\r\n        const error = await customerResponse.json();\r\n        throw new Error(`Square API error: ${error.errors?.[0]?.detail || customerResponse.statusText}`);\r\n      }\r\n      \r\n      const customerData = await customerResponse.json();\r\n      return customerData.customer;\r\n      \r\n    default:\r\n      throw new Error(`Unknown Square function: ${functionName}`);\r\n  }\r\n}\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\integrations\\video\\zoom.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":52,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":59,"endColumn":9},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":65,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":65,"endColumn":62}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Zoom Function Executor\n * Allows AI agent to call Zoom functions\n */\n\nimport type { ConnectedIntegration } from '@/types/integrations';\nimport { createZoomMeeting, cancelZoomMeeting } from '../zoom';\n\n/**\n * Execute a Zoom function\n */\nexport async function executeZoomFunction(\n  functionName: string,\n  parameters: Record<string, any>,\n  integration: ConnectedIntegration\n): Promise<any> {\n  const organizationId = integration.organizationId || '';\n  const accessToken = integration.accessToken || '';\n  \n  if (!organizationId) {\n    throw new Error('Organization ID not configured');\n  }\n  \n  if (!accessToken) {\n    throw new Error('Zoom access token not configured');\n  }\n  \n  switch (functionName) {\n    case 'createMeeting':\n      // Validate required parameters\n      if (!parameters.topic || typeof parameters.topic !== 'string') {\n        throw new Error('topic (string) is required for createMeeting');\n      }\n      if (!parameters.startTime || typeof parameters.startTime !== 'string') {\n        throw new Error('startTime (string) is required for createMeeting');\n      }\n      if (typeof parameters.duration !== 'number') {\n        throw new Error('duration (number) is required for createMeeting');\n      }\n      \n      return createZoomMeeting(organizationId, {\n        topic: parameters.topic,\n        startTime: new Date(parameters.startTime),\n        duration: parameters.duration,\n        timezone: parameters.timezone,\n        agenda: parameters.agenda,\n        attendees: parameters.attendees,\n      });\n      \n    case 'getRecordings':\n      // Get recordings using Zoom API\n      const recordingsResponse = await fetch(\n        `https://api.zoom.us/v2/users/me/recordings?from=${parameters.from || new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString().split('T')[0]}`,\n        {\n          headers: {\n            'Authorization': `Bearer ${accessToken}`,\n          },\n        }\n      );\n      \n      if (!recordingsResponse.ok) {\n        throw new Error('Failed to fetch Zoom recordings');\n      }\n      \n      const recordingsData = await recordingsResponse.json();\n      return recordingsData.meetings || [];\n      \n    case 'cancelMeeting':\n      // Validate required parameters\n      if (!parameters.meetingId || typeof parameters.meetingId !== 'string') {\n        throw new Error('meetingId (string) is required for cancelMeeting');\n      }\n      \n      return cancelZoomMeeting(organizationId, parameters.meetingId);\n      \n    default:\n      throw new Error(`Unknown Zoom function: ${functionName}`);\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\middleware\\rate-limiter.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":210,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":210,"endColumn":63},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":221,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":222,"endColumn":72}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Rate Limiter Middleware\n * \n * Prevents API abuse by limiting request rates per user/organization.\n * \n * Features:\n * - In-memory rate limiting with TTL\n * - Multiple rate limit strategies (per user, per org, per IP)\n * - Sliding window algorithm\n * - Configurable limits and windows\n * \n * Usage:\n * ```typescript\n * export async function POST(request: NextRequest) {\n *   const rateLimit = await checkRateLimit(request, {\n *     limit: 10,\n *     windowMs: 60000 // 10 requests per minute\n *   });\n *   \n *   if (!rateLimit.allowed) {\n *     return NextResponse.json({ error: 'Too many requests' }, { status: 429 });\n *   }\n *   \n *   // ... continue with request\n * }\n * ```\n */\n\nimport type { NextRequest } from 'next/server';\nimport { logger } from '@/lib/logger/logger';\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\nexport interface RateLimitConfig {\n  /** Maximum number of requests allowed within the window */\n  limit: number;\n  \n  /** Time window in milliseconds (default: 60000 = 1 minute) */\n  windowMs?: number;\n  \n  /** Identifier strategy (default: 'ip') */\n  strategy?: 'ip' | 'user' | 'org' | 'custom';\n  \n  /** Custom identifier (required if strategy is 'custom') */\n  identifier?: string;\n  \n  /** Skip rate limiting for certain conditions */\n  skip?: (request: NextRequest) => boolean | Promise<boolean>;\n}\n\nexport interface RateLimitResult {\n  /** Whether the request is allowed */\n  allowed: boolean;\n  \n  /** Current request count */\n  current: number;\n  \n  /** Maximum requests allowed */\n  limit: number;\n  \n  /** Time until limit resets (ms) */\n  resetMs: number;\n  \n  /** Number of remaining requests */\n  remaining: number;\n}\n\ninterface RateLimitEntry {\n  count: number;\n  resetAt: number;\n}\n\n// ============================================================================\n// IN-MEMORY STORE\n// ============================================================================\n\n/**\n * Simple in-memory rate limit store\n * Note: For production with multiple instances, use Redis or similar\n */\nclass RateLimitStore {\n  private store: Map<string, RateLimitEntry> = new Map();\n  private cleanupInterval: NodeJS.Timeout;\n  \n  constructor() {\n    // Clean up expired entries every minute\n    this.cleanupInterval = setInterval(() => {\n      this.cleanup();\n    }, 60000);\n  }\n  \n  /**\n   * Increment counter for identifier\n   */\n  increment(identifier: string, windowMs: number): RateLimitEntry {\n    const now = Date.now();\n    const existing = this.store.get(identifier);\n    \n    // If entry exists and hasn't expired, increment\n    if (existing && existing.resetAt > now) {\n      existing.count++;\n      return existing;\n    }\n    \n    // Create new entry\n    const entry: RateLimitEntry = {\n      count: 1,\n      resetAt: now + windowMs\n    };\n    \n    this.store.set(identifier, entry);\n    return entry;\n  }\n  \n  /**\n   * Get current entry for identifier\n   */\n  get(identifier: string): RateLimitEntry | null {\n    const entry = this.store.get(identifier);\n    \n    if (!entry) {\n      return null;\n    }\n    \n    // Check if expired\n    if (entry.resetAt <= Date.now()) {\n      this.store.delete(identifier);\n      return null;\n    }\n    \n    return entry;\n  }\n  \n  /**\n   * Reset counter for identifier\n   */\n  reset(identifier: string): void {\n    this.store.delete(identifier);\n  }\n  \n  /**\n   * Clean up expired entries\n   */\n  private cleanup(): void {\n    const now = Date.now();\n    let cleaned = 0;\n    \n    for (const [key, entry] of this.store.entries()) {\n      if (entry.resetAt <= now) {\n        this.store.delete(key);\n        cleaned++;\n      }\n    }\n    \n    if (cleaned > 0) {\n      logger.info(`Rate limiter cleaned up ${cleaned} expired entries`);\n    }\n  }\n  \n  /**\n   * Get store size (for monitoring)\n   */\n  size(): number {\n    return this.store.size;\n  }\n  \n  /**\n   * Clear all entries (for testing)\n   */\n  clear(): void {\n    this.store.clear();\n  }\n  \n  /**\n   * Stop cleanup interval\n   */\n  destroy(): void {\n    if (this.cleanupInterval) {\n      clearInterval(this.cleanupInterval);\n    }\n  }\n}\n\n// Global store instance\nconst store = new RateLimitStore();\n\n// ============================================================================\n// RATE LIMITING FUNCTIONS\n// ============================================================================\n\n/**\n * Get identifier for rate limiting based on strategy\n */\nasync function getIdentifier(\n  request: NextRequest,\n  strategy: RateLimitConfig['strategy'],\n  customIdentifier?: string\n): Promise<string> {\n  switch (strategy) {\n    case 'custom':\n      if (!customIdentifier) {\n        throw new Error('Custom identifier required for custom strategy');\n      }\n      return customIdentifier;\n      \n    case 'user':\n      // Extract user ID from request (e.g., from auth header)\n      const authHeader = request.headers.get('authorization');\n      if (authHeader) {\n        // Parse user ID from JWT or session\n        // This is a placeholder - implement based on your auth system\n        return `user:${authHeader}`;\n      }\n      // Fallback to IP if no auth\n      return `ip:${getClientIp(request)}`;\n      \n    case 'org':\n      // Extract organization ID from request\n      const orgId = request.headers.get('x-organization-id') || \n                    request.nextUrl.searchParams.get('organizationId');\n      if (orgId) {\n        return `org:${orgId}`;\n      }\n      // Fallback to IP if no org ID\n      return `ip:${getClientIp(request)}`;\n      \n    case 'ip':\n    default:\n      return `ip:${getClientIp(request)}`;\n  }\n}\n\n/**\n * Get client IP address from request\n */\nfunction getClientIp(request: NextRequest): string {\n  // Check for forwarded IP (behind proxy)\n  const forwarded = request.headers.get('x-forwarded-for');\n  if (forwarded) {\n    return forwarded.split(',')[0].trim();\n  }\n  \n  const realIp = request.headers.get('x-real-ip');\n  if (realIp) {\n    return realIp;\n  }\n  \n  // Fallback (may not work in all environments)\n  return 'unknown';\n}\n\n/**\n * Check if request is rate limited\n * \n * @param request - Next.js request object\n * @param config - Rate limit configuration\n * @returns Rate limit result\n */\nexport async function checkRateLimit(\n  request: NextRequest,\n  config: RateLimitConfig\n): Promise<RateLimitResult> {\n  const {\n    limit,\n    windowMs = 60000, // Default: 1 minute\n    strategy = 'ip',\n    identifier: customIdentifier,\n    skip\n  } = config;\n  \n  try {\n    // Check if rate limiting should be skipped\n    if (skip && await skip(request)) {\n      return {\n        allowed: true,\n        current: 0,\n        limit,\n        resetMs: 0,\n        remaining: limit\n      };\n    }\n    \n    // Get identifier based on strategy\n    const identifier = await getIdentifier(request, strategy, customIdentifier);\n    \n    // Increment counter\n    const entry = store.increment(identifier, windowMs);\n    \n    // Calculate result\n    const allowed = entry.count <= limit;\n    const resetMs = entry.resetAt - Date.now();\n    const remaining = Math.max(0, limit - entry.count);\n    \n    // Log if rate limit exceeded\n    if (!allowed) {\n      logger.warn('Rate limit exceeded', {\n        identifier,\n        current: entry.count,\n        limit,\n        strategy\n      });\n    }\n    \n    return {\n      allowed,\n      current: entry.count,\n      limit,\n      resetMs,\n      remaining\n    };\n    \n  } catch (error) {\n    // On error, allow request but log\n    logger.error('Rate limiter error', error as Error);\n    \n    return {\n      allowed: true,\n      current: 0,\n      limit,\n      resetMs: 0,\n      remaining: limit\n    };\n  }\n}\n\n/**\n * Rate limit middleware helper\n * Returns a 429 response if rate limit exceeded\n */\nexport async function rateLimitMiddleware(\n  request: NextRequest,\n  config: RateLimitConfig\n): Promise<Response | null> {\n  const result = await checkRateLimit(request, config);\n  \n  if (!result.allowed) {\n    return new Response(\n      JSON.stringify({\n        success: false,\n        error: 'Too many requests',\n        message: `Rate limit exceeded. Try again in ${Math.ceil(result.resetMs / 1000)} seconds.`,\n        rateLimit: {\n          limit: result.limit,\n          current: result.current,\n          remaining: result.remaining,\n          resetMs: result.resetMs\n        }\n      }),\n      {\n        status: 429,\n        headers: {\n          'Content-Type': 'application/json',\n          'X-RateLimit-Limit': result.limit.toString(),\n          'X-RateLimit-Remaining': result.remaining.toString(),\n          'X-RateLimit-Reset': new Date(Date.now() + result.resetMs).toISOString(),\n          'Retry-After': Math.ceil(result.resetMs / 1000).toString()\n        }\n      }\n    );\n  }\n  \n  return null; // Allow request to proceed\n}\n\n/**\n * Reset rate limit for identifier (useful for testing)\n */\nexport function resetRateLimit(identifier: string): void {\n  store.reset(identifier);\n}\n\n/**\n * Get store statistics (for monitoring)\n */\nexport function getRateLimitStats() {\n  return {\n    activeEntries: store.size()\n  };\n}\n\n// ============================================================================\n// PRESET CONFIGURATIONS\n// ============================================================================\n\n/**\n * Preset rate limits for common use cases\n */\nexport const RateLimitPresets = {\n  /** Strict: 10 requests per minute */\n  STRICT: {\n    limit: 10,\n    windowMs: 60000\n  },\n  \n  /** Standard: 60 requests per minute */\n  STANDARD: {\n    limit: 60,\n    windowMs: 60000\n  },\n  \n  /** Generous: 300 requests per minute */\n  GENEROUS: {\n    limit: 300,\n    windowMs: 60000\n  },\n  \n  /** AI endpoints: 20 requests per minute (expensive operations) */\n  AI_OPERATIONS: {\n    limit: 20,\n    windowMs: 60000\n  },\n  \n  /** Data mutations: 30 requests per minute */\n  MUTATIONS: {\n    limit: 30,\n    windowMs: 60000\n  },\n  \n  /** Read operations: 120 requests per minute */\n  READS: {\n    limit: 120,\n    windowMs: 60000\n  }\n} as const;\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\monitoring\\health-check.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":253,"column":63,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":253,"endColumn":76}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Health Check & Monitoring Service\n * System health monitoring and alerting\n */\n\nimport { logger } from '@/lib/logger/logger';\n\nexport interface HealthCheckResult {\n  status: 'healthy' | 'degraded' | 'unhealthy';\n  timestamp: string;\n  uptime: number;\n  checks: {\n    database: HealthStatus;\n    cache: HealthStatus;\n    ai: HealthStatus;\n    payments: HealthStatus;\n    integrations: HealthStatus;\n  };\n  metrics: {\n    memory: MemoryMetrics;\n    cpu: CPUMetrics;\n    requests: RequestMetrics;\n  };\n}\n\nexport interface HealthStatus {\n  status: 'pass' | 'warn' | 'fail';\n  message?: string;\n  responseTime?: number;\n  lastChecked: string;\n}\n\nexport interface MemoryMetrics {\n  used: number;\n  total: number;\n  percentage: number;\n}\n\nexport interface CPUMetrics {\n  usage: number;\n  loadAverage: number[];\n}\n\nexport interface RequestMetrics {\n  total: number;\n  errorsLast24h: number;\n  avgResponseTime: number;\n}\n\n/**\n * Perform comprehensive health check\n */\nexport async function performHealthCheck(): Promise<HealthCheckResult> {\n  const startTime = Date.now();\n  \n  const [\n    databaseHealth,\n    cacheHealth,\n    aiHealth,\n    paymentsHealth,\n    integrationsHealth,\n  ] = await Promise.all([\n    checkDatabase(),\n    checkCache(),\n    checkAI(),\n    checkPayments(),\n    checkIntegrations(),\n  ]);\n  \n  const metrics = await gatherMetrics();\n  \n  // Determine overall status\n  const allChecks = [\n    databaseHealth,\n    cacheHealth,\n    aiHealth,\n    paymentsHealth,\n    integrationsHealth,\n  ];\n  \n  let status: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';\n  \n  if (allChecks.some(check => check.status === 'fail')) {\n    status = 'unhealthy';\n  } else if (allChecks.some(check => check.status === 'warn')) {\n    status = 'degraded';\n  }\n  \n  return {\n    status,\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    checks: {\n      database: databaseHealth,\n      cache: cacheHealth,\n      ai: aiHealth,\n      payments: paymentsHealth,\n      integrations: integrationsHealth,\n    },\n    metrics,\n  };\n}\n\n/**\n * Check database connectivity\n */\nasync function checkDatabase(): Promise<HealthStatus> {\n  const startTime = Date.now();\n  \n  try {\n    const { FirestoreService } = await import('@/lib/db/firestore-service');\n    \n    // Simple ping query\n    await FirestoreService.get('_health', 'check');\n    \n    const responseTime = Date.now() - startTime;\n    \n    return {\n      status: responseTime < 100 ? 'pass' : responseTime < 500 ? 'warn' : 'fail',\n      message: `Database responding in ${responseTime}ms`,\n      responseTime,\n      lastChecked: new Date().toISOString(),\n    };\n  } catch (error: any) {\n    return {\n      status: 'fail',\n      message: `Database error: ${error.message}`,\n      lastChecked: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Check cache connectivity\n */\nasync function checkCache(): Promise<HealthStatus> {\n  const startTime = Date.now();\n  \n  try {\n    const { cacheService } = await import('@/lib/cache/redis-service');\n    \n    // Test cache operation\n    await cacheService.set('_health_check', Date.now(), { ttl: 10 });\n    await cacheService.get('_health_check');\n    \n    const responseTime = Date.now() - startTime;\n    \n    return {\n      status: 'pass',\n      message: `Cache responding in ${responseTime}ms`,\n      responseTime,\n      lastChecked: new Date().toISOString(),\n    };\n  } catch (error: any) {\n    return {\n      status: 'warn',\n      message: `Cache unavailable (using fallback): ${error.message}`,\n      lastChecked: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Check AI services\n */\nasync function checkAI(): Promise<HealthStatus> {\n  try {\n    // Check if AI services are configured\n    const hasGemini = !!process.env.GEMINI_API_KEY;\n    const hasOpenAI = !!process.env.OPENAI_API_KEY;\n    const hasAnthropic = !!process.env.ANTHROPIC_API_KEY;\n    \n    if (!hasGemini && !hasOpenAI && !hasAnthropic) {\n      return {\n        status: 'fail',\n        message: 'No AI providers configured',\n        lastChecked: new Date().toISOString(),\n      };\n    }\n    \n    return {\n      status: 'pass',\n      message: `AI providers configured: ${[hasGemini && 'Gemini', hasOpenAI && 'OpenAI', hasAnthropic && 'Anthropic'].filter(Boolean).join(', ')}`,\n      lastChecked: new Date().toISOString(),\n    };\n  } catch (error: any) {\n    return {\n      status: 'fail',\n      message: `AI check error: ${error.message}`,\n      lastChecked: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Check payment services\n */\nasync function checkPayments(): Promise<HealthStatus> {\n  try {\n    const hasStripe = !!process.env.STRIPE_SECRET_KEY;\n    \n    return {\n      status: hasStripe ? 'pass' : 'warn',\n      message: hasStripe ? 'Payment providers configured' : 'No payment providers configured',\n      lastChecked: new Date().toISOString(),\n    };\n  } catch (error: any) {\n    return {\n      status: 'warn',\n      message: `Payment check error: ${error.message}`,\n      lastChecked: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Check integrations\n */\nasync function checkIntegrations(): Promise<HealthStatus> {\n  try {\n    return {\n      status: 'pass',\n      message: 'Integrations operational',\n      lastChecked: new Date().toISOString(),\n    };\n  } catch (error: any) {\n    return {\n      status: 'warn',\n      message: `Integration check error: ${error.message}`,\n      lastChecked: new Date().toISOString(),\n    };\n  }\n}\n\n/**\n * Gather system metrics\n */\nasync function gatherMetrics(): Promise<{\n  memory: MemoryMetrics;\n  cpu: CPUMetrics;\n  requests: RequestMetrics;\n}> {\n  const memUsage = process.memoryUsage();\n  \n  return {\n    memory: {\n      used: memUsage.heapUsed,\n      total: memUsage.heapTotal,\n      percentage: (memUsage.heapUsed / memUsage.heapTotal) * 100,\n    },\n    cpu: {\n      usage: process.cpuUsage().user / 1000000, // Convert to seconds\n      loadAverage: process.platform === 'win32' ? [0, 0, 0] : require('os').loadavg(),\n    },\n    requests: {\n      total: 0, // Would be tracked by middleware\n      errorsLast24h: 0, // Would be tracked by error handler\n      avgResponseTime: 0, // Would be tracked by middleware\n    },\n  };\n}\n\n/**\n * Send alert if system is unhealthy\n */\nexport async function sendAlert(health: HealthCheckResult): Promise<void> {\n  if (health.status === 'healthy') {return;}\n  \n  logger.error('[Health Check] System is unhealthy', new Error(`System status: ${health.status}`), { \n    status: health.status, \n    health,\n    file: 'health-check.ts' \n  });\n  \n  // In production, send to Slack/PagerDuty/Email\n  if (process.env.SLACK_WEBHOOK_URL) {\n    try {\n      await fetch(process.env.SLACK_WEBHOOK_URL, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          text: `üö® System Health Alert: ${health.status.toUpperCase()}`,\n          attachments: [{\n            color: health.status === 'unhealthy' ? 'danger' : 'warning',\n            fields: Object.entries(health.checks).map(([name, check]) => ({\n              title: name,\n              value: `${check.status}: ${check.message || 'N/A'}`,\n              short: true,\n            })),\n          }],\n        }),\n      });\n    } catch (error) {\n      logger.error('[Health Check] Failed to send Slack alert:', error, { file: 'health-check.ts' });\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\orchestration\\coordinator-factory-server.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":35,"column":20,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":35,"endColumn":51},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":36,"column":26,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":36,"endColumn":61}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * SignalCoordinator Factory - SERVER ONLY\n * \n * This file is for server-side (Node.js) contexts only.\n * Uses firebase-admin and admin-dal.\n * \n * USAGE:\n * ```typescript\n * import { getServerSignalCoordinator } from '@/lib/orchestration/coordinator-factory-server';\n * \n * const coordinator = getServerSignalCoordinator();\n * await coordinator.emitSignal({...});\n * ```\n */\n\nimport 'server-only';\n\nimport type { SignalCoordinatorConfig } from './SignalCoordinator';\nimport { SignalCoordinator } from './SignalCoordinator';\n\n// Lazy-loaded instance to avoid circular dependencies\nlet serverCoordinator: SignalCoordinator | null = null;\n\n/**\n * Get SignalCoordinator for server-side (admin) context\n * Uses firebase-admin and admin-dal\n */\nexport function getServerSignalCoordinator(config?: SignalCoordinatorConfig): SignalCoordinator {\n  if (serverCoordinator) {\n    return serverCoordinator;\n  }\n\n  try {\n    // Import server-side dependencies\n    const { db } = require('@/lib/firebase-admin');\n    const { adminDal } = require('@/lib/firebase/admin-dal');\n    \n    if (!db) {\n      throw new Error('Firebase Admin DB not initialized');\n    }\n    \n    if (!adminDal) {\n      throw new Error('Admin DAL not initialized');\n    }\n\n    // Create server coordinator\n    serverCoordinator = new SignalCoordinator(db, adminDal, config);\n    \n    return serverCoordinator;\n  } catch (error) {\n    throw new Error(`Failed to create server SignalCoordinator: ${error instanceof Error ? error.message : 'Unknown error'}`);\n  }\n}\n\n/**\n * Reset coordinator instance (useful for testing)\n */\nexport function resetServerCoordinator(): void {\n  serverCoordinator = null;\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\outbound\\sequence-engine.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":598,"column":11,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":600,"endColumn":13},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":605,"column":11,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":607,"endColumn":13},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":612,"column":11,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":612,"endColumn":76},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":617,"column":11,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":617,"endColumn":80}],"suppressedMessages":[],"errorCount":4,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Sequence Engine\n * Core logic for managing and executing email sequences\n */\n\nimport type { \n  OutboundSequence,\n  ProspectEnrollment,\n  SequenceStep,\n  StepAction} from '@/types/outbound-sequence';\nimport {\n  EnrollmentStatus,\n  StepActionStatus \n} from '@/types/outbound-sequence';\nimport { FirestoreService, COLLECTIONS } from '@/lib/db/firestore-service'\nimport { logger } from '@/lib/logger/logger';;\n\nexport class SequenceEngine {\n  /**\n   * Enroll a prospect in a sequence\n   */\n  static async enrollProspect(\n    prospectId: string,\n    sequenceId: string,\n    organizationId: string\n  ): Promise<ProspectEnrollment> {\n    \n\n    // Load sequence\n    const sequence = await this.getSequence(sequenceId, organizationId);\n    if (!sequence) {\n      throw new Error('Sequence not found');\n    }\n\n    if (sequence.status !== 'active') {\n      throw new Error('Cannot enroll in inactive sequence');\n    }\n\n    // Check if already enrolled\n    const existing = await this.getEnrollment(prospectId, sequenceId, organizationId);\n    if (existing?.status === 'active') {\n      throw new Error('Prospect already enrolled in this sequence');\n    }\n\n    // Create enrollment\n    const enrollment: ProspectEnrollment = {\n      id: `enrollment_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n      sequenceId,\n      prospectId,\n      organizationId,\n      status: 'active',\n      currentStep: 0,\n      enrolledAt: new Date().toISOString(),\n      nextStepAt: this.calculateNextStepTime(sequence.steps[0]),\n      stepActions: [],\n      createdAt: new Date().toISOString(),\n      updatedAt: new Date().toISOString(),\n    };\n\n    // Save enrollment\n    await this.saveEnrollment(enrollment);\n\n    // Schedule first step\n    await this.scheduleStep(enrollment, sequence.steps[0]);\n\n    // Update sequence analytics\n    await this.updateSequenceAnalytics(sequenceId, organizationId, {\n      totalEnrolled: 1,\n      activeProspects: 1,\n    });\n\n    \n\n    return enrollment;\n  }\n\n  /**\n   * Unenroll a prospect from a sequence\n   */\n  static async unenrollProspect(\n    prospectId: string,\n    sequenceId: string,\n    organizationId: string,\n    reason: 'manual' | 'replied' | 'converted' | 'unsubscribed' | 'bounced'\n  ): Promise<void> {\n    \n\n    const enrollment = await this.getEnrollment(prospectId, sequenceId, organizationId);\n    if (!enrollment) {\n      throw new Error('Enrollment not found');\n    }\n\n    enrollment.status = reason === 'unsubscribed' ? 'unsubscribed' : \n                         reason === 'bounced' ? 'bounced' : 'removed';\n    enrollment.outcome = reason === 'manual' ? 'removed' : reason;\n    enrollment.outcomeDate = new Date().toISOString();\n    enrollment.completedAt = new Date().toISOString();\n    enrollment.updatedAt = new Date().toISOString();\n\n    await this.saveEnrollment(enrollment);\n\n    // Update sequence analytics\n    await this.updateSequenceAnalytics(sequenceId, organizationId, {\n      activeProspects: -1,\n      completedProspects: 1,\n    });\n  }\n\n  /**\n   * Process next step for a prospect\n   */\n  static async processNextStep(\n    enrollmentId: string,\n    organizationId: string\n  ): Promise<void> {\n    const enrollment = await this.getEnrollmentById(enrollmentId, organizationId);\n    if (enrollment?.status !== 'active') {\n      return; // Nothing to process\n    }\n\n    const sequence = await this.getSequence(enrollment.sequenceId, organizationId);\n    if (sequence?.status !== 'active') {\n      return;\n    }\n\n    const currentStepIndex = enrollment.currentStep;\n    const currentStep = sequence.steps[currentStepIndex];\n\n    if (!currentStep) {\n      // Sequence completed\n      await this.completeEnrollment(enrollment, organizationId);\n      return;\n    }\n\n    // Check if it's time to send\n    const now = new Date();\n    const nextStepTime = enrollment.nextStepAt ? new Date(enrollment.nextStepAt) : now;\n\n    if (now < nextStepTime) {\n      return; // Not time yet\n    }\n\n    // Check step conditions\n    if (!(await this.checkStepConditions(enrollment, currentStep))) {\n      \n      await this.skipStep(enrollment, currentStep, organizationId);\n      return;\n    }\n\n    // Execute step\n    await this.executeStep(enrollment, currentStep, sequence, organizationId);\n  }\n\n  /**\n   * Execute a sequence step (send email, create task, etc.)\n   */\n  private static async executeStep(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    sequence: OutboundSequence,\n    organizationId: string\n  ): Promise<void> {\n    \n\n    try {\n      // Create step action\n      const action: StepAction = {\n        stepId: step.id,\n        stepOrder: step.order,\n        scheduledFor: enrollment.nextStepAt || new Date().toISOString(),\n        status: 'sent',\n        subject: step.subject,\n        body: step.body,\n        createdAt: new Date().toISOString(),\n      };\n\n      // Execute based on step type\n      switch (step.type) {\n        case 'email':\n          await this.sendEmail(enrollment, step, organizationId);\n          action.sentAt = new Date().toISOString();\n          break;\n\n        case 'linkedin_message':\n          await this.sendLinkedInMessage(enrollment, step, organizationId);\n          action.sentAt = new Date().toISOString();\n          break;\n\n        case 'sms':\n          await this.sendSMS(enrollment, step, organizationId);\n          action.sentAt = new Date().toISOString();\n          break;\n\n        case 'call_task':\n        case 'manual_task':\n          await this.createTask(enrollment, step, organizationId);\n          action.status = 'scheduled';\n          break;\n      }\n\n      // Add action to enrollment\n      enrollment.stepActions.push(action);\n\n      // Move to next step\n      enrollment.currentStep += 1;\n\n      // Schedule next step\n      const nextStep = sequence.steps[enrollment.currentStep];\n      if (nextStep) {\n        enrollment.nextStepAt = this.calculateNextStepTime(nextStep, new Date());\n      } else {\n        // No more steps - mark as completed\n        enrollment.nextStepAt = undefined;\n      }\n\n      enrollment.updatedAt = new Date().toISOString();\n\n      await this.saveEnrollment(enrollment);\n\n      // Update step analytics\n      await this.updateStepAnalytics(step.id, organizationId, {\n        sent: 1,\n      });\n\n      // Update sequence analytics\n      await this.updateSequenceAnalytics(sequence.id, organizationId, {\n        totalSent: 1,\n      });\n\n      \n    } catch (error: any) {\n      logger.error('[Sequence Engine] Error executing step:', error, { file: 'sequence-engine.ts' });\n\n      // Record failed action\n      const failedAction: StepAction = {\n        stepId: step.id,\n        stepOrder: step.order,\n        scheduledFor: enrollment.nextStepAt || new Date().toISOString(),\n        status: 'failed',\n        error: error.message,\n        retryCount: 0,\n        createdAt: new Date().toISOString(),\n      };\n\n      enrollment.stepActions.push(failedAction);\n      enrollment.updatedAt = new Date().toISOString();\n\n      await this.saveEnrollment(enrollment);\n    }\n  }\n\n  /**\n   * Send email for a step\n   */\n  private static async sendEmail(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    organizationId: string\n  ): Promise<void> {\n    const { FirestoreService, COLLECTIONS } = await import('@/lib/db/firestore-service');\n    \n    // Get prospect email from CRM\n    const prospect = await FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/leads`,\n      enrollment.prospectId\n    );\n\n    if (!prospect?.email) {\n      throw new Error('Prospect email not found');\n    }\n\n    // Get organization settings to determine email provider\n    const org = await FirestoreService.get(COLLECTIONS.ORGANIZATIONS, organizationId);\n    const emailProvider = org?.emailProvider || 'gmail'; // Default to Gmail\n    const fromEmail = org?.fromEmail || process.env.FROM_EMAIL;\n\n    if (!fromEmail) {\n      throw new Error('FROM_EMAIL not configured for this organization');\n    }\n\n    // Try Gmail API first (free, integrated)\n    try {\n      const { sendEmailViaGmail } = await import('@/lib/integrations/gmail-service');\n      \n      await sendEmailViaGmail({\n        to: prospect.email,\n        from: fromEmail,\n        subject: step.subject || 'Follow-up',\n        body: step.body,\n        organizationId,\n        metadata: {\n          enrollmentId: enrollment.id,\n          stepId: step.id,\n          prospectId: enrollment.prospectId,\n        },\n      });\n\n      logger.info('Sequence Engine Email sent via Gmail to prospect.email}', { file: 'sequence-engine.ts' });\n      return;\n    } catch (gmailError: any) {\n      logger.warn('[Sequence Engine] Gmail send failed, trying fallback', { error: gmailError.message, file: 'sequence-engine.ts' });\n      \n      // Fallback to SendGrid if Gmail fails\n      if (emailProvider === 'sendgrid') {\n        const { getAPIKey } = await import('@/lib/config/api-keys');\n        const sendgridKey = await getAPIKey(organizationId, 'sendgrid');\n        \n        if (!sendgridKey) {\n          throw new Error('Gmail failed and SendGrid not configured. Cannot send email.');\n        }\n\n        const { sendEmail } = await import('@/lib/email/sendgrid-service');\n        const result = await sendEmail({\n          to: prospect.email,\n          subject: step.subject || 'Follow-up',\n          html: step.body,\n          tracking: {\n            trackOpens: true,\n            trackClicks: true,\n          },\n          metadata: {\n            enrollmentId: enrollment.id,\n            stepId: step.id,\n            organizationId,\n            prospectId: enrollment.prospectId,\n          },\n        }, sendgridKey);\n\n        if (!result.success) {\n          throw new Error(result.error || 'Failed to send email via SendGrid');\n        }\n\n        logger.info('Sequence Engine Email sent via SendGrid to prospect.email}', { file: 'sequence-engine.ts' });\n      } else {\n        throw gmailError;\n      }\n    }\n  }\n\n  /**\n   * Send LinkedIn message\n   */\n  private static async sendLinkedInMessage(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    organizationId: string\n  ): Promise<void> {\n    \n    \n    // Get prospect details\n    const prospect = await FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/prospects`,\n      enrollment.prospectId\n    );\n    \n    if (!prospect) {\n      throw new Error(`Prospect ${enrollment.prospectId} not found`);\n    }\n    \n    // Get LinkedIn integration credentials\n    const integrations = await FirestoreService.getAll(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/integrations`\n    );\n    const integration = integrations.filter((i: any) => i.service === 'linkedin');\n    \n    if (!integration || integration.length === 0) {\n      throw new Error('LinkedIn integration not configured');\n    }\n    \n    const linkedInToken = integration[0].accessToken;\n    \n    // Send LinkedIn message via RapidAPI or LinkedIn API\n    const { sendLinkedInMessage } = await import('@/lib/integrations/linkedin-messaging');\n    \n    await sendLinkedInMessage(\n      linkedInToken,\n      prospect.linkedInUrl || prospect.email,\n      step.content || '',\n      organizationId\n    );\n    \n    // Track step execution\n    await this.trackStepExecution(enrollment.id, step.id, organizationId, 'success');\n  }\n\n  /**\n   * Send SMS\n   */\n  private static async sendSMS(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    organizationId: string\n  ): Promise<void> {\n    \n    \n    // Get prospect details\n    const prospect = await FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/prospects`,\n      enrollment.prospectId\n    );\n    \n    if (!prospect?.phone) {\n      throw new Error(`Prospect ${enrollment.prospectId} has no phone number`);\n    }\n    \n    // Send SMS via Twilio\n    const { sendSMS } = await import('@/lib/sms/sms-service');\n    \n    const result = await sendSMS({\n      to: prospect.phone,\n      message: step.content || '',\n      organizationId,\n    });\n    \n    if (!result.success) {\n      throw new Error(result.error || 'Failed to send SMS');\n    }\n    \n    // Save SMS record with Twilio message ID for webhook tracking\n    const smsRecordId = result.messageId || `${Date.now()}-${enrollment.prospectId}`;\n    await FirestoreService.set(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/smsMessages`,\n      smsRecordId,\n      {\n        id: smsRecordId,\n        messageId: result.messageId, // Twilio SID for webhook matching\n        prospectId: enrollment.prospectId,\n        sequenceId: enrollment.sequenceId,\n        enrollmentId: enrollment.id,\n        stepId: step.id,\n        to: prospect.phone,\n        message: step.content,\n        status: 'sent',\n        sentAt: new Date().toISOString(),\n        provider: result.provider || 'twilio',\n        createdAt: new Date().toISOString(),\n        updatedAt: new Date().toISOString(),\n      }\n    );\n    \n    // Track step execution\n    await this.trackStepExecution(enrollment.id, step.id, organizationId, 'success');\n  }\n\n  /**\n   * Create task\n   */\n  private static async createTask(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    organizationId: string\n  ): Promise<void> {\n    \n    \n    // Get prospect details\n    const prospect = await FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/prospects`,\n      enrollment.prospectId\n    );\n    \n    if (!prospect) {\n      throw new Error(`Prospect ${enrollment.prospectId} not found`);\n    }\n    \n    // Calculate task due date\n    const dueDate = new Date();\n    dueDate.setDate(dueDate.getDate() + (step.taskDueDays || 1));\n    \n    // Create task in CRM\n    const taskId = `task-${Date.now()}-${enrollment.prospectId}`;\n    const task = {\n      id: taskId,\n      organizationId,\n      title: step.taskTitle || `Follow up with ${prospect.name}`,\n      description: step.content || `Automated task from sequence: ${enrollment.sequenceId}`,\n      type: 'follow-up',\n      status: 'pending',\n      priority: step.taskPriority || 'medium',\n      dueDate,\n      relatedTo: {\n        type: 'prospect',\n        id: enrollment.prospectId,\n        name: prospect.name,\n      },\n      sequenceId: enrollment.sequenceId,\n      stepId: step.id,\n      assignedTo: step.taskAssignee || 'unassigned',\n      createdBy: 'sequence-engine',\n      createdAt: new Date(),\n      updatedAt: new Date(),\n    };\n    \n    await FirestoreService.set(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/tasks`,\n      taskId,\n      task\n    );\n    \n    // Track step execution\n    await this.trackStepExecution(enrollment.id, step.id, organizationId, 'success');\n  }\n  \n  /**\n   * Track step execution for analytics\n   */\n  private static async trackStepExecution(\n    enrollmentId: string,\n    stepId: string,\n    organizationId: string,\n    status: 'success' | 'failed' | 'skipped',\n    error?: string\n  ): Promise<void> {\n    try {\n      const analyticsId = `${enrollmentId}-${stepId}-${Date.now()}`;\n      \n      await FirestoreService.set(\n        `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/sequenceAnalytics`,\n        analyticsId,\n        {\n          enrollmentId,\n          stepId,\n          status,\n          error,\n          executedAt: new Date(),\n          createdAt: new Date(),\n        }\n      );\n      \n      // Update step statistics\n      const statsId = `step-${stepId}`;\n      const currentStats = await FirestoreService.get(\n        `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/sequenceStepStats`,\n        statsId\n      );\n      \n      const stats = currentStats || {\n        stepId,\n        totalExecutions: 0,\n        successCount: 0,\n        failedCount: 0,\n        skippedCount: 0,\n      };\n      \n      stats.totalExecutions += 1;\n      if (status === 'success') {stats.successCount += 1;}\n      if (status === 'failed') {stats.failedCount += 1;}\n      if (status === 'skipped') {stats.skippedCount += 1;}\n      stats.successRate = (stats.successCount / stats.totalExecutions) * 100;\n      stats.updatedAt = new Date();\n      \n      await FirestoreService.set(\n        `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/sequenceStepStats`,\n        statsId,\n        stats\n      );\n    } catch (error) {\n      logger.error('[Sequence Engine] Error tracking step execution:', error, { file: 'sequence-engine.ts' });\n      // Don't throw - analytics failure shouldn't stop execution\n    }\n  }\n\n  /**\n   * Calculate when next step should execute\n   */\n  private static calculateNextStepTime(\n    step: SequenceStep,\n    fromDate: Date = new Date()\n  ): string {\n    const nextTime = new Date(fromDate);\n    nextTime.setDate(nextTime.getDate() + step.delayDays);\n    \n    if (step.delayHours) {\n      nextTime.setHours(nextTime.getHours() + step.delayHours);\n    }\n\n    // Apply send time if specified\n    if (step.sendTime) {\n      nextTime.setHours(step.sendTime.hour, step.sendTime.minute, 0, 0);\n    }\n\n    return nextTime.toISOString();\n  }\n\n  /**\n   * Check if step conditions are met\n   */\n  private static async checkStepConditions(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep\n  ): Promise<boolean> {\n    if (!step.conditions || step.conditions.length === 0) {\n      return true; // No conditions, always proceed\n    }\n\n    for (const condition of step.conditions) {\n      switch (condition.type) {\n        case 'opened_previous':\n          const previousOpened = enrollment.stepActions.some(\n            a => a.stepOrder === step.order - 1 && a.openedAt\n          );\n          if (!previousOpened) {return false;}\n          break;\n\n        case 'not_opened_previous':\n          const previousNotOpened = !enrollment.stepActions.some(\n            a => a.stepOrder === step.order - 1 && a.openedAt\n          );\n          if (!previousNotOpened) {return false;}\n          break;\n\n        case 'replied':\n          const hasReplied = enrollment.stepActions.some(a => a.repliedAt);\n          if (!hasReplied) {return false;}\n          break;\n\n        case 'not_replied':\n          const hasNotReplied = !enrollment.stepActions.some(a => a.repliedAt);\n          if (!hasNotReplied) {return false;}\n          break;\n      }\n    }\n\n    return true;\n  }\n\n  /**\n   * Skip a step\n   */\n  private static async skipStep(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep,\n    organizationId: string\n  ): Promise<void> {\n    const skippedAction: StepAction = {\n      stepId: step.id,\n      stepOrder: step.order,\n      scheduledFor: enrollment.nextStepAt || new Date().toISOString(),\n      status: 'skipped',\n      createdAt: new Date().toISOString(),\n    };\n\n    enrollment.stepActions.push(skippedAction);\n    enrollment.currentStep += 1;\n    enrollment.updatedAt = new Date().toISOString();\n\n    await this.saveEnrollment(enrollment);\n  }\n\n  /**\n   * Complete enrollment\n   */\n  private static async completeEnrollment(\n    enrollment: ProspectEnrollment,\n    organizationId: string\n  ): Promise<void> {\n    enrollment.status = 'completed';\n    enrollment.outcome = 'completed';\n    enrollment.completedAt = new Date().toISOString();\n    enrollment.outcomeDate = new Date().toISOString();\n    enrollment.updatedAt = new Date().toISOString();\n\n    await this.saveEnrollment(enrollment);\n\n    await this.updateSequenceAnalytics(enrollment.sequenceId, organizationId, {\n      activeProspects: -1,\n      completedProspects: 1,\n    });\n  }\n\n  /**\n   * Get sequence from Firestore\n   */\n  private static async getSequence(\n    sequenceId: string,\n    organizationId: string\n  ): Promise<OutboundSequence | null> {\n    return FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/sequences`,\n      sequenceId\n    );\n  }\n\n  /**\n   * Get enrollment\n   */\n  private static async getEnrollment(\n    prospectId: string,\n    sequenceId: string,\n    organizationId: string\n  ): Promise<ProspectEnrollment | null> {\n    try {\n      const { where, limit } = await import('firebase/firestore');\n      \n      const enrollments = await FirestoreService.getAll<ProspectEnrollment>(\n        `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/enrollments`,\n        [\n          where('prospectId', '==', prospectId),\n          where('sequenceId', '==', sequenceId),\n          limit(1)\n        ]\n      );\n      \n      return enrollments.length > 0 ? enrollments[0] : null;\n    } catch (error) {\n      logger.error('[SequenceEngine] Error getting enrollment:', error, { file: 'sequence-engine.ts' });\n    return null;\n    }\n  }\n\n  /**\n   * Get enrollment by ID\n   */\n  private static async getEnrollmentById(\n    enrollmentId: string,\n    organizationId: string\n  ): Promise<ProspectEnrollment | null> {\n    return FirestoreService.get(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/enrollments`,\n      enrollmentId\n    );\n  }\n\n  /**\n   * Save enrollment\n   */\n  private static async saveEnrollment(enrollment: ProspectEnrollment): Promise<void> {\n    await FirestoreService.set(\n      `${COLLECTIONS.ORGANIZATIONS}/${enrollment.organizationId}/enrollments`,\n      enrollment.id,\n      enrollment,\n      false\n    );\n  }\n\n  /**\n   * Update sequence analytics\n   */\n  private static async updateSequenceAnalytics(\n    sequenceId: string,\n    organizationId: string,\n    updates: Partial<OutboundSequence['analytics']>\n  ): Promise<void> {\n    const sequence = await this.getSequence(sequenceId, organizationId);\n    if (!sequence) {return;}\n\n    // Increment analytics\n    if (updates && sequence.analytics) {\n      Object.keys(updates).forEach((key) => {\n        const value = updates[key as keyof typeof updates];\n        if (typeof value === 'number' && sequence.analytics) {\n          (sequence.analytics as any)[key] = ((sequence.analytics as any)[key] || 0) + value;\n        }\n      });\n\n      // Recalculate rates\n      sequence.analytics.deliveryRate = sequence.analytics.totalSent > 0\n        ? (sequence.analytics.totalDelivered / sequence.analytics.totalSent) * 100\n        : 0;\n\n      sequence.analytics.openRate = sequence.analytics.totalDelivered > 0\n        ? (sequence.analytics.totalOpened / sequence.analytics.totalDelivered) * 100\n        : 0;\n\n      sequence.analytics.clickRate = sequence.analytics.totalDelivered > 0\n        ? (sequence.analytics.totalClicked / sequence.analytics.totalDelivered) * 100\n        : 0;\n\n      sequence.analytics.replyRate = sequence.analytics.totalDelivered > 0\n        ? (sequence.analytics.totalReplied / sequence.analytics.totalDelivered) * 100\n        : 0;\n\n      sequence.analytics.conversionRate = sequence.analytics.totalEnrolled > 0\n        ? (sequence.analytics.meetingsBooked / sequence.analytics.totalEnrolled) * 100\n        : 0;\n\n      sequence.analytics.lastRun = new Date().toISOString();\n    }\n\n    await FirestoreService.set(\n      `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/sequences`,\n      sequenceId,\n      sequence,\n      false\n    );\n  }\n\n  /**\n   * Update step analytics\n   */\n  private static async updateStepAnalytics(\n    stepId: string,\n    organizationId: string,\n    updates: Partial<SequenceStep>\n  ): Promise<void> {\n    try {\n      // Find the sequence that contains this step\n      const sequencesPath = `organizations/${organizationId}/sequences`;\n      const sequences = await FirestoreService.getAll<OutboundSequence>(sequencesPath);\n      \n      let targetSequence: OutboundSequence | null = null;\n      let targetStepIndex = -1;\n      \n      for (const sequence of sequences) {\n        const stepIndex = sequence.steps.findIndex(s => s.id === stepId);\n        if (stepIndex !== -1) {\n          targetSequence = sequence;\n          targetStepIndex = stepIndex;\n          break;\n        }\n      }\n      \n      if (!targetSequence || targetStepIndex === -1) {\n        logger.warn('Step not found for analytics update', { stepId, organizationId });\n        return;\n      }\n      \n      // Get the current step\n      const step = targetSequence.steps[targetStepIndex];\n      \n      // Update analytics fields with increments\n      const updatedStep = {\n        ...step,\n        sent: (step.sent || 0) + (updates.sent || 0),\n        delivered: (step.delivered || 0) + (updates.delivered || 0),\n        opened: (step.opened || 0) + (updates.opened || 0),\n        clicked: (step.clicked || 0) + (updates.clicked || 0),\n        replied: (step.replied || 0) + (updates.replied || 0),\n        updatedAt: new Date().toISOString(),\n      };\n      \n      // Update the step in the sequence\n      targetSequence.steps[targetStepIndex] = updatedStep;\n      \n      // Save the updated sequence\n      const sequencePath = `organizations/${organizationId}/sequences`;\n      await FirestoreService.update(sequencePath, targetSequence.id, {\n        steps: targetSequence.steps,\n        updatedAt: new Date().toISOString(),\n      });\n      \n      logger.info('Step analytics updated', {\n        stepId,\n        organizationId,\n        updates,\n        newValues: {\n          sent: updatedStep.sent,\n          delivered: updatedStep.delivered,\n          opened: updatedStep.opened,\n          clicked: updatedStep.clicked,\n          replied: updatedStep.replied,\n        },\n      });\n    } catch (error) {\n      logger.error('Failed to update step analytics', error as Error, {\n        stepId,\n        organizationId,\n        updates,\n      });\n      // Don't throw - analytics updates shouldn't break the main flow\n    }\n  }\n\n  /**\n   * Schedule a step for execution\n   */\n  private static async scheduleStep(\n    enrollment: ProspectEnrollment,\n    step: SequenceStep\n  ): Promise<void> {\n    // In production, this would add to a job queue\n    \n  }\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\persona\\templates\\real-estate.ts","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\'.","line":88,"column":156,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":88,"endColumn":157,"suggestions":[{"messageId":"removeEscape","fix":{"range":[7206,7207],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[7206,7206],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"import type { IndustryTemplate } from './types';\n\nexport const realEstateTemplates: Record<string, IndustryTemplate> = {\n  // REAL ESTATE SECTOR (Templates 1-5)\n  // ============================================\n  \n  'residential-real-estate': {\n    id: 'residential-real-estate',\n    name: 'Residential Real Estate',\n    description: 'For agents selling homes - emotional + financial approach',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The High-Status Neighborhood Authority',\n      positioning: 'Professional, protective of equity, and hyper-local',\n      tone: 'Confident authority with protective advisor undertones'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Lifestyle-to-Asset Pivot',\n      reasoning: 'Logic that connects emotional desires (e.g., \"big yard\") to financial security (e.g., \"high-resale zip code\")',\n      decisionProcess: 'Emotion ‚Üí Financial Validation ‚Üí Action'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Escrow milestones',\n        'Zoning basics',\n        'Fair Housing laws',\n        'Standard contract terms',\n        'Inspection protocols'\n      ],\n      dynamic: [\n        'MLS listings (real-time)',\n        'School ratings',\n        'Neighborhood trends',\n        'Client\\'s \"Sold\" history',\n        'Comparable sales data',\n        'Interest rate updates'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Identifies \"Feature Trends\" (e.g., high demand for home offices, outdoor spaces, smart home tech)',\n      adaptation: 'Alerts client to update marketing copy to reflect current trends and buyer preferences',\n      feedbackIntegration: 'Tracks which property features drive most viewings and adjusts emphasis accordingly'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Tour Booking',\n      conversionRhythm: 'Every 3rd message pushes for a physical viewing or custom \"Market Report\" for their specific zip code',\n      secondaryActions: [\n        'Custom zip code Market Report',\n        'Comparative Market Analysis (CMA)',\n        'Pre-approval referral',\n        'Home valuation request'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['linkedin-company', 'google-business'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'hiring_agents', label: 'Hiring Real Estate Agents', description: 'Recruiting new agents', keywords: [\"hiring agents\", \"join our team\", \"agent positions\", \"real estate careers\", \"agent recruitment\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'any'},\n        {id: 'top_producer', label: 'Top Producer', description: 'High sales volume or awards', keywords: [\"top producer\", \"top agent\", \"million dollar\", \"sales leader\", \"award winning\"], priority: 'CRITICAL', action: 'increase-score', scoreBoost: 40, platform: 'website'},\n        {id: 'new_listings', label: 'New Listings', description: 'Recently added properties', keywords: [\"new listing\", \"just listed\", \"coming soon\", \"recently added\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'luxury_homes', label: 'Luxury Market', description: 'Specializes in luxury real estate', keywords: [\"luxury homes\", \"luxury real estate\", \"high-end\", \"estates\", \"million dollar homes\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'first_time_buyers', label: 'First-Time Buyers', description: 'Focuses on first-time homebuyers', keywords: [\"first time\", \"first-time buyers\", \"first home\", \"buyer assistance\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 12, platform: 'website'},\n        {id: 'virtual_tours', label: 'Virtual Tours', description: 'Offers 3D or virtual property tours', keywords: [\"virtual tour\", \"3d tour\", \"matterport\", \"video walkthrough\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'buyer_representation', label: 'Buyer Representation', description: 'Represents buyers', keywords: [\"buyer agent\", \"buyer representation\", \"helping buyers\", \"buyer services\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 10, platform: 'website'},\n        {id: 'seller_representation', label: 'Seller Representation', description: 'Represents sellers', keywords: [\"listing agent\", \"seller representation\", \"selling your home\", \"list your property\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 10, platform: 'website'},\n        {id: 'relocation_specialist', label: 'Relocation Services', description: 'Assists with relocations', keywords: [\"relocation\", \"moving to\", \"relocating\", \"corporate relocation\"], priority: 'LOW', action: 'add-to-segment', scoreBoost: 8, platform: 'website'},\n        {id: 'investment_properties', label: 'Investment Properties', description: 'Specializes in investment real estate', keywords: [\"investment properties\", \"rental properties\", \"fix and flip\", \"investor friendly\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'team_size', label: 'Large Team', description: 'Multiple agents on team', keywords: [\"team of\", \"agents\", \"real estate team\"], regexPattern: '(\\\\d+)\\\\s*(agents?|realtors?)', priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'areas_served', label: 'Multiple Service Areas', description: 'Serves multiple cities/neighborhoods', keywords: [\"serving\", \"areas served\", \"neighborhoods\", \"communities\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'years_experience', label: 'Experience Level', description: 'Years in real estate', keywords: [\"years of experience\", \"since\", \"established\"], regexPattern: '(\\\\d+)\\\\+?\\\\s*years?', priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'},\n        {id: 'certifications', label: 'Professional Designations', description: 'Has certifications (CRS, ABR, etc)', keywords: [\"crs\", \"abr\", \"gri\", \"srs\", \"certified\", \"accredited\"], priority: 'LOW', action: 'increase-score', scoreBoost: 5, platform: 'website'},\n        {id: 'sold_count', label: 'Sales Volume', description: 'Number of homes sold', keywords: [\"homes sold\", \"sales\", \"transactions\"], regexPattern: '(\\\\d+)\\\\s*(homes?|properties)\\\\s*sold', priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'website'},\n        {id: 'mls_access', label: 'MLS Access', description: 'Has MLS search capability', keywords: [\"mls\", \"multiple listing\", \"search homes\", \"property search\"], priority: 'LOW', action: 'increase-score', scoreBoost: 5, platform: 'website'},\n        {id: 'market_reports', label: 'Market Reports', description: 'Provides market analysis', keywords: [\"market report\", \"market analysis\", \"market trends\", \"neighborhood stats\"], priority: 'LOW', action: 'increase-score', scoreBoost: 5, platform: 'website'},\n        {id: 'home_valuation', label: 'Home Valuation Tool', description: 'Offers property valuation', keywords: [\"home value\", \"property valuation\", \"what\\'s my home worth\", \"cma\"], priority: 'LOW', action: 'increase-score', scoreBoost: 5, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright notices', context: 'footer'},\n        {id: 'all_rights', pattern: 'all rights reserved', description: 'Rights statement', context: 'footer'},\n        {id: 'equal_housing', pattern: 'equal housing opportunity', description: 'Fair housing logo', context: 'footer'},\n        {id: 'realtor_logo', pattern: 'realtor¬Æ|realtors¬Æ', description: 'REALTOR trademark', context: 'all'},\n        {id: 'mls_disclaimer', pattern: 'mls.*disclaimer|data.*deemed reliable', description: 'MLS disclaimers', context: 'footer'},\n        {id: 'privacy_policy', pattern: 'privacy policy', description: 'Privacy link', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of use|and conditions)', description: 'Terms link', context: 'footer'},\n        {id: 'cookie_notice', pattern: 'we use cookies', description: 'Cookie banner', context: 'all'},\n        {id: 'social_media', pattern: 'follow (us|me) on', description: 'Social links', context: 'footer'},\n        {id: 'contact_us', pattern: '^contact( us)?$', description: 'Contact link', context: 'header'},\n        {id: 'about_us', pattern: '^about( us| me)?$', description: 'About link', context: 'header'},\n        {id: 'testimonials', pattern: '^testimonials$|^reviews$', description: 'Testimonials link', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog link', context: 'header'},\n        {id: 'search_homes', pattern: '^search homes$|^listings$', description: 'Search link', context: 'header'},\n        {id: 'back_to_top', pattern: 'back to top', description: 'Back to top link', context: 'footer'},\n        {id: 'site_map', pattern: 'site ?map', description: 'Sitemap link', context: 'footer'},\n        {id: 'accessibility', pattern: 'accessibility', description: 'Accessibility link', context: 'footer'},\n        {id: 'dmca', pattern: 'dmca', description: 'DMCA notice', context: 'footer'},\n        {id: 'idx_disclaimer', pattern: 'idx|internet data exchange', description: 'IDX disclaimer', context: 'footer'},\n        {id: 'powered_by', pattern: 'powered by|website by', description: 'Attribution', context: 'footer'}\n      ],\n\n      scoringRules: [\n        {id: 'top_producer_hiring', name: 'Growing Top Team', description: 'Top producer hiring agents', condition: 'signals.some(s => s.signalId === \"top_producer\") && signals.some(s => s.signalId === \"hiring_agents\")', scoreBoost: 25, priority: 1, enabled: true},\n        {id: 'luxury_investment', name: 'Luxury & Investment', description: 'Serves luxury and investment markets', condition: 'signals.some(s => s.signalId === \"luxury_homes\") && signals.some(s => s.signalId === \"investment_properties\")', scoreBoost: 20, priority: 2, enabled: true},\n        {id: 'full_service_agent', name: 'Full Service', description: 'Represents both buyers and sellers', condition: 'signals.some(s => s.signalId === \"buyer_representation\") && signals.some(s => s.signalId === \"seller_representation\")', scoreBoost: 15, priority: 3, enabled: true},\n        {id: 'tech_forward', name: 'Tech-Forward Agent', description: 'Uses virtual tours and modern tools', condition: 'signals.some(s => s.signalId === \"virtual_tours\") && signals.some(s => s.signalId === \"mls_access\")', scoreBoost: 10, priority: 4, enabled: true},\n        {id: 'established_team', name: 'Established Team', description: 'Large team with experience', condition: 'signals.some(s => s.signalId === \"team_size\") && signals.some(s => s.signalId === \"years_experience\")', scoreBoost: 15, priority: 5, enabled: true},\n        {id: 'high_volume', name: 'High Volume Producer', description: 'High sales count with multiple areas', condition: 'signals.some(s => s.signalId === \"sold_count\") && signals.some(s => s.signalId === \"areas_served\")', scoreBoost: 20, priority: 6, enabled: true},\n        {id: 'certified_professional', name: 'Certified Professional', description: 'Has certifications and experience', condition: 'signals.some(s => s.signalId === \"certifications\") && signals.some(s => s.signalId === \"years_experience\")', scoreBoost: 10, priority: 7, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'team_size', label: 'Number of Agents', type: 'number', description: 'Size of agent team', extractionHints: ['agents', 'team of', 'realtors'], required: false, defaultValue: 1},\n        {key: 'areas_served', label: 'Service Areas', type: 'array', description: 'Cities/neighborhoods served', extractionHints: ['serving', 'areas', 'neighborhoods'], required: false, defaultValue: []},\n        {key: 'years_experience', label: 'Years in Business', type: 'number', description: 'Years of experience', extractionHints: ['years', 'since', 'established'], required: false, defaultValue: 0},\n        {key: 'specialization', label: 'Market Specialization', type: 'string', description: 'Luxury, first-time, investment, etc', extractionHints: ['specialize', 'focus', 'expert in'], required: false, defaultValue: 'general'},\n        {key: 'homes_sold_annual', label: 'Annual Sales Volume', type: 'number', description: 'Homes sold per year', extractionHints: ['homes sold', 'transactions', 'sales'], required: false, defaultValue: 0},\n        {key: 'has_virtual_tours', label: 'Offers Virtual Tours', type: 'boolean', description: 'Whether 3D/virtual tours available', extractionHints: ['virtual', '3d tour', 'matterport'], required: false, defaultValue: false},\n        {key: 'certifications', label: 'Professional Certifications', type: 'array', description: 'CRS, ABR, GRI, etc', extractionHints: ['certified', 'designation', 'accredited'], required: false, defaultValue: []},\n        {key: 'buyer_or_seller', label: 'Buyer/Seller Focus', type: 'string', description: 'Buyer, seller, or both', extractionHints: ['buyer agent', 'listing agent', 'both'], required: false, defaultValue: 'both'}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-28',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Residential real estate intelligence - focuses on team growth, sales volume, market specialization, and tech capabilities'\n      }\n    }\n  },\n  \n  'commercial-real-estate': {\n    id: 'commercial-real-estate',\n    name: 'Commercial Property',\n    description: 'For commercial brokers - data-driven investment focus',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Strategic Asset Advisor',\n      positioning: 'Data-obsessed, efficient, and objective. Minimalist \"no-fluff\" communication',\n      tone: 'Analytical, sophisticated, financial metric vocabulary'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Yield-First Model',\n      reasoning: 'Logic that filters every query through Cap Rates, Cash-on-Cash Return, and NOI (Net Operating Income)',\n      decisionProcess: 'Financial Metrics ‚Üí Strategic Fit ‚Üí Exclusivity Hook'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'NNN (Triple Net) lease structures',\n        '1031 Exchange rules',\n        'Cap Rate calculations',\n        'NOI formulas',\n        'Zoning classifications',\n        'Commercial lease terms'\n      ],\n      dynamic: [\n        'Current market Cap Rates',\n        'Rent rolls',\n        'Vacancy rates',\n        'Industrial zoning data',\n        'Offering Memorandums (OMs)',\n        'Market absorption rates'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Tracks lead preference for \"Value-Add\" vs. \"Core\" assets based on risk tolerance and investment horizon',\n      adaptation: 'Automatically re-weights the agent\\'s property recommendations based on investor profile (income vs appreciation focus)',\n      feedbackIntegration: 'Learns which financial metrics (Cap Rate, IRR, Cash-on-Cash) resonate most with each investor type'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'NDA/OM Request',\n      conversionRhythm: 'Focuses on moving the lead to the \"Financial Disclosure\" phase as the primary conversion milestone',\n      secondaryActions: [\n        'Schedule site tour',\n        'Request Offering Memorandum',\n        'Zoning feasibility analysis',\n        '1031 Exchange consultation',\n        'Tenant credit analysis'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['linkedin-company', 'news'],\n        frequency: 'weekly',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 600\n      },\n\n      highValueSignals: [\n        {id: 'active_listings', label: 'Active Commercial Listings', description: 'Has available properties', keywords: [\"for sale\", \"for lease\", \"available\", \"listing\", \"commercial property\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'portfolio_size', label: 'Large Portfolio', description: 'Manages many properties', keywords: [\"portfolio\", \"properties managed\", \"square feet\"], regexPattern: '([\\\\d,]+)\\\\s*(sf|square feet|properties)', priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'tenant_representation', label: 'Tenant Rep Services', description: 'Represents tenants', keywords: [\"tenant representation\", \"tenant rep\", \"helping tenants\", \"lease negotiation\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'landlord_representation', label: 'Landlord Rep', description: 'Represents property owners', keywords: [\"landlord representation\", \"property owner\", \"leasing services\", \"asset management\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'investment_sales', label: 'Investment Sales', description: 'Specializes in sales transactions', keywords: [\"investment sales\", \"acquisition\", \"disposition\", \"cap rate\", \"roi\"], priority: 'CRITICAL', action: 'increase-score', scoreBoost: 40, platform: 'website'},\n        {id: 'property_types', label: 'Multi-Property Type', description: 'Handles multiple asset classes', keywords: [\"office\", \"retail\", \"industrial\", \"multifamily\", \"mixed-use\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 20, platform: 'website'},\n        {id: 'market_reports', label: 'Market Analytics', description: 'Provides market research', keywords: [\"market report\", \"market analysis\", \"trends\", \"vacancy rate\", \"absorption\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'site_selection', label: 'Site Selection Services', description: 'Helps with location strategy', keywords: [\"site selection\", \"location strategy\", \"demographics\", \"traffic counts\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: '1031_exchange', label: '1031 Exchange Expertise', description: 'Facilitates tax-deferred exchanges', keywords: [\"1031 exchange\", \"tax-deferred\", \"like-kind exchange\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'nnn_lease', label: 'Triple Net Lease', description: 'NNN lease specialization', keywords: [\"triple net\", \"nnn lease\", \"net lease\", \"absolute net\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'build_to_suit', label: 'Build-to-Suit', description: 'Custom construction services', keywords: [\"build to suit\", \"ground lease\", \"development\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'property_valuation', label: 'Valuation Services', description: 'Appraisal and valuation', keywords: [\"valuation\", \"appraisal\", \"property value\", \"market value\"], priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Brokers', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"careers\", \"broker positions\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'awards', label: 'Industry Recognition', description: 'Awards or top broker status', keywords: [\"top broker\", \"award\", \"costar\", \"dealmaker\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'recent_transactions', label: 'Recent Deals', description: 'Recently closed transactions', keywords: [\"just sold\", \"recently sold\", \"closed\", \"transaction\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright notices', context: 'footer'},\n        {id: 'all_rights', pattern: 'all rights reserved', description: 'Rights statement', context: 'footer'},\n        {id: 'equal_housing', pattern: 'equal (housing|opportunity)', description: 'Fair housing', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy link', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of use|and conditions)', description: 'Terms link', context: 'footer'},\n        {id: 'cookie', pattern: 'we use cookies', description: 'Cookie banner', context: 'all'},\n        {id: 'disclaimer', pattern: 'disclaimer|information deemed reliable', description: 'Legal disclaimer', context: 'footer'},\n        {id: 'social', pattern: 'follow (us|me)', description: 'Social links', context: 'footer'},\n        {id: 'contact', pattern: '^contact( us)?$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about( us)?$', description: 'About link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services link', context: 'header'},\n        {id: 'team', pattern: '^(our )?team$', description: 'Team link', context: 'header'},\n        {id: 'listings', pattern: '^listings$|^properties$', description: 'Listings link', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'site ?map', description: 'Sitemap', context: 'footer'},\n        {id: 'accessibility', pattern: 'accessibility', description: 'Accessibility', context: 'footer'},\n        {id: 'powered_by', pattern: 'powered by|website by', description: 'Attribution', context: 'footer'},\n        {id: 'login', pattern: '^(client )?login$', description: 'Login link', context: 'header'},\n        {id: 'search', pattern: '^search$', description: 'Search', context: 'header'},\n        {id: 'news', pattern: '^news$|^blog$', description: 'News/blog link', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'full_service', name: 'Full-Service Firm', description: 'Offers both tenant and landlord rep', condition: 'signals.some(s => s.signalId === \"tenant_representation\") && signals.some(s => s.signalId === \"landlord_representation\")', scoreBoost: 20, priority: 1, enabled: true},\n        {id: 'investment_specialist', name: 'Investment Specialist', description: 'Investment sales with 1031 exchange', condition: 'signals.some(s => s.signalId === \"investment_sales\") && signals.some(s => s.signalId === \"1031_exchange\")', scoreBoost: 25, priority: 2, enabled: true},\n        {id: 'growing_firm', name: 'Growing Firm', description: 'Hiring with recent transactions', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"recent_transactions\")', scoreBoost: 30, priority: 3, enabled: true},\n        {id: 'diversified_portfolio', name: 'Diversified', description: 'Multiple property types', condition: 'signals.some(s => s.signalId === \"property_types\")', scoreBoost: 15, priority: 4, enabled: true},\n        {id: 'development_capable', name: 'Development Services', description: 'Build-to-suit and site selection', condition: 'signals.some(s => s.signalId === \"build_to_suit\") && signals.some(s => s.signalId === \"site_selection\")', scoreBoost: 20, priority: 5, enabled: true},\n        {id: 'market_leader', name: 'Market Leader', description: 'Awards with large portfolio', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"portfolio_size\")', scoreBoost: 25, priority: 6, enabled: true},\n        {id: 'data_driven', name: 'Analytics-Focused', description: 'Provides market reports and valuations', condition: 'signals.some(s => s.signalId === \"market_reports\") && signals.some(s => s.signalId === \"property_valuation\")', scoreBoost: 15, priority: 7, enabled: true},\n        {id: 'active_pipeline', name: 'Active Pipeline', description: 'Has listings and recent deals', condition: 'signals.some(s => s.signalId === \"active_listings\") && signals.some(s => s.signalId === \"recent_transactions\")', scoreBoost: 20, priority: 8, enabled: true},\n        {id: 'specialist_knowledge', name: 'NNN Specialist', description: 'NNN lease expert with investment sales', condition: 'signals.some(s => s.signalId === \"nnn_lease\") && signals.some(s => s.signalId === \"investment_sales\")', scoreBoost: 18, priority: 9, enabled: true},\n        {id: 'comprehensive_services', name: 'Comprehensive', description: 'Multiple services offered', condition: 'signals.filter(s => [\"tenant_representation\", \"landlord_representation\", \"investment_sales\", \"site_selection\"].includes(s.signalId)).length >= 3', scoreBoost: 25, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'portfolio_square_feet', label: 'Portfolio Size (SF)', type: 'number', description: 'Total square footage managed', extractionHints: ['square feet', 'sf', 'portfolio'], required: false, defaultValue: 0},\n        {key: 'property_types_served', label: 'Property Types', type: 'array', description: 'Asset classes handled', extractionHints: ['office', 'retail', 'industrial', 'multifamily'], required: false, defaultValue: []},\n        {key: 'service_areas', label: 'Markets Served', type: 'array', description: 'Geographic markets', extractionHints: ['serving', 'markets', 'cities'], required: false, defaultValue: []},\n        {key: 'specialization', label: 'Primary Specialization', type: 'string', description: 'Main service focus', extractionHints: ['specialize', 'focus', 'expert in'], required: false, defaultValue: 'general'},\n        {key: 'broker_count', label: 'Number of Brokers', type: 'number', description: 'Team size', extractionHints: ['brokers', 'team', 'professionals'], required: false, defaultValue: 1},\n        {key: 'has_1031_services', label: 'Offers 1031 Exchange', type: 'boolean', description: 'Whether 1031 exchange available', extractionHints: ['1031', 'exchange', 'tax-deferred'], required: false, defaultValue: false},\n        {key: 'years_in_business', label: 'Years Established', type: 'number', description: 'Years in operation', extractionHints: ['years', 'since', 'established'], required: false, defaultValue: 0},\n        {key: 'avg_transaction_size', label: 'Average Deal Size', type: 'string', description: 'Typical transaction value', extractionHints: ['million', 'average', 'transaction'], required: false, defaultValue: 'unknown'}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Commercial real estate intelligence - focuses on portfolio size, transaction types, property specialization, and service breadth'\n      }\n    }\n  },\n  \n  'property-management': {\n    id: 'property-management',\n    name: 'Property Management',\n    description: 'For property managers - stress relief and systems focus',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Shield & Maximizer',\n      positioning: 'Diligent, risk-averse, and highly organized. Framed as a \"fiduciary for your free time\"',\n      tone: 'Protective, systematic, detail-oriented'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Stress-Relief Framework',\n      reasoning: 'Logic that identifies landlord \"headaches\" (maintenance calls, late rent, tenant turnover) and counters them with \"Systems\"',\n      decisionProcess: 'Pain Point ‚Üí System Solution ‚Üí Time Liberation'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Fair Housing Act compliance',\n        'Eviction protocols by state',\n        'Landlord-tenant law',\n        'Security deposit regulations',\n        'Lease agreement standards'\n      ],\n      dynamic: [\n        'Management fee structures',\n        'Tenant vetting criteria',\n        'Local vendor lists (plumbers, electricians)',\n        'Rental market rates',\n        'Maintenance request logs',\n        'Tenant payment history'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Flags common tenant complaints (HVAC issues, plumbing) to suggest proactive maintenance schedules',\n      adaptation: 'Alerts owner to preventive maintenance opportunities, reducing long-term churn and emergency costs',\n      feedbackIntegration: 'Tracks seasonal maintenance patterns (e.g., AC failures in summer) and proactively schedules service'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Rental Analysis Request',\n      conversionRhythm: 'Offers a free \"Profit Optimization\" report to capture the landlord\\'s contact info and demonstrate value',\n      secondaryActions: [\n        'Property inspection scheduling',\n        'Tenant placement guarantee details',\n        'Maintenance coordination demo',\n        'Rent collection system walkthrough',\n        'Financial reporting sample'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['google-business'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'units_managed', label: 'Large Portfolio', description: 'High unit count', keywords: [\"units managed\", \"properties managed\", \"doors\"], regexPattern: '([\\\\d,]+)\\\\s*(units?|doors?|properties)', priority: 'CRITICAL', action: 'increase-score', scoreBoost: 35, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Staff', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"careers\", \"now hiring\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'any'},\n        {id: 'maintenance_team', label: 'In-House Maintenance', description: 'Own maintenance crew', keywords: [\"maintenance team\", \"in-house maintenance\", \"24/7 maintenance\", \"emergency maintenance\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'tenant_portal', label: 'Online Tenant Portal', description: 'Digital tenant access', keywords: [\"tenant portal\", \"online portal\", \"pay rent online\", \"maintenance request online\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'financial_reporting', label: 'Owner Reporting', description: 'Financial reporting system', keywords: [\"owner reporting\", \"financial reports\", \"monthly statements\", \"profit and loss\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'tenant_screening', label: 'Tenant Screening', description: 'Background checks', keywords: [\"tenant screening\", \"background check\", \"credit check\", \"tenant vetting\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'rent_collection', label: 'Rent Collection', description: 'Collection services', keywords: [\"rent collection\", \"guaranteed rent\", \"rent payment\", \"late fees\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'eviction_services', label: 'Eviction Assistance', description: 'Legal eviction support', keywords: [\"eviction\", \"legal services\", \"tenant removal\", \"eviction process\"], priority: 'LOW', action: 'add-to-segment', scoreBoost: 8, platform: 'website'},\n        {id: 'property_types', label: 'Multiple Property Types', description: 'Diverse portfolio', keywords: [\"residential\", \"commercial\", \"multifamily\", \"single family\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'leasing_services', label: 'Full Leasing', description: 'Complete leasing service', keywords: [\"leasing\", \"tenant placement\", \"marketing\", \"showings\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'hoa_management', label: 'HOA Management', description: 'Homeowner association services', keywords: [\"hoa\", \"homeowner association\", \"condo association\", \"community management\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'vacancy_guarantee', label: 'Vacancy Guarantee', description: 'Rent guarantee program', keywords: [\"vacancy guarantee\", \"guaranteed rent\", \"rent insurance\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'expansion', label: 'Market Expansion', description: 'New markets or locations', keywords: [\"expanding\", \"new office\", \"now serving\", \"new market\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'certifications', label: 'Professional Certifications', description: 'Industry credentials', keywords: [\"cpm\", \"arm\", \"narpm\", \"certified\"], priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'},\n        {id: 'software_platform', label: 'PM Software', description: 'Uses modern PM software', keywords: [\"appfolio\", \"buildium\", \"propertyware\", \"rent manager\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 10, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'equal_housing', pattern: 'equal housing', description: 'Fair housing', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'properties', pattern: '^properties$', description: 'Properties', context: 'header'},\n        {id: 'owners', pattern: '^owners$', description: 'Owners link', context: 'header'},\n        {id: 'tenants', pattern: '^tenants$', description: 'Tenants link', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'login', pattern: 'login', description: 'Login', context: 'header'},\n        {id: 'portal', pattern: 'portal', description: 'Portal link', context: 'header'},\n        {id: 'careers', pattern: '^careers$', description: 'Careers', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'large_operator', name: 'Large Operator', description: 'High unit count', condition: 'signals.some(s => s.signalId === \"units_managed\")', scoreBoost: 25, priority: 1, enabled: true},\n        {id: 'full_service', name: 'Full Service PM', description: 'Maintenance and tenant portal', condition: 'signals.some(s => s.signalId === \"maintenance_team\") && signals.some(s => s.signalId === \"tenant_portal\")', scoreBoost: 20, priority: 2, enabled: true},\n        {id: 'growing_company', name: 'Growing', description: 'Hiring with expansion', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"expansion\")', scoreBoost: 30, priority: 3, enabled: true},\n        {id: 'tech_enabled', name: 'Technology-Forward', description: 'Portal and PM software', condition: 'signals.some(s => s.signalId === \"tenant_portal\") && signals.some(s => s.signalId === \"software_platform\")', scoreBoost: 15, priority: 4, enabled: true},\n        {id: 'professional', name: 'Professional PM', description: 'Certifications and experience', condition: 'signals.some(s => s.signalId === \"certifications\")', scoreBoost: 10, priority: 5, enabled: true},\n        {id: 'comprehensive', name: 'Comprehensive Services', description: 'Multiple core services', condition: 'signals.filter(s => [\"maintenance_team\", \"tenant_screening\", \"rent_collection\", \"leasing_services\"].includes(s.signalId)).length >= 3', scoreBoost: 20, priority: 6, enabled: true},\n        {id: 'guaranteed_income', name: 'Income Guarantee', description: 'Vacancy guarantee with rent collection', condition: 'signals.some(s => s.signalId === \"vacancy_guarantee\") && signals.some(s => s.signalId === \"rent_collection\")', scoreBoost: 18, priority: 7, enabled: true},\n        {id: 'diversified', name: 'Diversified Portfolio', description: 'Multiple property types', condition: 'signals.some(s => s.signalId === \"property_types\")', scoreBoost: 15, priority: 8, enabled: true},\n        {id: 'hoa_specialist', name: 'HOA Specialist', description: 'HOA management with multiple properties', condition: 'signals.some(s => s.signalId === \"hoa_management\") && signals.some(s => s.signalId === \"units_managed\")', scoreBoost: 20, priority: 9, enabled: true},\n        {id: 'transparent', name: 'Transparent Reporting', description: 'Financial reporting with portal access', condition: 'signals.some(s => s.signalId === \"financial_reporting\") && signals.some(s => s.signalId === \"tenant_portal\")', scoreBoost: 12, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'units_managed', label: 'Units/Doors Managed', type: 'number', description: 'Total units under management', extractionHints: ['units', 'doors', 'properties managed'], required: false, defaultValue: 0},\n        {key: 'property_types', label: 'Property Types', type: 'array', description: 'Types managed', extractionHints: ['residential', 'commercial', 'multifamily'], required: false, defaultValue: []},\n        {key: 'service_areas', label: 'Service Areas', type: 'array', description: 'Geographic coverage', extractionHints: ['serving', 'areas', 'cities'], required: false, defaultValue: []},\n        {key: 'has_maintenance_team', label: 'In-House Maintenance', type: 'boolean', description: 'Own maintenance crew', extractionHints: ['maintenance team', 'in-house'], required: false, defaultValue: false},\n        {key: 'has_tenant_portal', label: 'Online Portal', type: 'boolean', description: 'Digital tenant access', extractionHints: ['portal', 'online'], required: false, defaultValue: false},\n        {key: 'management_fee_percent', label: 'Management Fee %', type: 'string', description: 'Fee structure', extractionHints: ['fee', 'percent', '%'], required: false, defaultValue: 'unknown'},\n        {key: 'specialization', label: 'Specialization', type: 'string', description: 'Primary focus area', extractionHints: ['specialize', 'focus', 'expert'], required: false, defaultValue: 'general'}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Property management intelligence - focuses on portfolio size, service breadth, technology adoption, and growth indicators'\n      }\n    }\n  },\n  \n  'short-term-rentals': {\n    id: 'short-term-rentals',\n    name: 'Short-Term Rentals (Airbnb/Vacation)',\n    description: 'For STR hosts - revenue optimization and guest experience',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Revenue & Guest Experience Expert',\n      positioning: 'Upbeat, hospitality-focused, and tech-savvy',\n      tone: 'Enthusiastic, data-driven, service-oriented'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Algorithmic Edge',\n      reasoning: 'Logic that emphasizes beating the \"average\" host through dynamic pricing, Superhost-level response times, and 5-star reviews',\n      decisionProcess: 'Market Data ‚Üí Optimization Strategy ‚Üí Revenue Maximization'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'OTA (Airbnb/VRBO) best practices',\n        'Superhost requirements',\n        'Short-term rental regulations',\n        'Guest communication templates',\n        'Cleaning protocols'\n      ],\n      dynamic: [\n        'Seasonal occupancy data',\n        'Dynamic pricing algorithms',\n        'Cleaning schedules',\n        'Regional tourism drivers (events, seasons)',\n        'Competitor pricing',\n        'Guest review analytics'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Analyzes guest inquiries to suggest \"Missing Amenities\" (e.g., \"3 people asked if you have a hot tub this week\")',\n      adaptation: 'Recommends pricing adjustments based on local events, seasonality, and booking velocity',\n      feedbackIntegration: 'Tracks which amenities mentioned in reviews correlate with 5-star ratings and premium pricing'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Revenue Projection',\n      conversionRhythm: 'Prompts owners to see a \"Potential Earnings\" calendar for their property with seasonal breakdown',\n      secondaryActions: [\n        'Amenity gap analysis',\n        'Superhost roadmap',\n        'Dynamic pricing setup',\n        'Guest automation demo',\n        'Cleaning service recommendations'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['google-business'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'property_count', label: 'Multiple Properties', description: 'Manages multiple STRs', keywords: [\"properties\", \"listings\", \"portfolio\"], regexPattern: '(\\\\d+)\\\\s*(properties|listings|homes)', priority: 'CRITICAL', action: 'increase-score', scoreBoost: 40, platform: 'website'},\n        {id: 'superhost_status', label: 'Superhost', description: 'Airbnb Superhost status', keywords: [\"superhost\", \"super host\", \"top rated\", \"premier host\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'property_management', label: 'Full-Service Management', description: 'Offers complete STR management', keywords: [\"property management\", \"full service\", \"turnkey\", \"we handle everything\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'dynamic_pricing', label: 'Dynamic Pricing', description: 'Uses algorithmic pricing', keywords: [\"dynamic pricing\", \"revenue management\", \"pricelabs\", \"wheelhouse\", \"beyond pricing\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'cleaning_service', label: 'Cleaning Services', description: 'Professional cleaning team', keywords: [\"cleaning\", \"housekeeping\", \"cleaning team\", \"turnover service\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'guest_communication', label: 'Guest Communication', description: 'Automated guest messaging', keywords: [\"guest communication\", \"automated messaging\", \"24/7 support\", \"instant response\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'amenities_premium', label: 'Premium Amenities', description: 'High-end amenities offered', keywords: [\"hot tub\", \"pool\", \"luxury\", \"premium amenities\", \"high-end\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'revenue_guarantee', label: 'Revenue Guarantee', description: 'Guaranteed income program', keywords: [\"revenue guarantee\", \"guaranteed income\", \"minimum revenue\", \"income protection\"], priority: 'CRITICAL', action: 'add-to-segment', scoreBoost: 35, platform: 'website'},\n        {id: 'expansion', label: 'Expanding Portfolio', description: 'Adding new properties', keywords: [\"expanding\", \"new property\", \"adding listings\", \"growing portfolio\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'hiring', label: 'Hiring Staff', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"now hiring\", \"careers\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'guest_vetting', label: 'Guest Screening', description: 'Screens guests', keywords: [\"guest screening\", \"background check\", \"verified guests\", \"id verification\"], priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'},\n        {id: 'maintenance_team', label: 'Maintenance Services', description: 'In-house maintenance', keywords: [\"maintenance\", \"handyman\", \"repairs\", \"maintenance team\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'occupancy_rate', label: 'High Occupancy', description: 'Strong booking rate', keywords: [\"occupancy\", \"booked\", \"high demand\"], regexPattern: '(\\\\d+)%\\\\s*occupancy', priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'website'},\n        {id: 'review_score', label: 'High Review Score', description: 'Excellent guest reviews', keywords: [\"5 star\", \"five star\", \"excellent reviews\", \"top rated\"], regexPattern: '(4\\\\.[89]|5\\\\.0)\\\\s*(stars?|rating)', priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'insurance', label: 'STR Insurance', description: 'Specialized insurance', keywords: [\"str insurance\", \"short term rental insurance\", \"vacation rental insurance\", \"liability coverage\"], priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'properties', pattern: '^properties$|^listings$', description: 'Properties', context: 'header'},\n        {id: 'amenities', pattern: '^amenities$', description: 'Amenities link', context: 'header'},\n        {id: 'booking', pattern: '^book now$', description: 'Booking', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'login', pattern: 'login', description: 'Login', context: 'header'},\n        {id: 'owners', pattern: '^owners$', description: 'Owners link', context: 'header'},\n        {id: 'guests', pattern: '^guests$', description: 'Guests link', context: 'header'},\n        {id: 'reviews', pattern: '^reviews$', description: 'Reviews link', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'faq', pattern: '^faq$', description: 'FAQ', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'large_operator', name: 'Large Portfolio', description: 'Multiple properties with high occupancy', condition: 'signals.some(s => s.signalId === \"property_count\") && signals.some(s => s.signalId === \"occupancy_rate\")', scoreBoost: 30, priority: 1, enabled: true},\n        {id: 'professional_host', name: 'Professional Host', description: 'Superhost with premium amenities', condition: 'signals.some(s => s.signalId === \"superhost_status\") && signals.some(s => s.signalId === \"amenities_premium\")', scoreBoost: 25, priority: 2, enabled: true},\n        {id: 'full_service', name: 'Full-Service Provider', description: 'Complete management services', condition: 'signals.some(s => s.signalId === \"property_management\") && signals.some(s => s.signalId === \"cleaning_service\")', scoreBoost: 20, priority: 3, enabled: true},\n        {id: 'tech_enabled', name: 'Technology-Forward', description: 'Dynamic pricing and automation', condition: 'signals.some(s => s.signalId === \"dynamic_pricing\") && signals.some(s => s.signalId === \"guest_communication\")', scoreBoost: 18, priority: 4, enabled: true},\n        {id: 'growing_business', name: 'Growing Business', description: 'Expanding with hiring', condition: 'signals.some(s => s.signalId === \"expansion\") && signals.some(s => s.signalId === \"hiring\")', scoreBoost: 30, priority: 5, enabled: true},\n        {id: 'premium_service', name: 'Premium Operator', description: 'Revenue guarantee with high reviews', condition: 'signals.some(s => s.signalId === \"revenue_guarantee\") && signals.some(s => s.signalId === \"review_score\")', scoreBoost: 35, priority: 6, enabled: true},\n        {id: 'comprehensive', name: 'Comprehensive Services', description: 'Multiple service offerings', condition: 'signals.filter(s => [\"cleaning_service\", \"maintenance_team\", \"guest_communication\", \"guest_vetting\"].includes(s.signalId)).length >= 3', scoreBoost: 22, priority: 7, enabled: true},\n        {id: 'quality_focused', name: 'Quality-Focused', description: 'High reviews with vetting', condition: 'signals.some(s => s.signalId === \"review_score\") && signals.some(s => s.signalId === \"guest_vetting\")', scoreBoost: 15, priority: 8, enabled: true},\n        {id: 'insured_professional', name: 'Insured Professional', description: 'Insurance with property management', condition: 'signals.some(s => s.signalId === \"insurance\") && signals.some(s => s.signalId === \"property_management\")', scoreBoost: 12, priority: 9, enabled: true},\n        {id: 'established_host', name: 'Established Host', description: 'Superhost with multiple properties', condition: 'signals.some(s => s.signalId === \"superhost_status\") && signals.some(s => s.signalId === \"property_count\")', scoreBoost: 28, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'property_count', label: 'Number of Properties', type: 'number', description: 'STR properties managed', extractionHints: ['properties', 'listings', 'portfolio'], required: false, defaultValue: 1},\n        {key: 'avg_nightly_rate', label: 'Average Nightly Rate', type: 'string', description: 'Typical rate per night', extractionHints: ['per night', 'nightly', 'rate'], required: false, defaultValue: 'unknown'},\n        {key: 'occupancy_rate', label: 'Occupancy Rate %', type: 'number', description: 'Booking percentage', extractionHints: ['occupancy', 'booked'], required: false, defaultValue: 0},\n        {key: 'is_superhost', label: 'Superhost Status', type: 'boolean', description: 'Airbnb Superhost', extractionHints: ['superhost'], required: false, defaultValue: false},\n        {key: 'has_dynamic_pricing', label: 'Uses Dynamic Pricing', type: 'boolean', description: 'Algorithmic pricing', extractionHints: ['dynamic pricing', 'revenue management'], required: false, defaultValue: false},\n        {key: 'service_areas', label: 'Service Areas', type: 'array', description: 'Geographic coverage', extractionHints: ['serving', 'locations', 'cities'], required: false, defaultValue: []},\n        {key: 'specialization', label: 'Property Type Focus', type: 'string', description: 'Primary property type', extractionHints: ['specialize', 'focus', 'luxury', 'beach'], required: false, defaultValue: 'general'}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Short-term rental intelligence - focuses on portfolio size, revenue optimization, guest experience, and professional management services'\n      }\n    }\n  },\n  \n  'mortgage-lending': {\n    id: 'mortgage-lending',\n    name: 'Mortgage & Lending',\n    description: 'For mortgage brokers - compliant and advisory focused',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Financial Architect',\n      positioning: 'Precise, reassuring, and highly compliant. Avoids \"salesy\" pressure in favor of \"advisory\" clarity',\n      tone: 'Professional, educational, trustworthy'\n    },\n    \n    cognitiveLogic: {\n      framework: 'Scenario-Based Comparison',\n      reasoning: 'Logic that avoids quoting one rate and instead compares the total \"Cost of Capital\" over 5, 10, and 30 years across different loan products',\n      decisionProcess: 'Financial Situation ‚Üí Loan Product Comparison ‚Üí Total Cost Analysis'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'FHA/VA/Conventional guidelines',\n        'DTI (Debt-to-Income) calculations',\n        'Loan-to-Value (LTV) ratios',\n        'TRID compliance',\n        'Credit score requirements',\n        'Private Mortgage Insurance (PMI) rules'\n      ],\n      dynamic: [\n        'Daily rate sheets',\n        'Lender overlays',\n        'State-specific licensing requirements',\n        'Points vs. rate trade-offs',\n        'Lock period options',\n        'Real-time rate updates'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Detects when leads are \"Rate Shopping\" and triggers the \"Total Cost Analysis\" logic to compete on service and certainty rather than just 0.1% rate difference',\n      adaptation: 'Shifts from rate-focused to value-focused conversation (faster closing, better service, refinance strategy)',\n      feedbackIntegration: 'Learns which loan features (low down payment, no PMI, rate locks) matter most to different borrower segments'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Soft Pull/Pre-Application',\n      conversionRhythm: 'Directs users to a secure portal for a \"5-minute pre-qualification\" to capture verified contact info and financial snapshot',\n      secondaryActions: [\n        'Total cost comparison calculator',\n        'Pre-approval letter request',\n        'Refinance analysis',\n        'Debt consolidation review',\n        'First-time buyer education'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['linkedin-company'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'loan_officers', label: 'Multiple Loan Officers', description: 'Large team of LOs', keywords: [\"loan officers\", \"mortgage team\", \"lending team\"], regexPattern: '(\\\\d+)\\\\s*(loan officers?|los?)', priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Loan Officers', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"loan officer careers\", \"now hiring\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'any'},\n        {id: 'loan_types', label: 'Multiple Loan Products', description: 'Diverse loan offerings', keywords: [\"conventional\", \"fha\", \"va\", \"jumbo\", \"usda\", \"renovation\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'rate_guarantee', label: 'Rate Lock Guarantee', description: 'Extended rate lock', keywords: [\"rate lock\", \"lock guarantee\", \"rate protection\", \"extended lock\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'same_day_preapproval', label: 'Fast Pre-Approval', description: 'Quick pre-approval process', keywords: [\"same day\", \"fast approval\", \"quick preapproval\", \"instant approval\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'low_down_payment', label: 'Low Down Payment Options', description: 'Minimal down payment programs', keywords: [\"low down\", \"3% down\", \"zero down\", \"no money down\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 12, platform: 'website'},\n        {id: 'refinance_specialist', label: 'Refinance Specialist', description: 'Strong refinance focus', keywords: [\"refinance\", \"refi\", \"cash out\", \"lower your rate\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'first_time_buyer', label: 'First-Time Buyer Programs', description: 'Specializes in first-time buyers', keywords: [\"first time buyer\", \"first time home\", \"fthb\", \"homebuyer education\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 12, platform: 'website'},\n        {id: 'digital_application', label: 'Online Application', description: 'Digital mortgage process', keywords: [\"online application\", \"digital mortgage\", \"apply online\", \"paperless\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'lender_licenses', label: 'Multi-State Licensing', description: 'Licensed in multiple states', keywords: [\"licensed in\", \"serving\", \"states\"], regexPattern: 'licensed? in (\\\\d+) states?', priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'awards', label: 'Industry Recognition', description: 'Awards or recognition', keywords: [\"top lender\", \"award\", \"scotsman guide\", \"mortgage professional\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'closing_time', label: 'Fast Closing', description: 'Quick close guarantee', keywords: [\"fast close\", \"quick close\", \"15 day\", \"21 day close\"], regexPattern: '(\\\\d+)\\\\s*day close', priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'website'},\n        {id: 'jumbo_loans', label: 'Jumbo Loan Specialist', description: 'High-value mortgages', keywords: [\"jumbo\", \"high balance\", \"luxury homes\", \"million dollar\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 22, platform: 'website'},\n        {id: 'reverse_mortgage', label: 'Reverse Mortgage', description: 'HECM services', keywords: [\"reverse mortgage\", \"hecm\", \"home equity conversion\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'construction_loans', label: 'Construction Lending', description: 'Construction-to-perm loans', keywords: [\"construction loan\", \"build your own\", \"construction to permanent\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'equal_housing', pattern: 'equal housing', description: 'Equal housing', context: 'footer'},\n        {id: 'nmls', pattern: 'nmls #?\\\\d+', description: 'NMLS number', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'disclaimer', pattern: 'licensed mortgage|rates subject to change', description: 'Disclaimers', context: 'footer'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'rates', pattern: '^rates$', description: 'Rates link', context: 'header'},\n        {id: 'apply', pattern: '^apply( now)?$', description: 'Apply link', context: 'header'},\n        {id: 'calculator', pattern: '^calculators?$', description: 'Calculator', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'login', pattern: 'login', description: 'Login', context: 'header'},\n        {id: 'resources', pattern: '^resources$', description: 'Resources', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'large_team', name: 'Large Operation', description: 'Multiple loan officers', condition: 'signals.some(s => s.signalId === \"loan_officers\")', scoreBoost: 25, priority: 1, enabled: true},\n        {id: 'growing_company', name: 'Growing Company', description: 'Hiring with multi-state licensing', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"lender_licenses\")', scoreBoost: 30, priority: 2, enabled: true},\n        {id: 'competitive_edge', name: 'Competitive Advantage', description: 'Fast closing with rate guarantee', condition: 'signals.some(s => s.signalId === \"closing_time\") && signals.some(s => s.signalId === \"rate_guarantee\")', scoreBoost: 25, priority: 3, enabled: true},\n        {id: 'tech_forward', name: 'Technology-Forward', description: 'Digital application with fast approval', condition: 'signals.some(s => s.signalId === \"digital_application\") && signals.some(s => s.signalId === \"same_day_preapproval\")', scoreBoost: 18, priority: 4, enabled: true},\n        {id: 'diverse_products', name: 'Diverse Product Mix', description: 'Multiple specialized loan types', condition: 'signals.filter(s => [\"jumbo_loans\", \"reverse_mortgage\", \"construction_loans\", \"refinance_specialist\"].includes(s.signalId)).length >= 2', scoreBoost: 20, priority: 5, enabled: true},\n        {id: 'first_timer_focus', name: 'First-Time Buyer Specialist', description: 'FTHB programs with low down', condition: 'signals.some(s => s.signalId === \"first_time_buyer\") && signals.some(s => s.signalId === \"low_down_payment\")', scoreBoost: 15, priority: 6, enabled: true},\n        {id: 'luxury_specialist', name: 'Luxury Market', description: 'Jumbo loans with fast closing', condition: 'signals.some(s => s.signalId === \"jumbo_loans\") && signals.some(s => s.signalId === \"closing_time\")', scoreBoost: 22, priority: 7, enabled: true},\n        {id: 'recognized_leader', name: 'Industry Leader', description: 'Awards with multi-state presence', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"lender_licenses\")', scoreBoost: 25, priority: 8, enabled: true},\n        {id: 'comprehensive_services', name: 'Full-Service Lender', description: 'Multiple loan products with digital tools', condition: 'signals.some(s => s.signalId === \"loan_types\") && signals.some(s => s.signalId === \"digital_application\")', scoreBoost: 18, priority: 9, enabled: true},\n        {id: 'speed_leader', name: 'Speed Leader', description: 'Fast approval and closing', condition: 'signals.some(s => s.signalId === \"same_day_preapproval\") && signals.some(s => s.signalId === \"closing_time\")', scoreBoost: 20, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'loan_officer_count', label: 'Number of Loan Officers', type: 'number', description: 'Team size', extractionHints: ['loan officers', 'team', 'los'], required: false, defaultValue: 1},\n        {key: 'states_licensed', label: 'States Licensed', type: 'number', description: 'Multi-state reach', extractionHints: ['states', 'licensed in'], required: false, defaultValue: 1},\n        {key: 'loan_products', label: 'Loan Products Offered', type: 'array', description: 'Types of loans', extractionHints: ['conventional', 'fha', 'va', 'jumbo'], required: false, defaultValue: []},\n        {key: 'avg_closing_days', label: 'Average Closing Time (Days)', type: 'number', description: 'Typical closing period', extractionHints: ['day close', 'closing time'], required: false, defaultValue: 30},\n        {key: 'has_digital_app', label: 'Digital Application', type: 'boolean', description: 'Online application available', extractionHints: ['online', 'digital', 'apply online'], required: false, defaultValue: false},\n        {key: 'specialization', label: 'Market Specialization', type: 'string', description: 'Primary focus area', extractionHints: ['specialize', 'focus', 'expert'], required: false, defaultValue: 'general'},\n        {key: 'min_credit_score', label: 'Minimum Credit Score', type: 'number', description: 'Lowest score accepted', extractionHints: ['credit score', 'minimum', 'as low as'], required: false, defaultValue: 620}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Mortgage lending intelligence - focuses on team size, loan product diversity, processing speed, and multi-state capabilities'\n      }\n    }\n  },\n  \n  'home-staging': {\n    id: 'home-staging',\n    name: 'Home Staging',\n    description: 'For stagers - visual marketing and ROI focus',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'High-End Visual Marketer & Spatial Strategist',\n      positioning: 'Sophisticated, artistic, and ROI-focused',\n      tone: 'Elegant, professional, results-driven'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Emotional Connection Framework',\n      reasoning: 'Logic that shifts the conversation from \"furniture rental\" to \"buyer psychology\" and \"equity maximization\"',\n      decisionProcess: 'Visual Impact ‚Üí Buyer Psychology ‚Üí ROI Justification'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Design styles (Modern, Transitional, Contemporary)',\n        'Inventory logistics',\n        'Color psychology',\n        'Space optimization principles',\n        'Photography best practices'\n      ],\n      dynamic: [\n        'Client\\'s property portfolio',\n        '\"Before & After\" statistics',\n        'Package pricing tiers',\n        'Inventory availability',\n        'ROI data by property type',\n        'Market-specific styling trends'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Tracks which room types (e.g., \"Empty Living Room,\" \"Dated Kitchen\") cause the most lead hesitation',\n      adaptation: 'Prompts the client to create a specific case study for problematic room types to overcome objections',\n      feedbackIntegration: 'Correlates staging investments with days-on-market reduction and sale price increases'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Photo Quote Request',\n      conversionRhythm: 'Every conversation aims to get the lead to upload property photos for a \"Staging Impact Estimate\"',\n      secondaryActions: [\n        'Before & After portfolio review',\n        'ROI calculator (sale price increase vs staging cost)',\n        'Virtual staging preview',\n        'Package comparison guide',\n        'Consultation scheduling'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['google-business'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'portfolio_size', label: 'Large Inventory', description: 'Extensive furniture inventory', keywords: [\"inventory\", \"furniture collection\", \"pieces\", \"warehouse\"], regexPattern: '(\\\\d{3,})\\\\+?\\\\s*pieces?', priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'before_after', label: 'Before & After Portfolio', description: 'Shows transformation results', keywords: [\"before and after\", \"before & after\", \"transformations\", \"results\"], priority: 'CRITICAL', action: 'increase-score', scoreBoost: 35, platform: 'website'},\n        {id: 'virtual_staging', label: 'Virtual Staging', description: 'Offers digital staging', keywords: [\"virtual staging\", \"digital staging\", \"3d staging\", \"photo staging\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 20, platform: 'website'},\n        {id: 'occupied_staging', label: 'Occupied Home Staging', description: 'Stages occupied properties', keywords: [\"occupied\", \"lived-in\", \"consultation\", \"redesign\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'vacant_staging', label: 'Vacant Staging', description: 'Full vacant home staging', keywords: [\"vacant\", \"full staging\", \"empty home\", \"turnkey\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'luxury_staging', label: 'Luxury Staging', description: 'High-end property focus', keywords: [\"luxury\", \"high-end\", \"upscale\", \"premium\", \"million dollar\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'roi_stats', label: 'ROI Statistics', description: 'Provides staging ROI data', keywords: [\"roi\", \"return on investment\", \"increased sale price\", \"faster sale\"], regexPattern: '(\\\\d+)%\\\\s*(increase|faster|higher)', priority: 'CRITICAL', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'awards', label: 'Industry Awards', description: 'Recognition or certifications', keywords: [\"award\", \"certified\", \"accredited\", \"resa\", \"staging association\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 18, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Stagers', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"careers\", \"stager positions\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'expansion', label: 'Market Expansion', description: 'New locations or markets', keywords: [\"expanding\", \"new office\", \"now serving\", \"new market\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'any'},\n        {id: 'property_types', label: 'Multiple Property Types', description: 'Diverse staging experience', keywords: [\"residential\", \"commercial\", \"apartments\", \"condos\", \"townhomes\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'consultation_free', label: 'Free Consultation', description: 'Complimentary assessment', keywords: [\"free consultation\", \"complimentary\", \"no obligation\"], priority: 'LOW', action: 'increase-score', scoreBoost: 8, platform: 'website'},\n        {id: 'package_deals', label: 'Staging Packages', description: 'Tiered pricing options', keywords: [\"packages\", \"package pricing\", \"bronze silver gold\", \"tiers\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'quick_turnaround', label: 'Fast Installation', description: 'Quick staging setup', keywords: [\"24 hour\", \"48 hour\", \"quick install\", \"fast turnaround\"], regexPattern: '(\\\\d+)\\\\s*(hour|day)\\\\s*install', priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'partnerships', label: 'Agent Partnerships', description: 'Works with real estate agents', keywords: [\"agent partnership\", \"realtor network\", \"agent discount\", \"preferred stager\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'portfolio', pattern: '^portfolio$', description: 'Portfolio link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'gallery', pattern: '^gallery$', description: 'Gallery link', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'consultation', pattern: '^consultation$', description: 'Consult link', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'testimonials', pattern: '^testimonials$', description: 'Testimonials', context: 'header'},\n        {id: 'faq', pattern: '^faq$', description: 'FAQ', context: 'header'},\n        {id: 'pricing', pattern: '^pricing$', description: 'Pricing link', context: 'header'},\n        {id: 'process', pattern: '^(our )?process$', description: 'Process link', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'proven_results', name: 'Proven Results', description: 'Before/after with ROI stats', condition: 'signals.some(s => s.signalId === \"before_after\") && signals.some(s => s.signalId === \"roi_stats\")', scoreBoost: 35, priority: 1, enabled: true},\n        {id: 'full_service', name: 'Full-Service Provider', description: 'Virtual and physical staging', condition: 'signals.some(s => s.signalId === \"virtual_staging\") && (signals.some(s => s.signalId === \"vacant_staging\") || signals.some(s => s.signalId === \"occupied_staging\"))', scoreBoost: 25, priority: 2, enabled: true},\n        {id: 'luxury_specialist', name: 'Luxury Specialist', description: 'High-end with large inventory', condition: 'signals.some(s => s.signalId === \"luxury_staging\") && signals.some(s => s.signalId === \"portfolio_size\")', scoreBoost: 28, priority: 3, enabled: true},\n        {id: 'growing_business', name: 'Growing Business', description: 'Hiring with expansion', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"expansion\")', scoreBoost: 25, priority: 4, enabled: true},\n        {id: 'professional', name: 'Professional Operation', description: 'Awards with proven ROI', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"roi_stats\")', scoreBoost: 22, priority: 5, enabled: true},\n        {id: 'versatile', name: 'Versatile Provider', description: 'Multiple property types and staging methods', condition: 'signals.some(s => s.signalId === \"property_types\") && signals.filter(s => [\"vacant_staging\", \"occupied_staging\"].includes(s.signalId)).length >= 2', scoreBoost: 18, priority: 6, enabled: true},\n        {id: 'speed_service', name: 'Fast Service', description: 'Quick turnaround with packages', condition: 'signals.some(s => s.signalId === \"quick_turnaround\") && signals.some(s => s.signalId === \"package_deals\")', scoreBoost: 15, priority: 7, enabled: true},\n        {id: 'agent_friendly', name: 'Agent-Friendly', description: 'Partnerships with free consultation', condition: 'signals.some(s => s.signalId === \"partnerships\") && signals.some(s => s.signalId === \"consultation_free\")', scoreBoost: 12, priority: 8, enabled: true},\n        {id: 'comprehensive', name: 'Comprehensive Portfolio', description: 'Large inventory with quick install', condition: 'signals.some(s => s.signalId === \"portfolio_size\") && signals.some(s => s.signalId === \"quick_turnaround\")', scoreBoost: 20, priority: 9, enabled: true},\n        {id: 'modern_approach', name: 'Modern Approach', description: 'Virtual staging with proven results', condition: 'signals.some(s => s.signalId === \"virtual_staging\") && signals.some(s => s.signalId === \"before_after\")', scoreBoost: 18, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'inventory_count', label: 'Inventory Pieces', type: 'number', description: 'Total furniture pieces', extractionHints: ['pieces', 'inventory', 'furniture'], required: false, defaultValue: 0},\n        {key: 'avg_roi_percent', label: 'Average ROI %', type: 'number', description: 'Typical return on investment', extractionHints: ['roi', 'increase', 'return'], required: false, defaultValue: 0},\n        {key: 'service_types', label: 'Staging Services', type: 'array', description: 'Types of staging offered', extractionHints: ['vacant', 'occupied', 'virtual'], required: false, defaultValue: []},\n        {key: 'specialization', label: 'Market Specialization', type: 'string', description: 'Primary focus area', extractionHints: ['luxury', 'residential', 'commercial'], required: false, defaultValue: 'residential'},\n        {key: 'has_virtual_staging', label: 'Offers Virtual Staging', type: 'boolean', description: 'Digital staging available', extractionHints: ['virtual', 'digital'], required: false, defaultValue: false},\n        {key: 'service_areas', label: 'Service Areas', type: 'array', description: 'Geographic coverage', extractionHints: ['serving', 'areas', 'cities'], required: false, defaultValue: []},\n        {key: 'install_time_hours', label: 'Typical Install Time (Hours)', type: 'number', description: 'Average setup time', extractionHints: ['hour', 'install', 'setup'], required: false, defaultValue: 48}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Home staging intelligence - focuses on portfolio size, ROI demonstration, service diversity, and luxury market capabilities'\n      }\n    }\n  },\n  \n  'interior-design': {\n    id: 'interior-design',\n    name: 'Interior Design',\n    description: 'For designers - aesthetic and functional consultation',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Visionary Consultant',\n      positioning: 'Elegant, detailed, authoritative, and creative',\n      tone: 'Sophisticated, collaborative, inspirational'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Lifestyle Discovery Model',\n      reasoning: 'Logic that uses \"Diagnostic Questions\" to uncover a client\\'s aesthetic and functional needs before suggesting a style',\n      decisionProcess: 'Discovery ‚Üí Vision Alignment ‚Üí Curated Solutions'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Material durability standards',\n        'Color theory principles',\n        'Space planning fundamentals',\n        'Lighting design basics',\n        'Furniture scale and proportion'\n      ],\n      dynamic: [\n        'Vendor lists and lead times',\n        'Designer\\'s specific aesthetic \"signature\"',\n        'Material pricing and availability',\n        'Trend forecasting data',\n        'Portfolio images by style',\n        'Project timelines'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Analyzes lead \"Inspiration\" keywords (e.g., \"Scandi,\" \"Moody,\" \"Minimalist,\" \"Maximalist\")',\n      adaptation: 'Automatically curates the first set of portfolio images shown to the lead based on detected aesthetic preferences',\n      feedbackIntegration: 'Tracks which design styles convert best for different client demographics and project types'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Design Discovery Call',\n      conversionRhythm: 'Focuses on booking a paid or free consultation to establish project scope and vision alignment',\n      secondaryActions: [\n        'Style quiz/assessment',\n        'Portfolio showcase (filtered by style)',\n        'Mood board creation',\n        'Budget range discussion',\n        'Timeline planning'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['google-business'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'portfolio_projects', label: 'Extensive Portfolio', description: 'Large project portfolio', keywords: [\"projects\", \"portfolio\", \"completed\", \"featured work\"], regexPattern: '(\\\\d{2,})\\\\+?\\\\s*projects?', priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'awards', label: 'Design Awards', description: 'Industry recognition', keywords: [\"award\", \"best of houzz\", \"asid\", \"designer of the year\", \"featured in\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'residential_design', label: 'Residential Design', description: 'Home design focus', keywords: [\"residential\", \"home design\", \"whole house\", \"room redesign\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'commercial_design', label: 'Commercial Design', description: 'Commercial space expertise', keywords: [\"commercial\", \"office design\", \"retail\", \"hospitality design\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'full_service', label: 'Full-Service Design', description: 'End-to-end design services', keywords: [\"full service\", \"turnkey\", \"concept to completion\", \"from start to finish\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'virtual_design', label: 'Virtual/Online Design', description: 'Remote design services', keywords: [\"virtual design\", \"online design\", \"e-design\", \"remote consultation\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'luxury_design', label: 'Luxury Design', description: 'High-end market focus', keywords: [\"luxury\", \"high-end\", \"upscale\", \"custom\", \"bespoke\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 28, platform: 'website'},\n        {id: 'sustainable_design', label: 'Sustainable Design', description: 'Eco-friendly focus', keywords: [\"sustainable\", \"eco-friendly\", \"green design\", \"leed\", \"environmental\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'renovation_specialist', label: 'Renovation Specialist', description: 'Remodel expertise', keywords: [\"renovation\", \"remodel\", \"restoration\", \"historic\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Designers', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"designer positions\", \"careers\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'showroom', label: 'Design Showroom', description: 'Physical showroom space', keywords: [\"showroom\", \"design studio\", \"visit us\", \"come see\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'trade_program', label: 'Trade Program', description: 'Works with trade professionals', keywords: [\"trade\", \"to the trade\", \"designer discount\", \"trade only\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'certifications', label: 'Professional Certifications', description: 'Industry credentials', keywords: [\"asid\", \"iida\", \"ncidq\", \"certified\", \"accredited\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'featured_press', label: 'Media Features', description: 'Press coverage', keywords: [\"featured in\", \"elle decor\", \"architectural digest\", \"house beautiful\", \"press\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'specialty_services', label: 'Specialty Services', description: 'Niche design services', keywords: [\"color consultation\", \"space planning\", \"lighting design\", \"custom furniture\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'portfolio', pattern: '^portfolio$', description: 'Portfolio link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'process', pattern: '^process$', description: 'Process link', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'consultation', pattern: '^consultation$', description: 'Consult link', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'testimonials', pattern: '^testimonials$', description: 'Testimonials', context: 'header'},\n        {id: 'gallery', pattern: '^gallery$', description: 'Gallery', context: 'header'},\n        {id: 'shop', pattern: '^shop$', description: 'Shop link', context: 'header'},\n        {id: 'press', pattern: '^press$', description: 'Press link', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'recognized_designer', name: 'Recognized Designer', description: 'Awards with media features', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"featured_press\")', scoreBoost: 35, priority: 1, enabled: true},\n        {id: 'luxury_specialist', name: 'Luxury Specialist', description: 'Luxury focus with extensive portfolio', condition: 'signals.some(s => s.signalId === \"luxury_design\") && signals.some(s => s.signalId === \"portfolio_projects\")', scoreBoost: 30, priority: 2, enabled: true},\n        {id: 'comprehensive_provider', name: 'Comprehensive Provider', description: 'Full-service with showroom', condition: 'signals.some(s => s.signalId === \"full_service\") && signals.some(s => s.signalId === \"showroom\")', scoreBoost: 25, priority: 3, enabled: true},\n        {id: 'growing_firm', name: 'Growing Firm', description: 'Hiring with expansion', condition: 'signals.some(s => s.signalId === \"hiring\")', scoreBoost: 25, priority: 4, enabled: true},\n        {id: 'versatile', name: 'Versatile Designer', description: 'Both residential and commercial', condition: 'signals.some(s => s.signalId === \"residential_design\") && signals.some(s => s.signalId === \"commercial_design\")', scoreBoost: 22, priority: 5, enabled: true},\n        {id: 'professional', name: 'Professional', description: 'Certifications with awards', condition: 'signals.some(s => s.signalId === \"certifications\") && signals.some(s => s.signalId === \"awards\")', scoreBoost: 20, priority: 6, enabled: true},\n        {id: 'modern_approach', name: 'Modern Approach', description: 'Virtual and traditional services', condition: 'signals.some(s => s.signalId === \"virtual_design\") && signals.some(s => s.signalId === \"full_service\")', scoreBoost: 18, priority: 7, enabled: true},\n        {id: 'eco_conscious', name: 'Eco-Conscious', description: 'Sustainable design with certifications', condition: 'signals.some(s => s.signalId === \"sustainable_design\")', scoreBoost: 15, priority: 8, enabled: true},\n        {id: 'renovation_expert', name: 'Renovation Expert', description: 'Renovation specialist with portfolio', condition: 'signals.some(s => s.signalId === \"renovation_specialist\") && signals.some(s => s.signalId === \"portfolio_projects\")', scoreBoost: 18, priority: 9, enabled: true},\n        {id: 'trade_professional', name: 'Trade Professional', description: 'Trade program with showroom', condition: 'signals.some(s => s.signalId === \"trade_program\") && signals.some(s => s.signalId === \"showroom\")', scoreBoost: 15, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'project_count', label: 'Number of Projects', type: 'number', description: 'Completed projects', extractionHints: ['projects', 'completed', 'portfolio'], required: false, defaultValue: 0},\n        {key: 'design_styles', label: 'Design Styles', type: 'array', description: 'Aesthetic specializations', extractionHints: ['modern', 'traditional', 'transitional', 'contemporary'], required: false, defaultValue: []},\n        {key: 'specialization', label: 'Market Specialization', type: 'string', description: 'Primary focus area', extractionHints: ['residential', 'commercial', 'luxury'], required: false, defaultValue: 'residential'},\n        {key: 'has_showroom', label: 'Has Showroom', type: 'boolean', description: 'Physical showroom location', extractionHints: ['showroom', 'studio'], required: false, defaultValue: false},\n        {key: 'offers_virtual', label: 'Offers Virtual Design', type: 'boolean', description: 'Remote services available', extractionHints: ['virtual', 'online', 'e-design'], required: false, defaultValue: false},\n        {key: 'service_areas', label: 'Service Areas', type: 'array', description: 'Geographic coverage', extractionHints: ['serving', 'areas', 'cities'], required: false, defaultValue: []},\n        {key: 'team_size', label: 'Team Size', type: 'number', description: 'Number of designers', extractionHints: ['designers', 'team', 'staff'], required: false, defaultValue: 1}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Interior design intelligence - focuses on portfolio depth, industry recognition, service breadth, and market specialization'\n      }\n    }\n  },\n  \n  'architecture': {\n    id: 'architecture',\n    name: 'Architecture',\n    description: 'For architects - technical vision and regulatory expertise',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Technical Visionary',\n      positioning: 'Precise, visionary, and highly regulatory-aware. Focused on the intersection of \"Form and Function\"',\n      tone: 'Professional, technical, forward-thinking'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Feasibility-First Logic',\n      reasoning: 'Logic that prioritizes \"Can we build this?\" (zoning/code compliance) before \"What will it look like?\" (aesthetic design)',\n      decisionProcess: 'Regulatory Feasibility ‚Üí Technical Design ‚Üí Aesthetic Vision'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Building codes (IBC, IRC)',\n        'ADA compliance requirements',\n        'Structural engineering basics',\n        'Zoning regulations',\n        'Environmental design standards',\n        'Permit processes'\n      ],\n      dynamic: [\n        'Local permit timelines by jurisdiction',\n        'Past project blueprints',\n        'Firm-specific CAD/BIM processes',\n        'Zoning variances and precedents',\n        'Material innovations',\n        'Code updates and changes'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Flags if users are asking for \"Impossible Builds\" (e.g., 5 stories in a 2-story zoning district)',\n      adaptation: 'Suggests a \"Zoning Consultation\" or \"Variance Application\" strategy instead of immediate design engagement',\n      feedbackIntegration: 'Learns which code/zoning questions are most common and proactively addresses them early in conversation'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Feasibility Assessment',\n      conversionRhythm: 'Directs users toward a \"Site Review\" or \"Master Planning\" phase to establish viability before design',\n      secondaryActions: [\n        'Zoning analysis',\n        'Code compliance review',\n        'Conceptual design presentation',\n        'Preliminary budget estimate',\n        'Project timeline development'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['linkedin-company'],\n        frequency: 'weekly',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 600\n      },\n\n      highValueSignals: [\n        {id: 'project_count', label: 'Large Portfolio', description: 'Many completed projects', keywords: [\"projects\", \"portfolio\", \"completed\"], regexPattern: '(\\\\d{2,})\\\\+?\\\\s*projects?', priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'awards', label: 'Architecture Awards', description: 'Industry recognition', keywords: [\"aia award\", \"design award\", \"architecture award\", \"recognition\"], priority: 'CRITICAL', action: 'increase-score', scoreBoost: 40, platform: 'website'},\n        {id: 'leed_certified', label: 'LEED Certification', description: 'Sustainable design credentials', keywords: [\"leed\", \"leed certified\", \"green building\", \"sustainable\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'commercial_architecture', label: 'Commercial Architecture', description: 'Commercial project focus', keywords: [\"commercial\", \"office building\", \"retail\", \"hospitality\", \"mixed-use\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'residential_architecture', label: 'Residential Architecture', description: 'Custom home design', keywords: [\"residential\", \"custom homes\", \"single family\", \"estates\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'master_planning', label: 'Master Planning', description: 'Large-scale planning services', keywords: [\"master planning\", \"urban design\", \"site planning\", \"campus\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 28, platform: 'website'},\n        {id: 'renovation_adaptive', label: 'Renovation & Adaptive Reuse', description: 'Historic renovation expertise', keywords: [\"renovation\", \"adaptive reuse\", \"historic\", \"restoration\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'team_size', label: 'Large Firm', description: 'Multiple architects', keywords: [\"architects\", \"principals\", \"team\"], regexPattern: '(\\\\d+)\\\\s*architects?', priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Architects', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"architect positions\", \"careers\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'any'},\n        {id: 'bim_services', label: 'BIM Services', description: 'Building Information Modeling', keywords: [\"bim\", \"revit\", \"3d modeling\", \"digital twin\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'international_projects', label: 'International Projects', description: 'Global project experience', keywords: [\"international\", \"global\", \"worldwide\", \"countries\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 22, platform: 'website'},\n        {id: 'specialization', label: 'Specialized Practice', description: 'Niche expertise', keywords: [\"healthcare\", \"education\", \"hospitality\", \"industrial\", \"institutional\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'published_work', label: 'Published Work', description: 'Featured in publications', keywords: [\"published\", \"architectural digest\", \"featured in\", \"architecture magazine\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'registered', label: 'Licensed Architects', description: 'Professional licensure', keywords: [\"licensed\", \"registered\", \"aia\", \"ncarb\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'multi_office', label: 'Multiple Offices', description: 'Multi-location firm', keywords: [\"offices\", \"locations\", \"office in\"], regexPattern: '(\\\\d+)\\\\s*offices?', priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'projects', pattern: '^projects$', description: 'Projects link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'news', pattern: '^news$', description: 'News link', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'careers', pattern: '^careers$', description: 'Careers', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'team', pattern: '^team$', description: 'Team link', context: 'header'},\n        {id: 'press', pattern: '^press$', description: 'Press link', context: 'header'},\n        {id: 'awards', pattern: '^awards$', description: 'Awards link', context: 'header'},\n        {id: 'sustainability', pattern: '^sustainability$', description: 'Sustainability', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'award_winning_firm', name: 'Award-Winning Firm', description: 'AIA awards with large portfolio', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"project_count\")', scoreBoost: 40, priority: 1, enabled: true},\n        {id: 'large_practice', name: 'Large Practice', description: 'Multiple architects with offices', condition: 'signals.some(s => s.signalId === \"team_size\") && signals.some(s => s.signalId === \"multi_office\")', scoreBoost: 35, priority: 2, enabled: true},\n        {id: 'sustainable_leader', name: 'Sustainable Leader', description: 'LEED certified with green focus', condition: 'signals.some(s => s.signalId === \"leed_certified\")', scoreBoost: 25, priority: 3, enabled: true},\n        {id: 'tech_forward', name: 'Technology-Forward', description: 'BIM services with modern tools', condition: 'signals.some(s => s.signalId === \"bim_services\")', scoreBoost: 18, priority: 4, enabled: true},\n        {id: 'versatile', name: 'Versatile Practice', description: 'Both commercial and residential', condition: 'signals.some(s => s.signalId === \"commercial_architecture\") && signals.some(s => s.signalId === \"residential_architecture\")', scoreBoost: 22, priority: 5, enabled: true},\n        {id: 'growing_firm', name: 'Growing Firm', description: 'Hiring architects', condition: 'signals.some(s => s.signalId === \"hiring\")', scoreBoost: 30, priority: 6, enabled: true},\n        {id: 'recognized_leader', name: 'Recognized Leader', description: 'Published with awards', condition: 'signals.some(s => s.signalId === \"published_work\") && signals.some(s => s.signalId === \"awards\")', scoreBoost: 35, priority: 7, enabled: true},\n        {id: 'global_reach', name: 'Global Practice', description: 'International projects with large team', condition: 'signals.some(s => s.signalId === \"international_projects\") && signals.some(s => s.signalId === \"team_size\")', scoreBoost: 30, priority: 8, enabled: true},\n        {id: 'niche_expert', name: 'Niche Expert', description: 'Specialized practice area', condition: 'signals.some(s => s.signalId === \"specialization\")', scoreBoost: 18, priority: 9, enabled: true},\n        {id: 'adaptive_reuse', name: 'Adaptive Reuse Specialist', description: 'Historic renovation with portfolio', condition: 'signals.some(s => s.signalId === \"renovation_adaptive\") && signals.some(s => s.signalId === \"project_count\")', scoreBoost: 20, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'architect_count', label: 'Number of Architects', type: 'number', description: 'Licensed architects on staff', extractionHints: ['architects', 'principals', 'team'], required: false, defaultValue: 1},\n        {key: 'project_types', label: 'Project Types', type: 'array', description: 'Types of architecture', extractionHints: ['residential', 'commercial', 'institutional'], required: false, defaultValue: []},\n        {key: 'has_leed_accreditation', label: 'LEED Accredited', type: 'boolean', description: 'LEED certification', extractionHints: ['leed'], required: false, defaultValue: false},\n        {key: 'has_bim', label: 'Uses BIM', type: 'boolean', description: 'BIM capabilities', extractionHints: ['bim', 'revit'], required: false, defaultValue: false},\n        {key: 'office_locations', label: 'Office Count', type: 'number', description: 'Number of offices', extractionHints: ['offices', 'locations'], required: false, defaultValue: 1},\n        {key: 'specialization', label: 'Practice Specialization', type: 'string', description: 'Primary focus area', extractionHints: ['specialize', 'focus', 'expert'], required: false, defaultValue: 'general'},\n        {key: 'years_established', label: 'Years in Practice', type: 'number', description: 'Firm age', extractionHints: ['established', 'since', 'years'], required: false, defaultValue: 0}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Architecture intelligence - focuses on firm size, project diversity, sustainability credentials, and industry recognition'\n      }\n    }\n  },\n  \n  'construction-development': {\n    id: 'construction-development',\n    name: 'Construction & Development',\n    description: 'For builders - reliability and timeline management',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Master Builder',\n      positioning: 'Reliable, transparent, ruggedly professional, and timeline-driven',\n      tone: 'Straightforward, competent, trustworthy'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Critical Path Framework',\n      reasoning: 'Logic that emphasizes the \"Build Sequence,\" safety protocols, and budget transparency. Focuses on \"De-risking\" the project for the owner',\n      decisionProcess: 'Risk Assessment ‚Üí Sequencing ‚Üí Budget Control'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Material cost baselines',\n        'Trade sequences (Foundation ‚Üí Framing ‚Üí MEP ‚Üí Finishes)',\n        'Safety regulations (OSHA)',\n        'Quality control standards',\n        'Warranty structures'\n      ],\n      dynamic: [\n        'Current subcontractor availability',\n        'Project gallery (completed work)',\n        'Safety certifications and insurance',\n        'Material pricing (lumber, steel, concrete)',\n        'Weather delays and seasonal factors',\n        'Permit status tracking'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Tracks lead anxiety regarding \"Budget Overruns\" and \"Timeline Delays\"',\n      adaptation: 'Triggers a \"Fixed-Price vs. Cost-Plus\" educational module to address pricing concerns proactively',\n      feedbackIntegration: 'Identifies which guarantees (timeline, budget, quality) are most important to different client types'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Bid Request',\n      conversionRhythm: 'Moves the lead toward submitting plans for a \"Preliminary Estimate\" or \"Detailed Proposal\"',\n      secondaryActions: [\n        'Project timeline estimate',\n        'Material selection consultation',\n        'Subcontractor vetting process',\n        'Site visit scheduling',\n        'Financing options discussion'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['google-business', 'linkedin-company'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'projects_completed', label: 'High Project Volume', description: 'Many completed projects', keywords: [\"projects completed\", \"homes built\", \"developments\"], regexPattern: '(\\\\d{2,})\\\\+?\\\\s*(projects?|homes?|developments?)', priority: 'CRITICAL', action: 'increase-score', scoreBoost: 35, platform: 'website'},\n        {id: 'custom_homes', label: 'Custom Home Builder', description: 'Custom residential construction', keywords: [\"custom homes\", \"custom builder\", \"luxury homes\", \"estate homes\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'commercial_construction', label: 'Commercial Construction', description: 'Commercial project experience', keywords: [\"commercial construction\", \"office building\", \"retail construction\", \"industrial\"], priority: 'HIGH', action: 'add-to-segment', scoreBoost: 25, platform: 'website'},\n        {id: 'design_build', label: 'Design-Build Services', description: 'Integrated design-build', keywords: [\"design build\", \"design-build\", \"single source\", \"one stop\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 28, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Construction Workers', description: 'Growing workforce', keywords: [\"hiring\", \"now hiring\", \"careers\", \"join our team\", \"construction jobs\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'any'},\n        {id: 'expansion', label: 'Business Expansion', description: 'New markets or locations', keywords: [\"expanding\", \"new office\", \"now building in\", \"new market\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'certifications', label: 'Industry Certifications', description: 'Professional credentials', keywords: [\"licensed\", \"insured\", \"bonded\", \"nahb\", \"certified\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'warranty', label: 'Warranty Program', description: 'Construction warranty offered', keywords: [\"warranty\", \"guarantee\", \"quality assurance\"], regexPattern: '(\\\\d+)\\\\s*year warranty', priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'green_building', label: 'Green Building', description: 'Sustainable construction', keywords: [\"green building\", \"leed\", \"energy efficient\", \"sustainable\", \"net zero\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'subdivisions', label: 'Subdivision Development', description: 'Community development', keywords: [\"subdivision\", \"community\", \"development\", \"master planned\"], priority: 'CRITICAL', action: 'add-to-segment', scoreBoost: 35, platform: 'website'},\n        {id: 'remodeling', label: 'Remodeling Services', description: 'Renovation/addition expertise', keywords: [\"remodeling\", \"renovation\", \"additions\", \"home improvement\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'awards', label: 'Industry Awards', description: 'Builder awards or recognition', keywords: [\"builder of the year\", \"parade of homes\", \"award winning\", \"best builder\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'safety_record', label: 'Safety Record', description: 'Emphasizes safety performance', keywords: [\"safety\", \"osha\", \"zero accidents\", \"safety first\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'fixed_price', label: 'Fixed-Price Contracts', description: 'Guaranteed pricing', keywords: [\"fixed price\", \"guaranteed price\", \"no surprises\", \"firm quote\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: 'timeline_guarantee', label: 'Timeline Guarantee', description: 'On-time completion promise', keywords: [\"on-time\", \"timeline guarantee\", \"completion date\", \"scheduled completion\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'licensed', pattern: 'licensed.*insured.*bonded', description: 'License boilerplate', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'projects', pattern: '^projects$', description: 'Projects link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'gallery', pattern: '^gallery$', description: 'Gallery', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'careers', pattern: '^careers$', description: 'Careers', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'testimonials', pattern: '^testimonials$', description: 'Testimonials', context: 'header'},\n        {id: 'process', pattern: '^process$', description: 'Process link', context: 'header'},\n        {id: 'financing', pattern: '^financing$', description: 'Financing link', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'large_builder', name: 'Large Builder', description: 'High project volume with team growth', condition: 'signals.some(s => s.signalId === \"projects_completed\") && signals.some(s => s.signalId === \"hiring\")', scoreBoost: 40, priority: 1, enabled: true},\n        {id: 'design_build_firm', name: 'Design-Build Firm', description: 'Design-build with custom homes', condition: 'signals.some(s => s.signalId === \"design_build\") && signals.some(s => s.signalId === \"custom_homes\")', scoreBoost: 30, priority: 2, enabled: true},\n        {id: 'developer', name: 'Developer', description: 'Subdivision development with volume', condition: 'signals.some(s => s.signalId === \"subdivisions\") && signals.some(s => s.signalId === \"projects_completed\")', scoreBoost: 40, priority: 3, enabled: true},\n        {id: 'quality_focused', name: 'Quality-Focused', description: 'Awards with warranty', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"warranty\")', scoreBoost: 25, priority: 4, enabled: true},\n        {id: 'versatile_builder', name: 'Versatile Builder', description: 'Custom and commercial', condition: 'signals.some(s => s.signalId === \"custom_homes\") && signals.some(s => s.signalId === \"commercial_construction\")', scoreBoost: 28, priority: 5, enabled: true},\n        {id: 'remodeling_specialist', name: 'Remodeling Specialist', description: 'Renovation focus with portfolio', condition: 'signals.some(s => s.signalId === \"remodeling\") && signals.some(s => s.signalId === \"projects_completed\")', scoreBoost: 20, priority: 6, enabled: true},\n        {id: 'sustainable_builder', name: 'Sustainable Builder', description: 'Green building with certifications', condition: 'signals.some(s => s.signalId === \"green_building\") && signals.some(s => s.signalId === \"certifications\")', scoreBoost: 22, priority: 7, enabled: true},\n        {id: 'reliable_contractor', name: 'Reliable Contractor', description: 'Timeline and price guarantees', condition: 'signals.some(s => s.signalId === \"timeline_guarantee\") && signals.some(s => s.signalId === \"fixed_price\")', scoreBoost: 25, priority: 8, enabled: true},\n        {id: 'expanding_business', name: 'Expanding Business', description: 'Hiring with market expansion', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"expansion\")', scoreBoost: 30, priority: 9, enabled: true},\n        {id: 'safety_conscious', name: 'Safety-Conscious', description: 'Safety record with certifications', condition: 'signals.some(s => s.signalId === \"safety_record\") && signals.some(s => s.signalId === \"certifications\")', scoreBoost: 15, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'projects_completed', label: 'Projects Completed', type: 'number', description: 'Total completed projects', extractionHints: ['projects', 'homes built', 'completed'], required: false, defaultValue: 0},\n        {key: 'construction_types', label: 'Construction Types', type: 'array', description: 'Project types handled', extractionHints: ['custom', 'commercial', 'remodeling'], required: false, defaultValue: []},\n        {key: 'has_design_build', label: 'Design-Build Capabilities', type: 'boolean', description: 'Integrated services', extractionHints: ['design build'], required: false, defaultValue: false},\n        {key: 'service_areas', label: 'Service Areas', type: 'array', description: 'Geographic coverage', extractionHints: ['serving', 'areas', 'cities'], required: false, defaultValue: []},\n        {key: 'warranty_years', label: 'Warranty (Years)', type: 'number', description: 'Warranty period', extractionHints: ['year warranty', 'warranty'], required: false, defaultValue: 1},\n        {key: 'specialization', label: 'Specialization', type: 'string', description: 'Primary focus', extractionHints: ['specialize', 'custom homes', 'commercial'], required: false, defaultValue: 'general'},\n        {key: 'years_in_business', label: 'Years Established', type: 'number', description: 'Years operating', extractionHints: ['years', 'since', 'established'], required: false, defaultValue: 0}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Construction & development intelligence - focuses on project volume, service diversity, certifications, and growth indicators'\n      }\n    }\n  },\n  \n  'title-escrow': {\n    id: 'title-escrow',\n    name: 'Title & Escrow',\n    description: 'For title/escrow companies - compliance and security focus',\n    category: 'Real Estate',\n    \n    coreIdentity: {\n      title: 'The Neutral Third-Party / The Deal Closer',\n      positioning: 'Calm, precise, legally rigorous, and administrative',\n      tone: 'Professional, reassuring, detail-oriented'\n    },\n    \n    cognitiveLogic: {\n      framework: 'The Compliance & Security Logic',\n      reasoning: 'Focuses on \"Clear Title,\" \"Wire Fraud Protection,\" and the \"Final Milestone\" of the transaction',\n      decisionProcess: 'Title Verification ‚Üí Risk Mitigation ‚Üí Secure Closing'\n    },\n    \n    knowledgeRAG: {\n      static: [\n        'Closing disclosure requirements',\n        'Lien search protocols',\n        'ALTA (American Land Title Association) standards',\n        'Title insurance types',\n        'Escrow disbursement rules',\n        'Recording procedures'\n      ],\n      dynamic: [\n        'Fee calculators by state/county',\n        'Current turn-around times',\n        'Firm-specific wire instructions (secured)',\n        'Title clearance status',\n        'Closing cost breakdowns',\n        'Document tracking'\n      ]\n    },\n    \n    learningLoops: {\n      patternRecognition: 'Monitors common \"Closing Friction\" questions (wire fraud, unclear fees, timeline delays)',\n      adaptation: 'Prompts the agent to proactively explain things like \"Prerecorded documents\" to first-time sellers/buyers',\n      feedbackIntegration: 'Identifies which security measures (wire verification, fraud prevention) resonate most with different client types'\n    },\n    \n    tacticalExecution: {\n      primaryAction: 'Order Initiation',\n      conversionRhythm: 'Focuses on getting the \"Purchase Agreement\" uploaded to open the file and begin title search',\n      secondaryActions: [\n        'Wire fraud protection education',\n        'Closing cost estimate',\n        'Timeline confirmation',\n        'Document checklist provision',\n        'Secure portal setup'\n      ]\n    },\n\n    research: {\n      scrapingStrategy: {\n        primarySource: 'website',\n        secondarySources: ['linkedin-company'],\n        frequency: 'per-lead',\n        timeoutMs: 30000,\n        enableCaching: true,\n        cacheTtlSeconds: 300\n      },\n\n      highValueSignals: [\n        {id: 'transaction_volume', label: 'High Transaction Volume', description: 'Many closings per year', keywords: [\"transactions\", \"closings\", \"files closed\"], regexPattern: '([\\\\d,]+)\\\\s*(transactions?|closings?)', priority: 'CRITICAL', action: 'increase-score', scoreBoost: 40, platform: 'website'},\n        {id: 'multi_state', label: 'Multi-State Operations', description: 'Licensed in multiple states', keywords: [\"licensed in\", \"serving\", \"states\"], regexPattern: 'licensed? in (\\\\d+) states?', priority: 'HIGH', action: 'increase-score', scoreBoost: 30, platform: 'website'},\n        {id: 'hiring', label: 'Hiring Escrow Officers', description: 'Growing team', keywords: [\"hiring\", \"join our team\", \"careers\", \"escrow officer\", \"title examiner\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 28, platform: 'any'},\n        {id: 'expansion', label: 'Office Expansion', description: 'New offices or markets', keywords: [\"new office\", \"expanding\", \"now serving\", \"new location\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'any'},\n        {id: 'wire_fraud_protection', label: 'Wire Fraud Protection', description: 'Advanced security measures', keywords: [\"wire fraud\", \"fraud protection\", \"secure wire\", \"verified wiring\", \"wire verification\"], priority: 'CRITICAL', action: 'increase-score', scoreBoost: 35, platform: 'website'},\n        {id: 'online_closing', label: 'Online/Remote Closing', description: 'Digital closing capability', keywords: [\"remote closing\", \"online closing\", \"e-closing\", \"digital closing\", \"notary\"], priority: 'HIGH', action: 'increase-score', scoreBoost: 25, platform: 'website'},\n        {id: 'commercial_title', label: 'Commercial Title', description: 'Commercial transaction expertise', keywords: [\"commercial\", \"commercial title\", \"business transactions\", \"investment properties\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 18, platform: 'website'},\n        {id: 'refinance_specialist', label: 'Refinance Services', description: 'Refinance focus', keywords: [\"refinance\", \"refi\", \"refinancing\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 12, platform: 'website'},\n        {id: 'fast_turnaround', label: 'Fast Turnaround', description: 'Quick closing time', keywords: [\"fast closing\", \"quick turnaround\", \"rush service\"], regexPattern: '(\\\\d+)\\\\s*day (closing|turnaround)', priority: 'HIGH', action: 'increase-score', scoreBoost: 20, platform: 'website'},\n        {id: 'underwriter_direct', label: 'Direct Underwriter', description: 'Owned by underwriter', keywords: [\"underwriter\", \"direct\", \"first american\", \"fidelity\", \"old republic\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'},\n        {id: '1031_exchange', label: '1031 Exchange Services', description: 'Qualified intermediary', keywords: [\"1031\", \"qualified intermediary\", \"exchange\", \"tax-deferred\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 15, platform: 'website'},\n        {id: 'builder_services', label: 'Builder Services', description: 'New construction closings', keywords: [\"builder services\", \"new construction\", \"builder\", \"construction closings\"], priority: 'MEDIUM', action: 'add-to-segment', scoreBoost: 12, platform: 'website'},\n        {id: 'mobile_closing', label: 'Mobile Closing', description: 'Notary travels to client', keywords: [\"mobile closing\", \"we come to you\", \"convenient closing\", \"travel\"], priority: 'LOW', action: 'increase-score', scoreBoost: 10, platform: 'website'},\n        {id: 'customer_portal', label: 'Online Portal', description: 'Client portal access', keywords: [\"online portal\", \"client portal\", \"document portal\", \"secure access\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 12, platform: 'website'},\n        {id: 'awards', label: 'Industry Recognition', description: 'Awards or top company status', keywords: [\"award\", \"best title\", \"top company\", \"recognition\"], priority: 'MEDIUM', action: 'increase-score', scoreBoost: 15, platform: 'website'}\n      ],\n\n      fluffPatterns: [\n        {id: 'copyright', pattern: '¬©\\\\s*\\\\d{4}', description: 'Copyright', context: 'footer'},\n        {id: 'rights', pattern: 'all rights reserved', description: 'Rights', context: 'footer'},\n        {id: 'privacy', pattern: 'privacy policy', description: 'Privacy', context: 'footer'},\n        {id: 'terms', pattern: 'terms (of|and)', description: 'Terms', context: 'footer'},\n        {id: 'cookies', pattern: 'cookies', description: 'Cookie notice', context: 'all'},\n        {id: 'licensed', pattern: 'licensed.*regulated', description: 'License notice', context: 'footer'},\n        {id: 'social', pattern: 'follow us', description: 'Social media', context: 'footer'},\n        {id: 'contact', pattern: '^contact$', description: 'Contact link', context: 'header'},\n        {id: 'about', pattern: '^about$', description: 'About link', context: 'header'},\n        {id: 'services', pattern: '^services$', description: 'Services', context: 'header'},\n        {id: 'locations', pattern: '^locations$', description: 'Locations', context: 'header'},\n        {id: 'back_top', pattern: 'back to top', description: 'Back to top', context: 'footer'},\n        {id: 'sitemap', pattern: 'sitemap', description: 'Sitemap', context: 'footer'},\n        {id: 'powered', pattern: 'powered by', description: 'Attribution', context: 'footer'},\n        {id: 'careers', pattern: '^careers$', description: 'Careers', context: 'header'},\n        {id: 'blog', pattern: '^blog$', description: 'Blog', context: 'header'},\n        {id: 'calculator', pattern: '^calculator$', description: 'Calculator', context: 'header'},\n        {id: 'faq', pattern: '^faq$', description: 'FAQ', context: 'header'},\n        {id: 'portal', pattern: '^portal$', description: 'Portal link', context: 'header'},\n        {id: 'resources', pattern: '^resources$', description: 'Resources', context: 'header'}\n      ],\n\n      scoringRules: [\n        {id: 'high_volume_operator', name: 'High-Volume Operator', description: 'High transactions with multi-state presence', condition: 'signals.some(s => s.signalId === \"transaction_volume\") && signals.some(s => s.signalId === \"multi_state\")', scoreBoost: 45, priority: 1, enabled: true},\n        {id: 'security_leader', name: 'Security Leader', description: 'Wire fraud protection with online portal', condition: 'signals.some(s => s.signalId === \"wire_fraud_protection\") && signals.some(s => s.signalId === \"customer_portal\")', scoreBoost: 30, priority: 2, enabled: true},\n        {id: 'modern_company', name: 'Modern Company', description: 'Online closing with digital portal', condition: 'signals.some(s => s.signalId === \"online_closing\") && signals.some(s => s.signalId === \"customer_portal\")', scoreBoost: 25, priority: 3, enabled: true},\n        {id: 'growing_business', name: 'Growing Business', description: 'Hiring with expansion', condition: 'signals.some(s => s.signalId === \"hiring\") && signals.some(s => s.signalId === \"expansion\")', scoreBoost: 30, priority: 4, enabled: true},\n        {id: 'versatile_services', name: 'Versatile Services', description: 'Residential and commercial', condition: 'signals.some(s => s.signalId === \"commercial_title\")', scoreBoost: 18, priority: 5, enabled: true},\n        {id: 'speed_service', name: 'Speed Service', description: 'Fast turnaround with high volume', condition: 'signals.some(s => s.signalId === \"fast_turnaround\") && signals.some(s => s.signalId === \"transaction_volume\")', scoreBoost: 25, priority: 6, enabled: true},\n        {id: 'builder_partner', name: 'Builder Partner', description: 'Builder services with volume', condition: 'signals.some(s => s.signalId === \"builder_services\") && signals.some(s => s.signalId === \"transaction_volume\")', scoreBoost: 20, priority: 7, enabled: true},\n        {id: 'exchange_specialist', name: '1031 Exchange Specialist', description: '1031 services with commercial title', condition: 'signals.some(s => s.signalId === \"1031_exchange\") && signals.some(s => s.signalId === \"commercial_title\")', scoreBoost: 22, priority: 8, enabled: true},\n        {id: 'convenience_focused', name: 'Convenience-Focused', description: 'Mobile and online closing', condition: 'signals.some(s => s.signalId === \"mobile_closing\") && signals.some(s => s.signalId === \"online_closing\")', scoreBoost: 18, priority: 9, enabled: true},\n        {id: 'recognized_company', name: 'Recognized Company', description: 'Awards with high volume', condition: 'signals.some(s => s.signalId === \"awards\") && signals.some(s => s.signalId === \"transaction_volume\")', scoreBoost: 25, priority: 10, enabled: true}\n      ],\n\n      customFields: [\n        {key: 'annual_transactions', label: 'Annual Transactions', type: 'number', description: 'Yearly closing volume', extractionHints: ['transactions', 'closings', 'files'], required: false, defaultValue: 0},\n        {key: 'states_licensed', label: 'States Licensed', type: 'number', description: 'Multi-state presence', extractionHints: ['states', 'licensed in'], required: false, defaultValue: 1},\n        {key: 'office_count', label: 'Office Locations', type: 'number', description: 'Number of offices', extractionHints: ['offices', 'locations'], required: false, defaultValue: 1},\n        {key: 'has_online_closing', label: 'Offers Online Closing', type: 'boolean', description: 'Remote closing available', extractionHints: ['online', 'remote', 'e-closing'], required: false, defaultValue: false},\n        {key: 'has_wire_protection', label: 'Wire Fraud Protection', type: 'boolean', description: 'Advanced security', extractionHints: ['wire fraud', 'security'], required: false, defaultValue: false},\n        {key: 'avg_turnaround_days', label: 'Average Turnaround (Days)', type: 'number', description: 'Typical closing time', extractionHints: ['days', 'turnaround', 'closing time'], required: false, defaultValue: 30},\n        {key: 'specialization', label: 'Market Focus', type: 'string', description: 'Primary market', extractionHints: ['residential', 'commercial', 'refinance'], required: false, defaultValue: 'residential'}\n      ],\n\n      metadata: {\n        lastUpdated: '2025-12-29',\n        version: 1,\n        updatedBy: 'system',\n        notes: 'Title & escrow intelligence - focuses on transaction volume, security features, service speed, and geographic reach'\n      }\n    }\n  },\n  \n  // ============================================\n};\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\scraper-intelligence\\scraper-queue.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":420,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":420,"endColumn":67}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Scraper Queue\n * \n * Priority-based job queue for managing concurrent scrape operations.\n * Implements efficient job scheduling with priority handling.\n * \n * Features:\n * - Priority-based job scheduling\n * - Job status tracking\n * - Queue statistics\n * - Job cancellation\n * - Automatic cleanup of completed jobs\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport type {\n  JobQueue,\n  ScrapeJobConfig,\n  ScrapeJobResult,\n  ScrapeJobStatus,\n  ScrapeJobPriority,\n  QueueStats,\n} from './scraper-runner-types';\nimport { generateJobId } from './scraper-runner-types';\n\n// ============================================================================\n// CONSTANTS\n// ============================================================================\n\nconst PRIORITY_ORDER: Record<ScrapeJobPriority, number> = {\n  urgent: 0,\n  high: 1,\n  normal: 2,\n  low: 3,\n};\n\nconst MAX_COMPLETED_HISTORY = 1000; // Keep last 1000 completed jobs\nconst CLEANUP_INTERVAL_MS = 5 * 60 * 1000; // Cleanup every 5 minutes\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\n/**\n * Internal job representation\n */\ninterface QueuedJob {\n  config: ScrapeJobConfig;\n  result: ScrapeJobResult;\n  enqueuedAt: Date;\n  priority: number; // Numeric priority for sorting\n}\n\n// ============================================================================\n// IMPLEMENTATION\n// ============================================================================\n\n/**\n * In-memory priority queue for scrape jobs\n */\nexport class InMemoryScrapeQueue implements JobQueue {\n  private jobs = new Map<string, QueuedJob>();\n  private pendingQueue: string[] = []; // Job IDs in priority order\n  private cleanupTimer?: NodeJS.Timeout;\n  \n  // Statistics tracking\n  private stats = {\n    totalEnqueued: 0,\n    totalCompleted: 0,\n    totalFailed: 0,\n    totalCancelled: 0,\n    totalWaitTimeMs: 0,\n    totalExecutionTimeMs: 0,\n  };\n\n  constructor(\n    private readonly maxWorkers: number = 5\n  ) {\n    this.startCleanup();\n  }\n\n  /**\n   * Add a job to the queue\n   */\n  async enqueue(config: ScrapeJobConfig): Promise<void> {\n    const jobId = config.jobId;\n    const enqueuedAt = new Date();\n    const priority = PRIORITY_ORDER[config.priority] || PRIORITY_ORDER.normal;\n\n    // Create initial result\n    const result: ScrapeJobResult = {\n      config,\n      status: 'pending',\n      startedAt: enqueuedAt,\n    };\n\n    const job: QueuedJob = {\n      config,\n      result,\n      enqueuedAt,\n      priority,\n    };\n\n    // Add to jobs map\n    this.jobs.set(jobId, job);\n\n    // Add to pending queue in priority order\n    this.insertIntoPriorityQueue(jobId, priority);\n\n    this.stats.totalEnqueued++;\n\n    logger.debug('Job enqueued', {\n      jobId,\n      url: config.url,\n      priority: config.priority,\n      queuePosition: this.pendingQueue.indexOf(jobId),\n      queueSize: this.pendingQueue.length,\n    });\n  }\n\n  /**\n   * Get next job to process\n   * \n   * Returns the highest priority pending job, or null if queue is empty\n   */\n  async dequeue(): Promise<ScrapeJobConfig | null> {\n    if (this.pendingQueue.length === 0) {\n      return null;\n    }\n\n    // Get highest priority job (first in queue)\n    const jobId = this.pendingQueue.shift();\n    if (!jobId) {\n      return null;\n    }\n\n    const job = this.jobs.get(jobId);\n    if (!job) {\n      logger.error('Job not found in map', { jobId });\n      return null;\n    }\n\n    // Update status to running\n    job.result.status = 'running';\n    job.result.startedAt = new Date();\n\n    logger.debug('Job dequeued', {\n      jobId,\n      url: job.config.url,\n      priority: job.config.priority,\n      waitTimeMs: job.result.startedAt.getTime() - job.enqueuedAt.getTime(),\n    });\n\n    return job.config;\n  }\n\n  /**\n   * Get job by ID\n   */\n  async getJob(jobId: string): Promise<ScrapeJobResult | null> {\n    const job = this.jobs.get(jobId);\n    return job ? job.result : null;\n  }\n\n  /**\n   * Update job result\n   */\n  async updateJob(jobId: string, updates: Partial<ScrapeJobResult>): Promise<void> {\n    const job = this.jobs.get(jobId);\n    \n    if (!job) {\n      logger.warn('Cannot update non-existent job', { jobId });\n      return;\n    }\n\n    // Merge updates\n    Object.assign(job.result, updates);\n\n    // Update statistics based on status\n    if (updates.status) {\n      this.updateStats(job, updates.status);\n    }\n\n    logger.debug('Job updated', {\n      jobId,\n      status: job.result.status,\n      updates: Object.keys(updates),\n    });\n  }\n\n  /**\n   * Mark job as completed\n   */\n  async completeJob(\n    jobId: string,\n    result: Omit<ScrapeJobResult, 'config' | 'status' | 'startedAt'>\n  ): Promise<void> {\n    const job = this.jobs.get(jobId);\n    \n    if (!job) {\n      logger.warn('Cannot complete non-existent job', { jobId });\n      return;\n    }\n\n    const completedAt = new Date();\n    const durationMs = completedAt.getTime() - job.result.startedAt.getTime();\n\n    await this.updateJob(jobId, {\n      ...result,\n      status: 'completed',\n      completedAt,\n      durationMs,\n    });\n\n    logger.info('Job completed', {\n      jobId,\n      url: job.config.url,\n      durationMs,\n      signalCount: result.signals?.length || 0,\n    });\n  }\n\n  /**\n   * Mark job as failed\n   */\n  async failJob(jobId: string, error: Error, attemptNumber: number): Promise<void> {\n    const job = this.jobs.get(jobId);\n    \n    if (!job) {\n      logger.warn('Cannot fail non-existent job', { jobId });\n      return;\n    }\n\n    const completedAt = new Date();\n    const durationMs = completedAt.getTime() - job.result.startedAt.getTime();\n\n    await this.updateJob(jobId, {\n      status: 'failed',\n      completedAt,\n      durationMs,\n      error: {\n        message: error.message,\n        code: (error as any).code || 'UNKNOWN_ERROR',\n        attemptNumber,\n        timestamp: new Date(),\n      },\n    });\n\n    logger.error('Job failed', error, {\n      jobId,\n      url: job.config.url,\n      attemptNumber,\n      durationMs,\n    });\n  }\n\n  /**\n   * Cancel a job\n   */\n  async cancelJob(jobId: string): Promise<boolean> {\n    const job = this.jobs.get(jobId);\n    \n    if (!job) {\n      return false;\n    }\n\n    // Can only cancel pending jobs\n    if (job.result.status !== 'pending') {\n      logger.warn('Cannot cancel non-pending job', {\n        jobId,\n        status: job.result.status,\n      });\n      return false;\n    }\n\n    // Remove from pending queue\n    const index = this.pendingQueue.indexOf(jobId);\n    if (index !== -1) {\n      this.pendingQueue.splice(index, 1);\n    }\n\n    // Update status\n    await this.updateJob(jobId, {\n      status: 'cancelled',\n      completedAt: new Date(),\n    });\n\n    logger.info('Job cancelled', { jobId, url: job.config.url });\n\n    return true;\n  }\n\n  /**\n   * Get queue statistics\n   */\n  getStats(): QueueStats {\n    const byStatus: Record<ScrapeJobStatus, number> = {\n      pending: 0,\n      running: 0,\n      completed: 0,\n      failed: 0,\n      cancelled: 0,\n      cached: 0,\n    };\n\n    const byPriority: Record<ScrapeJobPriority, number> = {\n      urgent: 0,\n      high: 0,\n      normal: 0,\n      low: 0,\n    };\n\n    let runningCount = 0;\n\n    for (const job of this.jobs.values()) {\n      byStatus[job.result.status]++;\n      byPriority[job.config.priority]++;\n      \n      if (job.result.status === 'running') {\n        runningCount++;\n      }\n    }\n\n    const avgWaitTimeMs = this.stats.totalEnqueued > 0\n      ? this.stats.totalWaitTimeMs / this.stats.totalEnqueued\n      : 0;\n\n    const avgExecutionTimeMs = this.stats.totalCompleted > 0\n      ? this.stats.totalExecutionTimeMs / this.stats.totalCompleted\n      : 0;\n\n    const utilization = this.maxWorkers > 0\n      ? runningCount / this.maxWorkers\n      : 0;\n\n    return {\n      total: this.jobs.size,\n      byStatus,\n      byPriority,\n      avgWaitTimeMs,\n      avgExecutionTimeMs,\n      utilization,\n      activeWorkers: runningCount,\n      maxWorkers: this.maxWorkers,\n    };\n  }\n\n  /**\n   * Get all pending jobs\n   */\n  getPendingJobs(): ScrapeJobConfig[] {\n    return this.pendingQueue\n      .map(jobId => this.jobs.get(jobId))\n      .filter((job): job is QueuedJob => job !== undefined)\n      .map(job => job.config);\n  }\n\n  /**\n   * Get all running jobs\n   */\n  getRunningJobs(): ScrapeJobConfig[] {\n    return Array.from(this.jobs.values())\n      .filter(job => job.result.status === 'running')\n      .map(job => job.config);\n  }\n\n  /**\n   * Clear all jobs\n   */\n  clear(): void {\n    this.jobs.clear();\n    this.pendingQueue = [];\n    logger.info('Queue cleared');\n  }\n\n  /**\n   * Shutdown and cleanup\n   */\n  shutdown(): void {\n    if (this.cleanupTimer) {\n      clearInterval(this.cleanupTimer);\n      this.cleanupTimer = undefined;\n    }\n    this.clear();\n  }\n\n  // ==========================================================================\n  // PRIVATE METHODS\n  // ==========================================================================\n\n  /**\n   * Insert job into priority queue maintaining sort order\n   */\n  private insertIntoPriorityQueue(jobId: string, priority: number): void {\n    // Find insertion point (binary search would be more efficient for large queues)\n    let insertIndex = this.pendingQueue.length;\n    \n    for (let i = 0; i < this.pendingQueue.length; i++) {\n      const existingJobId = this.pendingQueue[i];\n      const existingJob = this.jobs.get(existingJobId);\n      \n      if (existingJob && existingJob.priority > priority) {\n        insertIndex = i;\n        break;\n      }\n    }\n\n    this.pendingQueue.splice(insertIndex, 0, jobId);\n  }\n\n  /**\n   * Update statistics based on job status change\n   */\n  private updateStats(job: QueuedJob, newStatus: ScrapeJobStatus): void {\n    const now = new Date();\n\n    switch (newStatus) {\n      case 'running':\n        // Calculate wait time\n        const waitTime = now.getTime() - job.enqueuedAt.getTime();\n        this.stats.totalWaitTimeMs += waitTime;\n        break;\n\n      case 'completed':\n        this.stats.totalCompleted++;\n        if (job.result.durationMs) {\n          this.stats.totalExecutionTimeMs += job.result.durationMs;\n        }\n        break;\n\n      case 'failed':\n        this.stats.totalFailed++;\n        if (job.result.durationMs) {\n          this.stats.totalExecutionTimeMs += job.result.durationMs;\n        }\n        break;\n\n      case 'cancelled':\n        this.stats.totalCancelled++;\n        break;\n    }\n  }\n\n  /**\n   * Start periodic cleanup of old completed jobs\n   */\n  private startCleanup(): void {\n    this.cleanupTimer = setInterval(() => {\n      this.cleanupOldJobs();\n    }, CLEANUP_INTERVAL_MS);\n\n    // Don't keep the process alive just for cleanup\n    if (this.cleanupTimer.unref) {\n      this.cleanupTimer.unref();\n    }\n  }\n\n  /**\n   * Remove old completed/failed/cancelled jobs\n   */\n  private cleanupOldJobs(): void {\n    const completedJobs: Array<{ jobId: string; completedAt: Date }> = [];\n\n    for (const [jobId, job] of this.jobs.entries()) {\n      if (\n        job.result.status === 'completed' ||\n        job.result.status === 'failed' ||\n        job.result.status === 'cancelled'\n      ) {\n        if (job.result.completedAt) {\n          completedJobs.push({ jobId, completedAt: job.result.completedAt });\n        }\n      }\n    }\n\n    // Sort by completion time (oldest first)\n    completedJobs.sort((a, b) => a.completedAt.getTime() - b.completedAt.getTime());\n\n    // Remove oldest jobs if over limit\n    const toRemove = Math.max(0, completedJobs.length - MAX_COMPLETED_HISTORY);\n    let removedCount = 0;\n\n    for (let i = 0; i < toRemove; i++) {\n      const jobId = completedJobs[i].jobId;\n      this.jobs.delete(jobId);\n      removedCount++;\n    }\n\n    if (removedCount > 0) {\n      logger.debug('Queue cleanup completed', {\n        removedJobs: removedCount,\n        remainingJobs: this.jobs.size,\n      });\n    }\n  }\n}\n\n// ============================================================================\n// FACTORY\n// ============================================================================\n\n/**\n * Create a new scrape queue\n */\nexport function createScrapeQueue(maxWorkers?: number): JobQueue {\n  return new InMemoryScrapeQueue(maxWorkers);\n}\n\n// ============================================================================\n// UTILITIES\n// ============================================================================\n\n/**\n * Calculate job priority based on various factors\n */\nexport function calculateJobPriority(config: ScrapeJobConfig): ScrapeJobPriority {\n  // If explicitly set, use that\n  if (config.priority) {\n    return config.priority;\n  }\n\n  // Otherwise, calculate based on factors\n  let score = 0;\n\n  // Factor 1: Platform urgency\n  const platformScores: Partial<Record<string, number>> = {\n    'news': 3,           // Time-sensitive\n    'social-media': 2,   // Moderately time-sensitive\n    'website': 1,        // Standard\n    'dns': -1,           // Can be delayed\n  };\n  score += platformScores[config.platform] || 0;\n\n  // Factor 2: Organization priority (could be added later)\n  // score += organizationPriorityScore;\n\n  // Map score to priority\n  if (score >= 3) {return 'urgent';}\n  if (score >= 1) {return 'high';}\n  if (score <= -1) {return 'low';}\n  return 'normal';\n}\n\n/**\n * Validate job configuration\n */\nexport function validateJobConfig(config: ScrapeJobConfig): {\n  valid: boolean;\n  errors: string[];\n} {\n  const errors: string[] = [];\n\n  if (!config.jobId) {\n    errors.push('Job ID is required');\n  }\n\n  if (!config.organizationId) {\n    errors.push('Organization ID is required');\n  }\n\n  if (!config.industryId) {\n    errors.push('Industry ID is required');\n  }\n\n  if (!config.url) {\n    errors.push('URL is required');\n  }\n\n  if (!config.platform) {\n    errors.push('Platform is required');\n  }\n\n  // Validate URL format\n  if (config.url) {\n    try {\n      new URL(config.url);\n    } catch {\n      errors.push('Invalid URL format');\n    }\n  }\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\scraper-intelligence\\scraper-runner.ts","messages":[{"ruleId":"no-constant-condition","severity":2,"message":"Unexpected constant condition.","line":209,"column":12,"nodeType":"Literal","messageId":"unexpected","endLine":209,"endColumn":16}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Scraper Runner\r\n * \r\n * Main orchestration engine for intelligent web scraping across all 49 industry templates.\r\n * Coordinates caching, rate limiting, queue management, and progress tracking.\r\n * \r\n * Features:\r\n * - Multi-template scraping orchestration\r\n * - Intelligent caching (5-minute default TTL)\r\n * - Domain-based rate limiting\r\n * - Priority-based job queue\r\n * - Real-time progress tracking\r\n * - Automatic retry with exponential backoff\r\n * - Concurrent scrape management\r\n */\r\n\r\nimport { logger } from '@/lib/logger/logger';\r\nimport { processAndStoreScrape } from './scraper-intelligence-service';\r\nimport { getIndustryTemplate } from '@/lib/persona/industry-templates';\r\nimport type {\r\n  ScraperRunner,\r\n  ScraperRunnerConfig,\r\n  ScrapeJobConfig,\r\n  ScrapeJobResult,\r\n  ScrapeCache,\r\n  DomainRateLimiter,\r\n  JobQueue,\r\n  ProgressTracker,\r\n  ErrorHandler,\r\n  QueueStats,\r\n  CacheStats,\r\n} from './scraper-runner-types';\r\nimport {\r\n  DEFAULT_RUNNER_CONFIG,\r\n  extractDomain,\r\n  generateJobId,\r\n  ScrapeError,\r\n} from './scraper-runner-types';\r\nimport { createScrapeCache, getScrapeCacheKey, calculateCacheTTL } from './scraper-cache';\r\nimport { createDomainRateLimiter } from './domain-rate-limiter';\r\nimport { createScrapeQueue, validateJobConfig } from './scraper-queue';\r\nimport { createProgressTracker, createProgressEvent, formatProgressMessage } from './progress-tracker';\r\nimport { createErrorHandler, withRetry, withTimeout, logError } from './error-handler';\r\n\r\n// ============================================================================\r\n// IMPLEMENTATION\r\n// ============================================================================\r\n\r\n/**\r\n * Production-ready scraper runner implementation\r\n */\r\nexport class ProductionScraperRunner implements ScraperRunner {\r\n  private cache: ScrapeCache;\r\n  private rateLimiter: DomainRateLimiter;\r\n  private queue: JobQueue;\r\n  private progressTracker: ProgressTracker;\r\n  private errorHandler: ErrorHandler;\r\n  private config: ScraperRunnerConfig;\r\n  private running = false;\r\n  private activeWorkers = 0;\r\n  private shutdownSignal = false;\r\n\r\n  // Statistics\r\n  private stats = {\r\n    completedJobs: 0,\r\n    failedJobs: 0,\r\n    cachedJobs: 0,\r\n  };\r\n\r\n  constructor(config: Partial<ScraperRunnerConfig> = {}) {\r\n    this.config = { ...DEFAULT_RUNNER_CONFIG, ...config };\r\n\r\n    // Initialize components\r\n    this.cache = createScrapeCache(1000, this.config.cacheTtlMs);\r\n    this.rateLimiter = createDomainRateLimiter(this.config.rateLimitConfig);\r\n    this.queue = createScrapeQueue(this.config.maxConcurrent);\r\n    this.progressTracker = createProgressTracker();\r\n    this.errorHandler = createErrorHandler(this.config.retryStrategy);\r\n\r\n    logger.info('Scraper Runner initialized', {\r\n      maxConcurrent: this.config.maxConcurrent,\r\n      cacheTtlMs: this.config.cacheTtlMs,\r\n      enableCaching: this.config.enableCaching,\r\n      enableProgressTracking: this.config.enableProgressTracking,\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Submit a scrape job\r\n   */\r\n  async submitJob(config: ScrapeJobConfig): Promise<string> {\r\n    // Validate configuration\r\n    const validation = validateJobConfig(config);\r\n    if (!validation.valid) {\r\n      throw new ScrapeError(\r\n        `Invalid job configuration: ${validation.errors.join(', ')}`,\r\n        'validation_error',\r\n        400,\r\n        false,\r\n        { errors: validation.errors }\r\n      );\r\n    }\r\n\r\n    // Generate job ID if not provided\r\n    if (!config.jobId) {\r\n      config.jobId = generateJobId();\r\n    }\r\n\r\n    // Set defaults\r\n    const jobConfig: ScrapeJobConfig = {\r\n      ...config,\r\n      priority: config.priority || 'normal',\r\n      maxRetries: config.maxRetries ?? this.config.retryStrategy.maxAttempts,\r\n      timeoutMs: config.timeoutMs ?? this.config.defaultTimeoutMs,\r\n      skipCache: config.skipCache ?? false,\r\n    };\r\n\r\n    // Add to queue\r\n    await this.queue.enqueue(jobConfig);\r\n\r\n    // Emit progress event\r\n    if (this.config.enableProgressTracking) {\r\n      this.progressTracker.emit(createProgressEvent(\r\n        jobConfig.jobId,\r\n        'job_queued',\r\n        formatProgressMessage('job_queued', jobConfig.url),\r\n        0\r\n      ));\r\n    }\r\n\r\n    // Start processing if not already running\r\n    if (!this.running) {\r\n      this.startProcessing();\r\n    }\r\n\r\n    logger.info('Job submitted', {\r\n      jobId: jobConfig.jobId,\r\n      url: jobConfig.url,\r\n      priority: jobConfig.priority,\r\n      organizationId: jobConfig.organizationId,\r\n    });\r\n\r\n    return jobConfig.jobId;\r\n  }\r\n\r\n  /**\r\n   * Submit multiple jobs in batch\r\n   */\r\n  async submitBatch(configs: ScrapeJobConfig[]): Promise<string[]> {\r\n    const jobIds: string[] = [];\r\n\r\n    for (const config of configs) {\r\n      try {\r\n        const jobId = await this.submitJob(config);\r\n        jobIds.push(jobId);\r\n      } catch (error) {\r\n        logger.error('Failed to submit batch job', error as Error, {\r\n          url: config.url,\r\n        });\r\n        // Continue with other jobs\r\n      }\r\n    }\r\n\r\n    logger.info('Batch submitted', {\r\n      totalJobs: configs.length,\r\n      submittedJobs: jobIds.length,\r\n      failedJobs: configs.length - jobIds.length,\r\n    });\r\n\r\n    return jobIds;\r\n  }\r\n\r\n  /**\r\n   * Get job result\r\n   */\r\n  async getJobResult(jobId: string): Promise<ScrapeJobResult | null> {\r\n    return this.queue.getJob(jobId);\r\n  }\r\n\r\n  /**\r\n   * Cancel a job\r\n   */\r\n  async cancelJob(jobId: string): Promise<boolean> {\r\n    const cancelled = await this.queue.cancelJob(jobId);\r\n\r\n    if (cancelled && this.config.enableProgressTracking) {\r\n      const result = await this.queue.getJob(jobId);\r\n      if (result) {\r\n        this.progressTracker.emit(createProgressEvent(\r\n          jobId,\r\n          'job_cancelled',\r\n          formatProgressMessage('job_cancelled', result.config.url)\r\n        ));\r\n      }\r\n    }\r\n\r\n    return cancelled;\r\n  }\r\n\r\n  /**\r\n   * Wait for job completion\r\n   */\r\n  async waitForJob(\r\n    jobId: string,\r\n    timeoutMs: number = 60000\r\n  ): Promise<ScrapeJobResult> {\r\n    const startTime = Date.now();\r\n\r\n    while (true) {\r\n      const result = await this.queue.getJob(jobId);\r\n\r\n      if (!result) {\r\n        throw new ScrapeError(\r\n          `Job not found: ${jobId}`,\r\n          'validation_error',\r\n          404,\r\n          false\r\n        );\r\n      }\r\n\r\n      // Check if completed\r\n      if (\r\n        result.status === 'completed' ||\r\n        result.status === 'failed' ||\r\n        result.status === 'cancelled' ||\r\n        result.status === 'cached'\r\n      ) {\r\n        return result;\r\n      }\r\n\r\n      // Check timeout\r\n      if (Date.now() - startTime > timeoutMs) {\r\n        throw new ScrapeError(\r\n          `Timeout waiting for job ${jobId}`,\r\n          'timeout_error',\r\n          408,\r\n          false\r\n        );\r\n      }\r\n\r\n      // Wait before checking again\r\n      await new Promise(resolve => setTimeout(resolve, 100));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get runner statistics\r\n   */\r\n  getStats(): {\r\n    queue: QueueStats;\r\n    cache: CacheStats;\r\n    activeJobs: number;\r\n    completedJobs: number;\r\n    failedJobs: number;\r\n  } {\r\n    return {\r\n      queue: this.queue.getStats(),\r\n      cache: this.cache.getStats(),\r\n      activeJobs: this.activeWorkers,\r\n      completedJobs: this.stats.completedJobs,\r\n      failedJobs: this.stats.failedJobs,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Shutdown runner gracefully\r\n   */\r\n  async shutdown(): Promise<void> {\r\n    logger.info('Shutting down scraper runner...');\r\n    this.shutdownSignal = true;\r\n\r\n    // Wait for active workers to complete (max 30 seconds)\r\n    const shutdownTimeout = 30000;\r\n    const startTime = Date.now();\r\n\r\n    while (this.activeWorkers > 0 && Date.now() - startTime < shutdownTimeout) {\r\n      await new Promise(resolve => setTimeout(resolve, 100));\r\n    }\r\n\r\n    // Shutdown components\r\n    this.cache.clear();\r\n    this.progressTracker.shutdown();\r\n    this.rateLimiter.shutdown();\r\n    this.queue.shutdown();\r\n\r\n    logger.info('Scraper runner shut down', {\r\n      activeWorkersRemaining: this.activeWorkers,\r\n    });\r\n  }\r\n\r\n  // ==========================================================================\r\n  // PRIVATE METHODS - PROCESSING\r\n  // ==========================================================================\r\n\r\n  /**\r\n   * Start job processing loop\r\n   */\r\n  private async startProcessing(): Promise<void> {\r\n    if (this.running) {\r\n      return;\r\n    }\r\n\r\n    this.running = true;\r\n    logger.info('Starting job processing');\r\n\r\n    // Start worker loops\r\n    const workers: Promise<void>[] = [];\r\n    for (let i = 0; i < this.config.maxConcurrent; i++) {\r\n      workers.push(this.workerLoop(i));\r\n    }\r\n\r\n    // Wait for all workers (they run until shutdown)\r\n    await Promise.all(workers);\r\n\r\n    this.running = false;\r\n    logger.info('Job processing stopped');\r\n  }\r\n\r\n  /**\r\n   * Worker loop for processing jobs\r\n   */\r\n  private async workerLoop(workerId: number): Promise<void> {\r\n    logger.debug('Worker started', { workerId });\r\n\r\n    while (!this.shutdownSignal) {\r\n      try {\r\n        // Get next job\r\n        const jobConfig = await this.queue.dequeue();\r\n\r\n        if (!jobConfig) {\r\n          // No jobs available, wait before checking again\r\n          await new Promise(resolve => setTimeout(resolve, 1000));\r\n          continue;\r\n        }\r\n\r\n        // Process job\r\n        this.activeWorkers++;\r\n        await this.processJob(jobConfig);\r\n        this.activeWorkers--;\r\n\r\n      } catch (error) {\r\n        logger.error('Worker loop error', error as Error, { workerId });\r\n        this.activeWorkers = Math.max(0, this.activeWorkers - 1);\r\n      }\r\n    }\r\n\r\n    logger.debug('Worker stopped', { workerId });\r\n  }\r\n\r\n  /**\r\n   * Process a single job\r\n   */\r\n  private async processJob(config: ScrapeJobConfig): Promise<void> {\r\n    const { jobId, url, organizationId, industryId, platform } = config;\r\n\r\n    logger.info('Processing job', { jobId, url, organizationId, industryId });\r\n\r\n    // Emit started event\r\n    if (this.config.enableProgressTracking) {\r\n      this.progressTracker.emit(createProgressEvent(\r\n        jobId,\r\n        'job_started',\r\n        formatProgressMessage('job_started', url),\r\n        10\r\n      ));\r\n    }\r\n\r\n    try {\r\n      // Step 1: Check cache (if enabled)\r\n      if (this.config.enableCaching && !config.skipCache) {\r\n        const cached = await this.checkCache(config);\r\n        if (cached) {\r\n          await this.queue.completeJob(jobId, {\r\n            signals: cached.signals,\r\n            leadScore: cached.leadScore,\r\n            tempScrapeId: cached.tempScrapeId,\r\n            cached: true,\r\n            cacheAgeMs: cached.cacheAgeMs,\r\n            storageReduction: cached.storageReduction,\r\n          });\r\n\r\n          this.stats.cachedJobs++;\r\n          this.stats.completedJobs++;\r\n\r\n          if (this.config.enableProgressTracking) {\r\n            this.progressTracker.emit(createProgressEvent(\r\n              jobId,\r\n              'job_cached',\r\n              formatProgressMessage('job_cached', url),\r\n              100\r\n            ));\r\n          }\r\n\r\n          return;\r\n        }\r\n      }\r\n\r\n      // Step 2: Wait for rate limit slot\r\n      const domain = extractDomain(url);\r\n      await this.rateLimiter.waitForSlot(domain);\r\n\r\n      // Step 3: Execute scrape with retry logic\r\n      const result = await withRetry(\r\n        () => withTimeout(\r\n          () => this.executeScrape(config),\r\n          config.timeoutMs!,\r\n          `Scrape timeout for ${url}`\r\n        ),\r\n        this.errorHandler,\r\n        config.maxRetries\r\n      );\r\n\r\n      // Step 4: Cache result (if enabled)\r\n      if (this.config.enableCaching) {\r\n        const ttl = calculateCacheTTL(platform);\r\n        const cacheKey = getScrapeCacheKey(url, platform, organizationId);\r\n        \r\n        const resultToCache: ScrapeJobResult = {\r\n          config,\r\n          status: 'completed',\r\n          startedAt: new Date(),\r\n          completedAt: new Date(),\r\n          ...result,\r\n        };\r\n\r\n        await this.cache.set(cacheKey, resultToCache, ttl);\r\n      }\r\n\r\n      // Step 5: Mark job as completed\r\n      await this.queue.completeJob(jobId, result);\r\n      this.stats.completedJobs++;\r\n\r\n      if (this.config.enableProgressTracking) {\r\n        this.progressTracker.emit(createProgressEvent(\r\n          jobId,\r\n          'job_completed',\r\n          formatProgressMessage('job_completed', url),\r\n          100,\r\n          { signalCount: result.signals?.length || 0 }\r\n        ));\r\n      }\r\n\r\n      logger.info('Job completed successfully', {\r\n        jobId,\r\n        url,\r\n        signalCount: result.signals?.length || 0,\r\n        leadScore: result.leadScore,\r\n      });\r\n\r\n    } catch (error) {\r\n      await this.handleJobError(config, error as Error);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check cache for existing result\r\n   */\r\n  private async checkCache(config: ScrapeJobConfig): Promise<{\r\n    signals: any[];\r\n    leadScore: number;\r\n    tempScrapeId: string;\r\n    cacheAgeMs: number;\r\n    storageReduction?: any;\r\n  } | null> {\r\n    const { url, platform, organizationId } = config;\r\n    const cacheKey = getScrapeCacheKey(url, platform, organizationId);\r\n\r\n    const cached = await this.cache.get(cacheKey);\r\n\r\n    if (cached) {\r\n      const ageMs = Date.now() - cached.cachedAt.getTime();\r\n      \r\n      logger.info('Cache hit', {\r\n        url,\r\n        ageMs,\r\n        hits: cached.hits,\r\n      });\r\n\r\n      return {\r\n        signals: cached.result.signals || [],\r\n        leadScore: cached.result.leadScore || 0,\r\n        tempScrapeId: cached.result.tempScrapeId || '',\r\n        cacheAgeMs: ageMs,\r\n        storageReduction: cached.result.storageReduction,\r\n      };\r\n    }\r\n\r\n    logger.debug('Cache miss', { url });\r\n    return null;\r\n  }\r\n\r\n  /**\r\n   * Execute the actual scrape operation\r\n   */\r\n  private async executeScrape(config: ScrapeJobConfig): Promise<{\r\n    signals: any[];\r\n    leadScore: number;\r\n    tempScrapeId: string;\r\n    storageReduction?: any;\r\n  }> {\r\n    const { url, organizationId, workspaceId, industryId, relatedRecordId, platform } = config;\r\n\r\n    // Get industry template\r\n    const template = await getIndustryTemplate(industryId);\r\n    if (!template) {\r\n      throw new ScrapeError(\r\n        `Industry template not found: ${industryId}`,\r\n        'validation_error',\r\n        404,\r\n        false,\r\n        { industryId }\r\n      );\r\n    }\r\n\r\n    // TODO: Replace with actual web scraping implementation\r\n    // For now, this is a placeholder that calls the existing service\r\n    // In production, you would:\r\n    // 1. Fetch the webpage (using puppeteer, playwright, or axios)\r\n    // 2. Extract content (convert HTML to markdown or text)\r\n    // 3. Call processAndStoreScrape with the raw content\r\n\r\n    // Placeholder scraping logic\r\n    const rawHtml = `<!DOCTYPE html><html><body>Sample content for ${url}</body></html>`;\r\n    const cleanedContent = `Sample content for ${url}`;\r\n    const metadata = {\r\n      title: 'Sample Page',\r\n      description: 'Sample description',\r\n      author: undefined,\r\n      keywords: [],\r\n    };\r\n\r\n    // Process and store the scrape\r\n    const result = await processAndStoreScrape({\r\n      organizationId,\r\n      workspaceId,\r\n      industryId,\r\n      recordId: relatedRecordId || `temp_${Date.now()}`,\r\n      url,\r\n      rawHtml,\r\n      cleanedContent,\r\n      metadata,\r\n      platform,\r\n    });\r\n\r\n    return {\r\n      signals: result.signals,\r\n      leadScore: result.leadScore,\r\n      tempScrapeId: result.tempScrapeId,\r\n      storageReduction: result.storageReduction,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Handle job error\r\n   */\r\n  private async handleJobError(config: ScrapeJobConfig, error: Error): Promise<void> {\r\n    const { jobId, url } = config;\r\n\r\n    logError(error, { jobId, url });\r\n\r\n    // Determine attempt number (from retry context if available)\r\n    const attemptNumber = (error as any).attemptNumber || 1;\r\n\r\n    // Mark job as failed\r\n    await this.queue.failJob(jobId, error, attemptNumber);\r\n    this.stats.failedJobs++;\r\n\r\n    // Emit failure event\r\n    if (this.config.enableProgressTracking) {\r\n      const formatted = this.errorHandler.formatError(error);\r\n      this.progressTracker.emit(createProgressEvent(\r\n        jobId,\r\n        'job_failed',\r\n        formatProgressMessage('job_failed', url, formatted.message),\r\n        0,\r\n        { error: formatted }\r\n      ));\r\n    }\r\n\r\n    logger.error('Job failed', error, {\r\n      jobId,\r\n      url,\r\n      attemptNumber,\r\n    });\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// FACTORY\r\n// ============================================================================\r\n\r\n/**\r\n * Create a new scraper runner instance\r\n */\r\nexport function createScraperRunner(\r\n  config?: Partial<ScraperRunnerConfig>\r\n): ScraperRunner {\r\n  return new ProductionScraperRunner(config);\r\n}\r\n\r\n// ============================================================================\r\n// SINGLETON (Optional)\r\n// ============================================================================\r\n\r\nlet globalRunner: ScraperRunner | null = null;\r\n\r\n/**\r\n * Get global scraper runner instance (singleton)\r\n */\r\nexport function getScraperRunner(\r\n  config?: Partial<ScraperRunnerConfig>\r\n): ScraperRunner {\r\n  if (!globalRunner) {\r\n    globalRunner = createScraperRunner(config);\r\n  }\r\n  return globalRunner;\r\n}\r\n\r\n/**\r\n * Reset global scraper runner (for testing)\r\n */\r\nexport function resetScraperRunner(): void {\r\n  if (globalRunner) {\r\n    globalRunner.shutdown();\r\n    globalRunner = null;\r\n  }\r\n}\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\services\\discovery-engine.ts","messages":[{"ruleId":"no-dupe-else-if","severity":2,"message":"This branch can never execute. Its condition is a duplicate or covered by previous conditions in the if-else-if chain.","line":791,"column":12,"nodeType":"BinaryExpression","messageId":"unexpected","endLine":791,"endColumn":42}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Native Discovery Engine\n * \n * This service is 100% native and relies on zero third-party data APIs.\n * \n * HUNTER-CLOSER COMPLIANCE:\n * - Replaces Clearbit, ZoomInfo, Apollo with our own scraping\n * - Checks discoveryArchive first (30-day cache)\n * - Uses BrowserController for intelligent web scraping\n * - LLM synthesis of raw data into structured Lead Objects\n * - Builds proprietary competitive moat\n * \n * Data Extraction Targets:\n * - Team members (About, Team pages)\n * - Tech stack (footer scripts, meta tags, job postings)\n * - Press mentions (News, Press pages)\n * - Contact information\n * - Company size indicators\n * - Recent activity signals\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport { BrowserController, createBrowserController } from './BrowserController';\nimport { \n  saveToDiscoveryArchive, \n  getFromDiscoveryArchiveByHash,\n  calculateContentHash \n} from '@/lib/scraper-intelligence/discovery-archive-service';\nimport { sendUnifiedChatMessage } from '@/lib/ai/unified-ai-service';\nimport type { TemporaryScrape } from '@/types/scraper-intelligence';\nimport type { WorkflowState } from '@/types/workflow-state';\nimport { createWorkflowState } from '@/types/workflow-state';\nimport { getServerSignalCoordinator } from '@/lib/orchestration/coordinator-factory-server';\nimport { Timestamp } from 'firebase/firestore';\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\nexport interface DiscoveredCompany {\n  domain: string;\n  companyName?: string;\n  description?: string;\n  industry?: string;\n  size?: string;\n  location?: string;\n  \n  // Team data\n  teamMembers: Array<{\n    name: string;\n    title?: string;\n    imageUrl?: string;\n    linkedinUrl?: string;\n    email?: string;\n  }>;\n  \n  // Tech stack\n  techStack: Array<{\n    name: string;\n    category: 'frontend' | 'backend' | 'analytics' | 'marketing' | 'infrastructure' | 'other';\n    confidence: number;\n  }>;\n  \n  // Press & news\n  pressmentions: Array<{\n    title: string;\n    url?: string;\n    date?: string;\n    summary?: string;\n  }>;\n  \n  // Contact info\n  contactInfo: {\n    email?: string;\n    phone?: string;\n    address?: string;\n    socialMedia?: {\n      linkedin?: string;\n      twitter?: string;\n      facebook?: string;\n    };\n  };\n  \n  // Signals\n  signals: {\n    isHiring: boolean;\n    jobCount: number;\n    recentActivity: boolean;\n    fundingStage?: string;\n    growthIndicators: string[];\n  };\n  \n  // Metadata\n  metadata: {\n    scrapedAt: Date;\n    expiresAt: Date;\n    source: 'discovery-engine';\n    confidence: number;\n  };\n  \n  // Workflow state tracking\n  workflow: WorkflowState;\n}\n\nexport interface DiscoveryResult {\n  company: DiscoveredCompany;\n  rawData: RawScrapedData;\n  fromCache: boolean;\n  scrapeId: string;\n}\n\nexport interface DiscoveredPerson {\n  email: string;\n  firstName?: string;\n  lastName?: string;\n  fullName?: string;\n  title?: string;\n  company?: string;\n  location?: string;\n  \n  // Social profiles\n  socialProfiles: {\n    linkedin?: string;\n    twitter?: string;\n    github?: string;\n    website?: string;\n  };\n  \n  // Professional data\n  currentRole?: {\n    title: string;\n    company: string;\n    startDate?: string;\n  };\n  \n  previousRoles?: Array<{\n    title: string;\n    company: string;\n    startDate?: string;\n    endDate?: string;\n  }>;\n  \n  // Skills and interests\n  skills?: string[];\n  interests?: string[];\n  \n  // Metadata\n  metadata: {\n    discoveredAt: Date;\n    expiresAt: Date;\n    source: 'person-discovery';\n    confidence: number;\n    methods: string[]; // How we found this data (e.g., 'linkedin', 'company-website', 'github')\n  };\n  \n  // Workflow state tracking\n  workflow: WorkflowState;\n}\n\nexport interface PersonDiscoveryResult {\n  person: DiscoveredPerson;\n  fromCache: boolean;\n  scrapeId: string;\n}\n\nexport interface RawScrapedData {\n  url: string;\n  html: string;\n  text: string;\n  highValueAreas: Array<{\n    type: string;\n    content: string;\n    selector: string;\n  }>;\n  links: Array<{\n    href: string;\n    text: string;\n    type?: string;\n  }>;\n  teamMembers: Array<any>;\n  techStack: Array<any>;\n  careerData: any;\n}\n\n// ============================================================================\n// MAIN DISCOVERY FUNCTION\n// ============================================================================\n\n/**\n * Discover company data from domain\n * \n * This is the main entry point for company discovery.\n * Checks 30-day cache first, then scrapes if needed.\n * \n * @param domain - Company domain (e.g., 'example.com')\n * @param organizationId - Organization requesting the discovery\n * @returns Complete discovery result with company data\n * \n * @example\n * ```typescript\n * const result = await discoverCompany('stripe.com', 'org_123');\n * console.log(`Found ${result.company.teamMembers.length} team members`);\n * console.log(`From cache: ${result.fromCache}`);\n * ```\n */\nexport async function discoverCompany(\n  domain: string,\n  organizationId: string\n): Promise<DiscoveryResult> {\n  try {\n    logger.info('Starting company discovery', {\n      domain,\n      organizationId,\n      source: 'native-discovery-engine',\n    });\n\n    // Step 1: Check discoveryArchive (30-day cache)\n    const cached = await checkDiscoveryArchive(domain, organizationId);\n    if (cached) {\n      logger.info('Discovery archive HIT - serving from cache', {\n        domain,\n        organizationId,\n        cacheAge: Date.now() - cached.scrape.createdAt.getTime(),\n        message: 'Cost savings achieved - no scraping needed',\n      });\n\n      const company = JSON.parse(cached.scrape.cleanedContent) as DiscoveredCompany;\n      \n      // Emit Signal Bus signals even for cached data (lower priority)\n      await emitDiscoverySignals(company, organizationId, true);\n\n      return {\n        company,\n        rawData: JSON.parse(cached.scrape.rawHtml) as RawScrapedData,\n        fromCache: true,\n        scrapeId: cached.scrape.id,\n      };\n    }\n\n    // Step 2: Cache MISS - perform native scraping\n    logger.info('Discovery archive MISS - initiating scrape', {\n      domain,\n      organizationId,\n      message: 'Building proprietary moat',\n    });\n\n    const rawData = await scrapeCompanyData(domain);\n\n    // Step 3: Synthesize structured data with LLM\n    const company = await synthesizeLeadObject(domain, rawData);\n\n    // Step 4: Save to discoveryArchive (30-day TTL)\n    const scrapeResult = await saveToArchive(domain, organizationId, company, rawData);\n\n    logger.info('Company discovery complete', {\n      domain,\n      organizationId,\n      teamMembersFound: company.teamMembers.length,\n      techStackFound: company.techStack.length,\n      fromCache: false,\n    });\n\n    // Emit Signal Bus signals for newly discovered data\n    await emitDiscoverySignals(company, organizationId, false);\n\n    return {\n      company,\n      rawData,\n      fromCache: false,\n      scrapeId: scrapeResult.scrape.id,\n    };\n  } catch (error) {\n    logger.error('Failed to discover company', error, {\n      domain,\n      organizationId,\n    });\n    \n    const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n    throw new Error(`Failed to discover company ${domain}: ${errorMessage}`);\n  }\n}\n\n// ============================================================================\n// CACHE CHECKING\n// ============================================================================\n\n/**\n * Check if company data exists in discoveryArchive (30-day cache)\n */\nasync function checkDiscoveryArchive(\n  domain: string,\n  organizationId: string\n): Promise<{ scrape: TemporaryScrape } | null> {\n  try {\n    // We'll use URL as the cache key\n    const url = domain.startsWith('http') ? domain : `https://${domain}`;\n    const contentHash = calculateContentHash(url);\n\n    const cached = await getFromDiscoveryArchiveByHash(organizationId, contentHash);\n    \n    if (!cached) {\n      return null;\n    }\n\n    // Check if still valid (not expired)\n    if (cached.expiresAt < new Date()) {\n      logger.info('Discovery archive entry expired', {\n        domain,\n        expiresAt: cached.expiresAt,\n      });\n      return null;\n    }\n\n    return { scrape: cached };\n  } catch (error) {\n    logger.warn('Failed to check discovery archive', {\n      domain,\n      error: error instanceof Error ? error.message : 'Unknown error',\n    });\n    return null;\n  }\n}\n\n// ============================================================================\n// WEB SCRAPING\n// ============================================================================\n\n/**\n * Scrape company data using BrowserController\n * \n * Orchestrates Playwright browser to visit domain and extract data.\n * Uses stealth mode to avoid detection.\n */\nasync function scrapeCompanyData(domain: string): Promise<RawScrapedData> {\n  const controller = createBrowserController({ headless: true });\n  \n  try {\n    const url = domain.startsWith('http') ? domain : `https://${domain}`;\n    \n    logger.info('Starting web scrape', { domain, url });\n\n    // Navigate to domain\n    await controller.navigate(url);\n\n    // Extract high-value areas\n    const highValueAreas = await controller.identifyHighValueAreas();\n    \n    // Extract detailed data from each area\n    const areaContents = await Promise.all(\n      highValueAreas.slice(0, 10).map(async (area) => {\n        try {\n          const extracted = await controller.extractFromArea(area);\n          return {\n            type: area.type,\n            content: typeof extracted.content === 'string' \n              ? extracted.content \n              : JSON.stringify(extracted.content),\n            selector: area.selector,\n          };\n        } catch (error) {\n          logger.warn('Failed to extract from area', {\n            type: area.type,\n            error: error instanceof Error ? error.message : 'Unknown',\n          });\n          return null;\n        }\n      })\n    );\n\n    // Get links\n    const links = await controller.findFooterLinks();\n\n    // Get team members\n    const teamMembers = await controller.findTeamDirectory();\n\n    // Get tech stack\n    const techStack = await controller.extractTechStack();\n\n    // Get career data\n    const careerData = await controller.findCareerPortal();\n\n    // Get full HTML and text\n    const html = await controller.getContent();\n    const text = await controller.getTextContent();\n\n    logger.info('Web scrape complete', {\n      domain,\n      highValueAreas: areaContents.filter(a => a !== null).length,\n      linksFound: links.length,\n      teamMembersFound: teamMembers.length,\n      techStackFound: techStack.length,\n    });\n\n    return {\n      url,\n      html: html.substring(0, 100000), // Limit size\n      text: text.substring(0, 50000),\n      highValueAreas: areaContents.filter((a): a is NonNullable<typeof a> => a !== null),\n      links,\n      teamMembers,\n      techStack,\n      careerData,\n    };\n  } catch (error) {\n    logger.error('Failed to scrape company data', error, { domain });\n    throw error;\n  } finally {\n    await controller.close();\n  }\n}\n\n// ============================================================================\n// INDUSTRY DETECTION\n// ============================================================================\n\n/**\n * Industry-specific patterns for better data extraction\n */\nconst INDUSTRY_PATTERNS = {\n  saas: {\n    keywords: ['software', 'platform', 'api', 'cloud', 'app', 'tool', 'dashboard', 'subscription', 'saas'],\n    techIndicators: ['react', 'vue', 'angular', 'stripe', 'aws', 'gcp', 'azure'],\n    extractionFocus: ['pricing', 'features', 'integrations', 'api-docs', 'changelog'],\n  },\n  ecommerce: {\n    keywords: ['shop', 'store', 'cart', 'checkout', 'product', 'buy', 'price', 'shipping', 'order'],\n    techIndicators: ['shopify', 'woocommerce', 'magento', 'stripe', 'paypal'],\n    extractionFocus: ['products', 'categories', 'shipping-policy', 'return-policy'],\n  },\n  healthcare: {\n    keywords: ['health', 'medical', 'doctor', 'patient', 'clinic', 'hospital', 'telemedicine', 'wellness'],\n    techIndicators: ['hipaa', 'ehr', 'emr', 'epic', 'cerner'],\n    extractionFocus: ['services', 'providers', 'locations', 'insurance', 'compliance'],\n  },\n  fintech: {\n    keywords: ['finance', 'bank', 'payment', 'invest', 'crypto', 'blockchain', 'lending', 'insurance'],\n    techIndicators: ['stripe', 'plaid', 'coinbase', 'blockchain', 'encryption'],\n    extractionFocus: ['security', 'compliance', 'features', 'rates', 'partners'],\n  },\n  manufacturing: {\n    keywords: ['manufacturing', 'production', 'factory', 'industrial', 'supply chain', 'warehouse'],\n    techIndicators: ['iot', 'plc', 'scada', 'erp', 'mes'],\n    extractionFocus: ['products', 'capabilities', 'certifications', 'locations'],\n  },\n  consulting: {\n    keywords: ['consulting', 'advisory', 'services', 'expert', 'professional services', 'strategy'],\n    techIndicators: [],\n    extractionFocus: ['services', 'team', 'case-studies', 'clients', 'expertise'],\n  },\n  agency: {\n    keywords: ['agency', 'marketing', 'advertising', 'creative', 'digital', 'design', 'branding'],\n    techIndicators: ['adobe', 'figma', 'google-analytics', 'hubspot'],\n    extractionFocus: ['portfolio', 'services', 'clients', 'team', 'awards'],\n  },\n};\n\n/**\n * Detect company industry from scraped data\n */\nfunction detectIndustry(rawData: RawScrapedData): string | null {\n  const textLower = rawData.text.toLowerCase();\n  const techStack = rawData.techStack.map((t) => t.name.toLowerCase());\n\n  let bestMatch: { industry: string; score: number } | null = null;\n\n  for (const [industry, pattern] of Object.entries(INDUSTRY_PATTERNS)) {\n    let score = 0;\n\n    // Check keywords in text\n    for (const keyword of pattern.keywords) {\n      const regex = new RegExp(`\\\\b${keyword}\\\\b`, 'gi');\n      const matches = textLower.match(regex);\n      if (matches) {\n        score += matches.length * 2;\n      }\n    }\n\n    // Check tech indicators\n    for (const tech of pattern.techIndicators) {\n      if (techStack.some((t) => t.includes(tech.toLowerCase()))) {\n        score += 5;\n      }\n    }\n\n    if (!bestMatch || score > bestMatch.score) {\n      bestMatch = { industry, score };\n    }\n  }\n\n  // Only return if confidence is reasonable\n  return bestMatch && bestMatch.score > 3 ? bestMatch.industry : null;\n}\n\n// ============================================================================\n// LLM SYNTHESIS\n// ============================================================================\n\n/**\n * Synthesize structured Lead Object from raw scraped data\n * \n * Uses LLM to extract meaningful information from raw HTML/text\n * and structure it into a clean DiscoveredCompany object.\n * Now enhanced with industry-specific prompts.\n */\nasync function synthesizeLeadObject(\n  domain: string,\n  rawData: RawScrapedData\n): Promise<DiscoveredCompany> {\n  try {\n    // Detect industry for better prompt engineering\n    const detectedIndustry = detectIndustry(rawData);\n    \n    logger.info('Synthesizing lead object with LLM', { \n      domain,\n      detectedIndustry: detectedIndustry || 'general',\n    });\n\n    // Build industry-specific prompt for LLM\n    const prompt = buildSynthesisPrompt(domain, rawData, detectedIndustry);\n\n    // Generate structured data with LLM\n    const response = await sendUnifiedChatMessage({\n      model: 'gpt-4o-mini',\n      messages: [\n        {\n          role: 'system',\n          content: buildSystemPrompt(detectedIndustry),\n        },\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n      temperature: 0.1, // Low temperature for consistent extraction\n      maxTokens: 2000,\n    });\n\n    // Parse LLM response\n    let synthesized: Partial<DiscoveredCompany>;\n    try {\n      // Try to extract JSON from response text\n      const content = response.text;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        synthesized = JSON.parse(jsonMatch[0]);\n      } else {\n        synthesized = JSON.parse(content);\n      }\n    } catch (parseError) {\n      logger.warn('Failed to parse LLM response, using defaults', {\n        domain,\n        error: parseError instanceof Error ? parseError.message : 'Unknown',\n      });\n      synthesized = {};\n    }\n\n    // Merge with raw data\n    const company: DiscoveredCompany = {\n      domain,\n      companyName: synthesized.companyName || extractDomainName(domain),\n      description: synthesized.description,\n      industry: synthesized.industry,\n      size: synthesized.size,\n      location: synthesized.location,\n      \n      teamMembers: rawData.teamMembers.length > 0 \n        ? rawData.teamMembers \n        : (synthesized.teamMembers || []),\n      \n      techStack: rawData.techStack.length > 0 \n        ? rawData.techStack \n        : (synthesized.techStack || []),\n      \n      pressmentions: synthesized.pressmentions || [],\n      \n      contactInfo: synthesized.contactInfo || {\n        socialMedia: {},\n      },\n      \n      signals: {\n        isHiring: (rawData.careerData?.jobCount || 0) > 0,\n        jobCount: rawData.careerData?.jobCount || 0,\n        recentActivity: true,\n        fundingStage: synthesized.signals?.fundingStage,\n        growthIndicators: synthesized.signals?.growthIndicators || [],\n      },\n      \n      metadata: {\n        scrapedAt: new Date(),\n        expiresAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000), // 30 days\n        source: 'discovery-engine',\n        confidence: calculateConfidence(rawData, synthesized),\n      },\n      \n      // Initialize workflow state\n      workflow: createWorkflowState('discovery', 'completed'),\n    };\n\n    logger.info('LLM synthesis complete', {\n      domain,\n      confidence: company.metadata.confidence,\n    });\n\n    return company;\n  } catch (error) {\n    logger.error('Failed to synthesize lead object', error, { domain });\n    \n    // Fallback to raw data only\n    return {\n      domain,\n      companyName: extractDomainName(domain),\n      teamMembers: rawData.teamMembers || [],\n      techStack: rawData.techStack || [],\n      pressmentions: [],\n      contactInfo: { socialMedia: {} },\n      signals: {\n        isHiring: (rawData.careerData?.jobCount || 0) > 0,\n        jobCount: rawData.careerData?.jobCount || 0,\n        recentActivity: false,\n        growthIndicators: [],\n      },\n      metadata: {\n        scrapedAt: new Date(),\n        expiresAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000),\n        source: 'discovery-engine',\n        confidence: 0.5,\n      },\n      workflow: createWorkflowState('discovery', 'completed'),\n    };\n  }\n}\n\n/**\n * Build system prompt based on detected industry\n */\nfunction buildSystemPrompt(industry: string | null): string {\n  const basePrompt = `You are an expert B2B company data analyst specializing in extracting structured information from website content. Your task is to analyze website data and return accurate, well-structured JSON objects.`;\n\n  if (!industry) {\n    return basePrompt;\n  }\n\n  const industryPrompts: Record<string, string> = {\n    saas: `${basePrompt} You specialize in SaaS companies. Pay special attention to:\n- Pricing tiers and business model (freemium, subscription, usage-based)\n- Target customer segments (SMB, mid-market, enterprise)\n- Key integrations and API availability\n- Product categories and features\n- Growth indicators (customer count, funding, expansions)`,\n\n    ecommerce: `${basePrompt} You specialize in e-commerce businesses. Pay special attention to:\n- Product categories and catalog size\n- Shipping and fulfillment capabilities\n- Payment methods and checkout features\n- Return policies and customer service\n- Market focus (B2C, B2B, D2C)`,\n\n    healthcare: `${basePrompt} You specialize in healthcare companies. Pay special attention to:\n- Services offered (telehealth, diagnostics, treatment, etc.)\n- Compliance certifications (HIPAA, FDA, etc.)\n- Provider network and locations\n- Insurance accepted\n- Patient-focused vs. provider-focused offerings`,\n\n    fintech: `${basePrompt} You specialize in fintech companies. Pay special attention to:\n- Financial products and services\n- Security and compliance measures\n- Regulatory licenses and jurisdictions\n- Payment methods and banking partners\n- Target customer segments (consumer, business, enterprise)`,\n\n    manufacturing: `${basePrompt} You specialize in manufacturing companies. Pay special attention to:\n- Manufacturing capabilities and processes\n- Product categories and materials\n- Quality certifications (ISO, etc.)\n- Production locations and facilities\n- Supply chain and distribution capabilities`,\n\n    consulting: `${basePrompt} You specialize in consulting firms. Pay special attention to:\n- Service offerings and expertise areas\n- Client industries served\n- Team credentials and experience\n- Case studies and success stories\n- Geographic coverage`,\n\n    agency: `${basePrompt} You specialize in creative and marketing agencies. Pay special attention to:\n- Service capabilities (branding, digital, creative, etc.)\n- Portfolio and notable clients\n- Team size and specializations\n- Awards and recognition\n- Technology stack used`,\n  };\n\n  return industryPrompts[industry] || basePrompt;\n}\n\n/**\n * Build LLM prompt for data synthesis (industry-specific)\n */\nfunction buildSynthesisPrompt(\n  domain: string,\n  rawData: RawScrapedData,\n  industry: string | null\n): string {\n  const basePrompt = `Extract company information from this website data for ${domain}.\n\n${industry ? `DETECTED INDUSTRY: ${industry.toUpperCase()}` : ''}\n\nWEBSITE TEXT (first 5000 chars):\n${rawData.text.substring(0, 5000)}\n\nHIGH-VALUE AREAS:\n${rawData.highValueAreas.map((area, i) => \n  `${i + 1}. ${area.type}: ${area.content.substring(0, 500)}`\n).join('\\n')}\n\nTEAM MEMBERS FOUND: ${rawData.teamMembers.length}\nTECH STACK FOUND: ${rawData.techStack.map(t => t.name).join(', ')}\nCAREER OPENINGS: ${rawData.careerData?.jobCount || 0}`;\n\n  // Add industry-specific extraction instructions\n  let industryInstructions = '';\n  if (industry && INDUSTRY_PATTERNS[industry as keyof typeof INDUSTRY_PATTERNS]) {\n    const pattern = INDUSTRY_PATTERNS[industry as keyof typeof INDUSTRY_PATTERNS];\n    industryInstructions = `\n\nINDUSTRY-SPECIFIC FOCUS AREAS:\n${pattern.extractionFocus.map((focus, i) => `${i + 1}. ${focus}`).join('\\n')}\n\nWhen extracting data, prioritize finding information about: ${pattern.extractionFocus.join(', ')}`;\n  }\n\n  return `${basePrompt}${industryInstructions}\n\nExtract and return a JSON object with this structure:\n{\n  \"companyName\": \"string\",\n  \"description\": \"string (2-3 sentences highlighting key value proposition)\",\n  \"industry\": \"string (be specific, e.g., 'B2B SaaS - Marketing Analytics' not just 'Software')\",\n  \"size\": \"string (e.g., '1-10', '10-50', '50-200', '200-1000', '1000+', 'Enterprise')\",\n  \"location\": \"string (headquarters city, country)\",\n  \"contactInfo\": {\n    \"email\": \"string (general contact or sales email)\",\n    \"phone\": \"string\",\n    \"address\": \"string (if available)\",\n    \"socialMedia\": {\n      \"linkedin\": \"string (full URL)\",\n      \"twitter\": \"string (handle or URL)\",\n      \"facebook\": \"string (URL)\"\n    }\n  },\n  \"signals\": {\n    \"fundingStage\": \"string (bootstrapped, seed, series A-F, public, acquired, etc.)\",\n    \"growthIndicators\": [\n      \"string array of specific growth signals like 'Recently raised Series B',\n      'Expanding to 3 new markets',\n      'Hiring 50+ roles',\n      'Featured in TechCrunch',\n      'Hit 100K users milestone'\"\n    ]\n  },\n  \"pressmentions\": [\n    {\n      \"title\": \"string (headline)\",\n      \"summary\": \"string (1-2 sentence summary)\",\n      \"date\": \"string (YYYY-MM-DD or 'Month YYYY' format)\",\n      \"url\": \"string (if available)\"\n    }\n  ]\n}\n\nIMPORTANT:\n- Be specific and accurate, don't make up information\n- If data is not available, omit the field or use null\n- Extract real quotes and facts from the website\n- For growth indicators, be specific with numbers and timeframes\n- Return ONLY valid JSON, no markdown formatting, no explanations`;\n}\n\n/**\n * Calculate confidence score based on data completeness\n */\nfunction calculateConfidence(rawData: RawScrapedData, synthesized: Partial<DiscoveredCompany>): number {\n  let score = 0;\n  let maxScore = 0;\n\n  // Team members found\n  maxScore += 20;\n  if (rawData.teamMembers.length > 0) {score += 20;}\n  else if (rawData.teamMembers.length > 5) {score += 15;}\n  else if (rawData.teamMembers.length > 0) {score += 10;}\n\n  // Tech stack found\n  maxScore += 15;\n  if (rawData.techStack.length > 5) {score += 15;}\n  else if (rawData.techStack.length > 0) {score += 10;}\n\n  // Company info extracted\n  maxScore += 30;\n  if (synthesized.companyName) {score += 10;}\n  if (synthesized.description) {score += 10;}\n  if (synthesized.industry) {score += 5;}\n  if (synthesized.size) {score += 5;}\n\n  // Contact info found\n  maxScore += 15;\n  if (synthesized.contactInfo?.email) {score += 10;}\n  if (synthesized.contactInfo?.phone) {score += 5;}\n\n  // High-value areas extracted\n  maxScore += 20;\n  score += Math.min(20, rawData.highValueAreas.length * 4);\n\n  return Math.round((score / maxScore) * 100) / 100;\n}\n\n/**\n * Extract company name from domain\n */\nfunction extractDomainName(domain: string): string {\n  const name = domain.replace(/^https?:\\/\\//, '').replace(/^www\\./, '').split('.')[0];\n  return name.charAt(0).toUpperCase() + name.slice(1);\n}\n\n// ============================================================================\n// ARCHIVE STORAGE\n// ============================================================================\n\n/**\n * Save discovered data to discoveryArchive with 30-day TTL\n */\nasync function saveToArchive(\n  domain: string,\n  organizationId: string,\n  company: DiscoveredCompany,\n  rawData: RawScrapedData\n): Promise<{ scrape: TemporaryScrape; isNew: boolean }> {\n  try {\n    const url = domain.startsWith('http') ? domain : `https://${domain}`;\n\n    const result = await saveToDiscoveryArchive({\n      organizationId,\n      url,\n      rawHtml: JSON.stringify(rawData),\n      cleanedContent: JSON.stringify(company),\n      metadata: {\n        title: company.companyName || extractDomainName(domain),\n        description: company.description,\n        author: 'discovery-engine',\n      },\n    });\n\n    logger.info('Saved to discovery archive', {\n      domain,\n      organizationId,\n      scrapeId: result.scrape.id,\n      isNew: result.isNew,\n      expiresAt: result.scrape.expiresAt,\n    });\n\n    return result;\n  } catch (error) {\n    logger.error('Failed to save to discovery archive', error, {\n      domain,\n      organizationId,\n    });\n    throw error;\n  }\n}\n\n// ============================================================================\n// BATCH DISCOVERY\n// ============================================================================\n\n/**\n * Discover multiple companies in batch\n * \n * Rate-limited to avoid overwhelming target sites.\n * \n * @param domains - Array of domains to discover\n * @param organizationId - Organization requesting discovery\n * @param options - Batch options\n * @returns Array of discovery results\n */\nexport async function discoverCompaniesBatch(\n  domains: string[],\n  organizationId: string,\n  options: {\n    concurrency?: number;\n    delayMs?: number;\n  } = {}\n): Promise<DiscoveryResult[]> {\n  const { concurrency = 3, delayMs = 2000 } = options;\n\n  logger.info('Starting batch discovery', {\n    domainsCount: domains.length,\n    concurrency,\n    organizationId,\n  });\n\n  const results: DiscoveryResult[] = [];\n  \n  // Process in batches\n  for (let i = 0; i < domains.length; i += concurrency) {\n    const batch = domains.slice(i, i + concurrency);\n    \n    const batchResults = await Promise.allSettled(\n      batch.map(domain => discoverCompany(domain, organizationId))\n    );\n\n    for (const result of batchResults) {\n      if (result.status === 'fulfilled') {\n        results.push(result.value);\n      } else {\n        logger.error('Batch discovery failed for domain', result.reason);\n      }\n    }\n\n    // Rate limiting delay between batches\n    if (i + concurrency < domains.length) {\n      await new Promise(resolve => setTimeout(resolve, delayMs));\n    }\n  }\n\n  logger.info('Batch discovery complete', {\n    totalDomains: domains.length,\n    successCount: results.length,\n    failedCount: domains.length - results.length,\n  });\n\n  return results;\n}\n\n// ============================================================================\n// PERSON DISCOVERY\n// ============================================================================\n\n/**\n * Discover person data from email address\n * \n * This function enriches a person's email with professional data by:\n * 1. Checking 30-day cache first\n * 2. Extracting domain and searching company website\n * 3. Finding LinkedIn profile via Google search\n * 4. Synthesizing data with LLM\n * \n * @param email - Person's email address\n * @param organizationId - Organization requesting the discovery\n * @returns Complete person discovery result\n * \n * @example\n * ```typescript\n * const result = await discoverPerson('john@example.com', 'org_123');\n * console.log(`Found: ${result.person.fullName} - ${result.person.title}`);\n * console.log(`LinkedIn: ${result.person.socialProfiles.linkedin}`);\n * console.log(`From cache: ${result.fromCache}`);\n * ```\n */\nexport async function discoverPerson(\n  email: string,\n  organizationId: string\n): Promise<PersonDiscoveryResult> {\n  try {\n    logger.info('Starting person discovery', {\n      email,\n      organizationId,\n      source: 'person-discovery',\n    });\n\n    // Validate email\n    if (!email?.includes('@')) {\n      throw new Error('Invalid email address');\n    }\n\n    // Step 1: Check discoveryArchive (30-day cache)\n    const cacheKey = `person:${email}`;\n    const contentHash = calculateContentHash(cacheKey);\n    const cached = await getFromDiscoveryArchiveByHash(organizationId, contentHash);\n    \n    if (cached && cached.expiresAt > new Date()) {\n      logger.info('Person discovery archive HIT', {\n        email,\n        organizationId,\n        cacheAge: Date.now() - cached.createdAt.getTime(),\n      });\n\n      const person = JSON.parse(cached.cleanedContent) as DiscoveredPerson;\n      \n      // Emit Signal Bus signal even for cached data (lower priority)\n      await emitPersonDiscoverySignals(person, organizationId, true);\n\n      return {\n        person,\n        fromCache: true,\n        scrapeId: cached.id,\n      };\n    }\n\n    // Step 2: Cache MISS - perform discovery\n    logger.info('Person discovery archive MISS - initiating search', {\n      email,\n      organizationId,\n    });\n\n    const person = await discoverPersonData(email, organizationId);\n\n    // Step 3: Save to discoveryArchive (30-day TTL)\n    const scrapeResult = await saveToDiscoveryArchive({\n      organizationId,\n      url: cacheKey,\n      rawHtml: JSON.stringify({ email, discoveredAt: new Date() }),\n      cleanedContent: JSON.stringify(person),\n      metadata: {\n        title: person.fullName || email,\n        description: person.title,\n        author: 'person-discovery',\n      },\n    });\n\n    logger.info('Person discovery complete', {\n      email,\n      organizationId,\n      fullName: person.fullName,\n      title: person.title,\n      fromCache: false,\n    });\n\n    // Emit Signal Bus signal for newly discovered person\n    await emitPersonDiscoverySignals(person, organizationId, false);\n\n    return {\n      person,\n      fromCache: false,\n      scrapeId: scrapeResult.scrape.id,\n    };\n  } catch (error) {\n    logger.error('Failed to discover person', error, {\n      email,\n      organizationId,\n    });\n    \n    const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n    throw new Error(`Failed to discover person ${email}: ${errorMessage}`);\n  }\n}\n\n/**\n * Perform person data discovery\n * \n * Multi-source discovery strategy:\n * 1. Extract domain from email\n * 2. Search company website for person\n * 3. Search LinkedIn via Google\n * 4. Search GitHub if applicable\n * 5. Synthesize with LLM\n */\nasync function discoverPersonData(\n  email: string,\n  organizationId: string\n): Promise<DiscoveredPerson> {\n  const controller = createBrowserController({ headless: true });\n  const discoveryMethods: string[] = [];\n  const personData: Partial<DiscoveredPerson> & { socialProfiles: Record<string, string> } = {\n    email,\n    socialProfiles: {},\n  };\n\n  try {\n    // Extract email parts\n    const [localPart, domain] = email.split('@');\n    const firstName = extractFirstName(localPart);\n    const lastName = extractLastName(localPart);\n\n    personData.firstName = firstName;\n    personData.lastName = lastName;\n    personData.fullName = `${firstName} ${lastName}`.trim() || email;\n\n    // Strategy 1: Search company website\n    try {\n      const companyUrl = `https://${domain}`;\n      await controller.navigate(companyUrl);\n      \n      const teamMembers = await controller.findTeamDirectory();\n      const matchedMember = teamMembers.find((member) => {\n        const memberName = member.name.toLowerCase();\n        return (\n          (firstName && memberName.includes(firstName.toLowerCase())) ||\n          (lastName && memberName.includes(lastName.toLowerCase())) ||\n          member.email === email\n        );\n      });\n\n      if (matchedMember) {\n        personData.title = matchedMember.title;\n        personData.currentRole = {\n          title: matchedMember.title || '',\n          company: domain,\n        };\n        if (matchedMember.linkedinUrl) {\n          personData.socialProfiles.linkedin = matchedMember.linkedinUrl;\n        }\n        discoveryMethods.push('company-website');\n      }\n    } catch (error) {\n      logger.debug('Company website search failed', {\n        email,\n        error: error instanceof Error ? error.message : 'Unknown',\n      });\n    }\n\n    // Strategy 2: LinkedIn search via Google\n    if (!personData.socialProfiles.linkedin) {\n      try {\n        const searchQuery = `site:linkedin.com/in \"${firstName} ${lastName}\" ${domain}`;\n        const googleUrl = `https://www.google.com/search?q=${encodeURIComponent(searchQuery)}`;\n        \n        await controller.navigate(googleUrl);\n        await controller.getPage()?.waitForTimeout(2000);\n        \n        // Extract LinkedIn URLs from search results\n        const linkedinLinks = await controller.getPage()?.$$eval('a', (links) =>\n          links\n            .map((link) => link.getAttribute('href') || '')\n            .filter((href) => href.includes('linkedin.com/in/'))\n            .map((href) => {\n              // Extract clean LinkedIn URL\n              const match = href.match(/https?:\\/\\/(www\\.)?linkedin\\.com\\/in\\/[^&?]+/);\n              return match ? match[0] : null;\n            })\n            .filter((url): url is string => url !== null)\n        );\n\n        if (linkedinLinks && linkedinLinks.length > 0) {\n          personData.socialProfiles.linkedin = linkedinLinks[0];\n          discoveryMethods.push('google-linkedin-search');\n        }\n      } catch (error) {\n        logger.debug('LinkedIn search failed', {\n          email,\n          error: error instanceof Error ? error.message : 'Unknown',\n        });\n      }\n    }\n\n    // Strategy 3: GitHub search (for technical roles)\n    try {\n      const githubUsername = localPart.replace(/[^a-zA-Z0-9-]/g, '');\n      const githubUrl = `https://github.com/${githubUsername}`;\n      \n      await controller.navigate(githubUrl);\n      await controller.getPage()?.waitForTimeout(1000);\n      \n      // Check if profile exists (no 404)\n      const title = await controller.getPage()?.title();\n      if (title && !title.includes('Page not found')) {\n        personData.socialProfiles.github = githubUrl;\n        discoveryMethods.push('github');\n      }\n    } catch (error) {\n      logger.debug('GitHub search failed', {\n        email,\n        error: error instanceof Error ? error.message : 'Unknown',\n      });\n    }\n\n    // Strategy 4: LLM synthesis\n    const synthesized = await synthesizePersonData(email, personData, discoveryMethods);\n\n    const finalPerson: DiscoveredPerson = {\n      ...personData,\n      ...synthesized,\n      email,\n      socialProfiles: {\n        ...personData.socialProfiles,\n        ...synthesized.socialProfiles,\n      },\n      metadata: {\n        discoveredAt: new Date(),\n        expiresAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000), // 30 days\n        source: 'person-discovery',\n        confidence: calculatePersonConfidence(personData, discoveryMethods),\n        methods: discoveryMethods,\n      },\n      workflow: createWorkflowState('discovery', 'completed'),\n    };\n\n    return finalPerson;\n  } catch (error) {\n    logger.error('Failed to discover person data', error, { email });\n    \n    // Return minimal data\n    return {\n      email,\n      fullName: personData.fullName || email,\n      socialProfiles: personData.socialProfiles || {},\n      metadata: {\n        discoveredAt: new Date(),\n        expiresAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000),\n        source: 'person-discovery',\n        confidence: 0.1,\n        methods: discoveryMethods,\n      },\n      workflow: createWorkflowState('discovery', 'failed'),\n    };\n  } finally {\n    await controller.close();\n  }\n}\n\n/**\n * Synthesize person data with LLM\n */\nasync function synthesizePersonData(\n  email: string,\n  personData: Partial<DiscoveredPerson>,\n  methods: string[]\n): Promise<Partial<DiscoveredPerson>> {\n  try {\n    const prompt = `Enrich this person's profile based on available data:\n\nEmail: ${email}\nName: ${personData.fullName || 'Unknown'}\nTitle: ${personData.title || 'Unknown'}\nCompany: ${personData.currentRole?.company || 'Unknown'}\nLinkedIn: ${personData.socialProfiles?.linkedin || 'Not found'}\nGitHub: ${personData.socialProfiles?.github || 'Not found'}\n\nDiscovery methods used: ${methods.join(', ')}\n\nBased on this information, provide:\n1. Inferred professional role/seniority\n2. Likely skills (if technical role detected)\n3. Professional interests\n4. Missing profile information\n\nReturn JSON with this structure:\n{\n  \"title\": \"string (if can be improved)\",\n  \"skills\": [\"string array\"],\n  \"interests\": [\"string array\"],\n  \"currentRole\": {\n    \"title\": \"string\",\n    \"company\": \"string\"\n  }\n}\n\nReturn ONLY valid JSON, no markdown.`;\n\n    const response = await sendUnifiedChatMessage({\n      model: 'gpt-4o-mini',\n      messages: [{ role: 'user', content: prompt }],\n      temperature: 0.1,\n      maxTokens: 500,\n    });\n\n    // Parse LLM response\n    try {\n      const content = response.text;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]);\n      }\n    } catch (parseError) {\n      logger.debug('Failed to parse LLM person synthesis', {\n        email,\n        error: parseError instanceof Error ? parseError.message : 'Unknown',\n      });\n    }\n\n    return {};\n  } catch (error) {\n    logger.debug('Person LLM synthesis failed', {\n      email,\n      error: error instanceof Error ? error.message : 'Unknown',\n    });\n    return {};\n  }\n}\n\n/**\n * Calculate person discovery confidence score\n */\nfunction calculatePersonConfidence(\n  personData: Partial<DiscoveredPerson>,\n  methods: string[]\n): number {\n  let score = 0;\n  let maxScore = 0;\n\n  // Name found\n  maxScore += 20;\n  if (personData.fullName && personData.fullName !== personData.email) {\n    score += 20;\n  }\n\n  // Title found\n  maxScore += 25;\n  if (personData.title) {score += 25;}\n\n  // LinkedIn found\n  maxScore += 30;\n  if (personData.socialProfiles?.linkedin) {score += 30;}\n\n  // Company website match\n  maxScore += 15;\n  if (methods.includes('company-website')) {score += 15;}\n\n  // Additional profiles\n  maxScore += 10;\n  if (personData.socialProfiles?.github) {score += 5;}\n  if (personData.socialProfiles?.twitter) {score += 5;}\n\n  return Math.round((score / maxScore) * 100) / 100;\n}\n\n/**\n * Extract first name from email local part\n */\nfunction extractFirstName(localPart: string): string {\n  // Common patterns: john.doe, john_doe, johndoe, j.doe\n  const cleaned = localPart.toLowerCase().replace(/[^a-z.]/g, '');\n  const parts = cleaned.split('.');\n  \n  if (parts.length > 0 && parts[0].length > 1) {\n    return capitalize(parts[0]);\n  }\n  \n  return '';\n}\n\n/**\n * Extract last name from email local part\n */\nfunction extractLastName(localPart: string): string {\n  const cleaned = localPart.toLowerCase().replace(/[^a-z.]/g, '');\n  const parts = cleaned.split('.');\n  \n  if (parts.length > 1 && parts[1].length > 1) {\n    return capitalize(parts[1]);\n  }\n  \n  return '';\n}\n\n/**\n * Capitalize first letter\n */\nfunction capitalize(str: string): string {\n  return str.charAt(0).toUpperCase() + str.slice(1);\n}\n\n/**\n * Batch person discovery\n */\nexport async function discoverPeopleBatch(\n  emails: string[],\n  organizationId: string,\n  options: {\n    concurrency?: number;\n    delayMs?: number;\n  } = {}\n): Promise<PersonDiscoveryResult[]> {\n  const { concurrency = 3, delayMs = 2000 } = options;\n\n  logger.info('Starting batch person discovery', {\n    emailsCount: emails.length,\n    concurrency,\n    organizationId,\n  });\n\n  const results: PersonDiscoveryResult[] = [];\n  \n  // Process in batches\n  for (let i = 0; i < emails.length; i += concurrency) {\n    const batch = emails.slice(i, i + concurrency);\n    \n    const batchResults = await Promise.allSettled(\n      batch.map(email => discoverPerson(email, organizationId))\n    );\n\n    for (const result of batchResults) {\n      if (result.status === 'fulfilled') {\n        results.push(result.value);\n      } else {\n        logger.error('Batch person discovery failed', result.reason);\n      }\n    }\n\n    // Rate limiting delay between batches\n    if (i + concurrency < emails.length) {\n      await new Promise(resolve => setTimeout(resolve, delayMs));\n    }\n  }\n\n  logger.info('Batch person discovery complete', {\n    totalEmails: emails.length,\n    successCount: results.length,\n    failedCount: emails.length - results.length,\n  });\n\n  return results;\n}\n\n// ============================================================================\n// SIGNAL BUS INTEGRATION\n// ============================================================================\n\n/**\n * Emit discovery signals to the Neural Net\n * \n * Emits signals when company data is discovered (new or cached).\n * Triggers downstream actions like lead scoring, sequence enrollment, etc.\n */\nasync function emitDiscoverySignals(\n  company: DiscoveredCompany,\n  organizationId: string,\n  fromCache: boolean\n): Promise<void> {\n  try {\n    const coordinator = getServerSignalCoordinator();\n\n    // Signal 1: website.discovered - Always emit when company is discovered\n    await coordinator.emitSignal({\n      type: 'website.discovered',\n      orgId: organizationId,\n      confidence: company.metadata.confidence,\n      priority: fromCache ? 'Low' : 'Medium',\n      metadata: {\n        source: 'discovery-engine',\n        domain: company.domain,\n        companyName: company.companyName,\n        industry: company.industry,\n        size: company.size,\n        location: company.location,\n        teamMembersCount: company.teamMembers.length,\n        techStackCount: company.techStack.length,\n        fromCache,\n        scrapedAt: company.metadata.scrapedAt.toISOString(),\n        expiresAt: company.metadata.expiresAt.toISOString(),\n      },\n    });\n\n    // Signal 2: website.technology.detected - Emit if tech stack found\n    if (company.techStack.length > 0) {\n      await coordinator.emitSignal({\n        type: 'website.technology.detected',\n        orgId: organizationId,\n        confidence: 0.9, // Tech stack detection is usually accurate\n        priority: 'Medium',\n        metadata: {\n          source: 'discovery-engine',\n          domain: company.domain,\n          companyName: company.companyName,\n          techStack: company.techStack.map(t => ({\n            name: t.name,\n            category: t.category,\n            confidence: t.confidence,\n          })),\n          techStackCount: company.techStack.length,\n          categories: [...new Set(company.techStack.map(t => t.category))],\n        },\n      });\n    }\n\n    // Signal 3: lead.discovered - Emit for each team member found\n    if (company.teamMembers.length > 0) {\n      for (const member of company.teamMembers.slice(0, 10)) { // Limit to first 10 to avoid spam\n        if (member.email) {\n          await coordinator.emitSignal({\n            type: 'lead.discovered',\n            leadId: member.email, // Use email as temporary leadId\n            orgId: organizationId,\n            confidence: member.email ? 0.8 : 0.5,\n            priority: member.email ? 'Medium' : 'Low',\n            metadata: {\n              source: 'discovery-engine',\n              discoveryMethod: 'team-directory',\n              domain: company.domain,\n              companyName: company.companyName,\n              personName: member.name,\n              personTitle: member.title,\n              personEmail: member.email,\n              personLinkedIn: member.linkedinUrl,\n              personImageUrl: member.imageUrl,\n              companyIndustry: company.industry,\n              companySize: company.size,\n            },\n          });\n        }\n      }\n    }\n\n    logger.info('Discovery signals emitted', {\n      domain: company.domain,\n      organizationId,\n      fromCache,\n      signalsEmitted: {\n        websiteDiscovered: 1,\n        technologyDetected: company.techStack.length > 0 ? 1 : 0,\n        leadsDiscovered: Math.min(company.teamMembers.filter(m => m.email).length, 10),\n      },\n    });\n  } catch (error) {\n    // Don't fail discovery if signal emission fails\n    logger.error('Failed to emit discovery signals', error, {\n      domain: company.domain,\n      organizationId,\n    });\n  }\n}\n\n/**\n * Emit person discovery signals to the Neural Net\n * \n * Emits signals when person data is discovered.\n */\nasync function emitPersonDiscoverySignals(\n  person: DiscoveredPerson,\n  organizationId: string,\n  fromCache: boolean\n): Promise<void> {\n  try {\n    const coordinator = getServerSignalCoordinator();\n\n    // Signal: lead.discovered\n    await coordinator.emitSignal({\n      type: 'lead.discovered',\n      leadId: person.email,\n      orgId: organizationId,\n      confidence: person.metadata.confidence,\n      priority: fromCache ? 'Low' : 'Medium',\n      metadata: {\n        source: 'person-discovery',\n        discoveryMethod: 'email-enrichment',\n        email: person.email,\n        firstName: person.firstName,\n        lastName: person.lastName,\n        fullName: person.fullName,\n        title: person.title,\n        company: person.company,\n        currentRole: person.currentRole,\n        location: person.location,\n        socialProfiles: person.socialProfiles,\n        skills: person.skills,\n        interests: person.interests,\n        discoveryMethods: person.metadata.methods,\n        fromCache,\n        discoveredAt: person.metadata.discoveredAt.toISOString(),\n        expiresAt: person.metadata.expiresAt.toISOString(),\n      },\n    });\n\n    logger.info('Person discovery signal emitted', {\n      email: person.email,\n      organizationId,\n      fullName: person.fullName,\n      fromCache,\n    });\n  } catch (error) {\n    // Don't fail person discovery if signal emission fails\n    logger.error('Failed to emit person discovery signal', error, {\n      email: person.email,\n      organizationId,\n    });\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\services\\mutation-engine.ts","messages":[{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\[.","line":179,"column":42,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":179,"endColumn":43,"suggestions":[{"messageId":"removeEscape","fix":{"range":[5202,5203],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[5202,5202],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]},{"ruleId":"no-useless-escape","severity":2,"message":"Unnecessary escape character: \\[.","line":207,"column":42,"nodeType":"Literal","messageId":"unnecessaryEscape","endLine":207,"endColumn":43,"suggestions":[{"messageId":"removeEscape","fix":{"range":[5913,5914],"text":""},"desc":"Remove the `\\`. This maintains the current functionality."},{"messageId":"escapeBackslash","fix":{"range":[5913,5913],"text":"\\"},"desc":"Replace the `\\` with `\\\\` to include the actual backslash character."}]}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Mutation Engine\n * \n * Compiles IndustryTemplate + OnboardingData ‚Üí Mutated Template (BaseModel input)\n * \n * Core Responsibilities:\n * 1. Deep merge template with onboarding-specific mutations\n * 2. Apply conditional rules based on customer profile\n * 3. Adjust signal weights mathematically\n * 4. Modify persona based on sales methodology\n * \n * Design Principles:\n * - Immutable: Never modifies original template\n * - Predictable: Same inputs always produce same output\n * - Testable: All mutations are verifiable through unit tests\n */\n\nimport type { IndustryTemplate, MutationRule } from '@/lib/persona/templates/types';\nimport type { OnboardingData } from '@/types/agent-memory';\nimport { logger } from '@/lib/logger/logger';\n\nexport class MutationEngine {\n  /**\n   * Compile template with onboarding data\n   * \n   * @param template - Industry template (genetic blueprint)\n   * @param onboarding - Client onboarding data\n   * @returns Mutated template ready for BaseModel conversion\n   */\n  compile(\n    template: IndustryTemplate,\n    onboarding: OnboardingData\n  ): IndustryTemplate {\n    if (!onboarding) {\n      throw new Error('Onboarding data is required');\n    }\n\n    logger.debug('[MutationEngine] Starting compilation', {\n      templateId: template.id,\n      businessName: onboarding.businessName\n    });\n\n    // Start with deep clone of template (immutable)\n    let mutated = this.deepClone(template);\n\n    // Apply global mutation rules\n    mutated = this.applyGlobalRules(mutated, onboarding);\n\n    // Apply template-specific mutation rules (if any)\n    if ('mutationRules' in template && Array.isArray((template as any).mutationRules)) {\n      mutated = this.applyTemplateRules(mutated, onboarding, (template as any).mutationRules as MutationRule[]);\n    }\n\n    logger.debug('[MutationEngine] Compilation complete', {\n      templateId: template.id,\n      mutationsApplied: true\n    });\n\n    return mutated;\n  }\n\n  /**\n   * Apply global mutation rules that apply to ALL templates\n   */\n  private applyGlobalRules(\n    template: IndustryTemplate,\n    onboarding: OnboardingData\n  ): IndustryTemplate {\n    let mutated = { ...template };\n\n    // Rule 1: Enterprise Focus - Boost hiring/expansion signals\n    if (this.isEnterpriseFocus(onboarding)) {\n      mutated = this.boostEnterpriseSignals(mutated);\n    }\n\n    // Rule 2: Aggressive Closing - Adjust persona tone\n    if (onboarding.closingStyle && onboarding.closingStyle > 7) {\n      mutated = this.adjustForAggressiveClosing(mutated);\n    }\n\n    // Rule 3: B2B Complexity - Adjust cognitive framework\n    if (this.isB2BComplex(onboarding)) {\n      mutated = this.adjustForB2BComplexity(mutated);\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Apply template-specific mutation rules\n   */\n  private applyTemplateRules(\n    template: IndustryTemplate,\n    onboarding: OnboardingData,\n    rules: MutationRule[]\n  ): IndustryTemplate {\n    let mutated = { ...template };\n\n    // Sort by priority (lower number = higher priority)\n    const sortedRules = [...rules].sort((a, b) => a.priority - b.priority);\n\n    for (const rule of sortedRules) {\n      if (rule.condition(onboarding)) {\n        logger.debug('[MutationEngine] Applying rule', { ruleId: rule.id });\n        mutated = this.applyMutations(mutated, rule.mutations);\n      }\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Apply mutation operations to template\n   */\n  private applyMutations(\n    template: IndustryTemplate,\n    mutations: any[]\n  ): IndustryTemplate {\n    const mutated = this.deepClone(template);\n\n    for (const mutation of mutations) {\n      const { path, operation, value, skipIfMissing } = mutation;\n\n      try {\n        const currentValue = this.getValueAtPath(mutated, path);\n\n        if (currentValue === undefined && skipIfMissing) {\n          continue;\n        }\n\n        const newValue = this.calculateNewValue(currentValue, operation, value);\n        this.setValueAtPath(mutated, path, newValue);\n      } catch (error) {\n        logger.warn('[MutationEngine] Mutation failed', {\n          path,\n          operation,\n          error: error instanceof Error ? error.message : 'Unknown error'\n        });\n      }\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Calculate new value based on operation\n   */\n  private calculateNewValue(current: any, operation: string, value: any): any {\n    switch (operation) {\n      case 'add':\n        return (current || 0) + value;\n      case 'subtract':\n        return (current || 0) - value;\n      case 'multiply':\n        return (current || 0) * value;\n      case 'set':\n        return value;\n      case 'append':\n        return Array.isArray(current) ? [...current, value] : [value];\n      case 'prepend':\n        return Array.isArray(current) ? [value, ...current] : [value];\n      default:\n        return current;\n    }\n  }\n\n  /**\n   * Get value at nested path\n   */\n  private getValueAtPath(obj: any, path: string): any {\n    // Handle array notation like \"highValueSignals[funding].scoreBoost\"\n    const parts = path.split('.');\n    let current = obj;\n\n    for (const part of parts) {\n      if (!current) {return undefined;}\n\n      // Check for array index notation [id]\n      const arrayMatch = part.match(/^([^\\[]+)\\[([^\\]]+)\\]$/);\n      if (arrayMatch) {\n        const [, arrayKey, idValue] = arrayMatch;\n        const array = current[arrayKey];\n        if (Array.isArray(array)) {\n          current = array.find((item: any) => item.id === idValue);\n        } else {\n          return undefined;\n        }\n      } else {\n        current = current[part];\n      }\n    }\n\n    return current;\n  }\n\n  /**\n   * Set value at nested path\n   */\n  private setValueAtPath(obj: any, path: string, value: any): void {\n    const parts = path.split('.');\n    let current = obj;\n\n    for (let i = 0; i < parts.length - 1; i++) {\n      const part = parts[i];\n      \n      // Handle array notation\n      const arrayMatch = part.match(/^([^\\[]+)\\[([^\\]]+)\\]$/);\n      if (arrayMatch) {\n        const [, arrayKey, idValue] = arrayMatch;\n        const array = current[arrayKey];\n        if (Array.isArray(array)) {\n          current = array.find((item: any) => item.id === idValue);\n        }\n      } else {\n        if (!current[part]) {\n          current[part] = {};\n        }\n        current = current[part];\n      }\n    }\n\n    const lastPart = parts[parts.length - 1];\n    current[lastPart] = value;\n  }\n\n  /**\n   * Check if target customer is Enterprise\n   */\n  private isEnterpriseFocus(onboarding: OnboardingData): boolean {\n    const targetCustomer = onboarding.targetCustomer?.toLowerCase() || '';\n    return (\n      targetCustomer.includes('enterprise') ||\n      targetCustomer.includes('500+') ||\n      targetCustomer.includes('large')\n    );\n  }\n\n  /**\n   * Check if target is B2B with complex procurement\n   */\n  private isB2BComplex(onboarding: OnboardingData): boolean {\n    const targetCustomer = onboarding.targetCustomer?.toLowerCase() || '';\n    return (\n      targetCustomer.includes('b2b') ||\n      targetCustomer.includes('procurement') ||\n      targetCustomer.includes('rfp') ||\n      targetCustomer.includes('business')\n    );\n  }\n\n  /**\n   * Boost signals relevant to Enterprise customers\n   */\n  private boostEnterpriseSignals(template: IndustryTemplate): IndustryTemplate {\n    const mutated = this.deepClone(template);\n\n    if (mutated.research?.highValueSignals) {\n      mutated.research.highValueSignals = mutated.research.highValueSignals.map(signal => {\n        // Boost signals related to growth, funding, hiring\n        if (\n          signal.id.includes('funding') ||\n          signal.id.includes('hiring') ||\n          signal.id.includes('expansion') ||\n          signal.id.includes('new_location')\n        ) {\n          return {\n            ...signal,\n            scoreBoost: signal.scoreBoost + 3\n          };\n        }\n        return signal;\n      });\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Adjust template for aggressive closing methodology\n   */\n  private adjustForAggressiveClosing(template: IndustryTemplate): IndustryTemplate {\n    const mutated = this.deepClone(template);\n\n    // Adjust tone to be more direct\n    if (mutated.coreIdentity) {\n      mutated.coreIdentity.tone = 'Direct, urgent, action-oriented';\n    }\n\n    // Adjust conversion rhythm\n    if (mutated.tacticalExecution) {\n      mutated.tacticalExecution.conversionRhythm = \n        'Every message ends with a clear call-to-action and booking link';\n    }\n\n    // Boost urgency-related signals if present\n    if (mutated.research?.highValueSignals) {\n      mutated.research.highValueSignals = mutated.research.highValueSignals.map(signal => {\n        if (signal.id.includes('hiring') || signal.id.includes('expansion')) {\n          return {\n            ...signal,\n            scoreBoost: signal.scoreBoost + 2\n          };\n        }\n        return signal;\n      });\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Adjust cognitive framework for B2B complexity\n   */\n  private adjustForB2BComplexity(template: IndustryTemplate): IndustryTemplate {\n    const mutated = this.deepClone(template);\n\n    if (mutated.cognitiveLogic) {\n      // Enhance framework for complex sales\n      if (!mutated.cognitiveLogic.framework.includes('B2B')) {\n        mutated.cognitiveLogic.framework = `B2B Enterprise: ${mutated.cognitiveLogic.framework}`;\n      }\n\n      // Update reasoning to include stakeholder management\n      if (!mutated.cognitiveLogic.reasoning.includes('stakeholder')) {\n        mutated.cognitiveLogic.reasoning += \n          '. Identify multiple stakeholders and decision-makers in complex buying committees.';\n      }\n    }\n\n    return mutated;\n  }\n\n  /**\n   * Deep clone object (handles nested structures)\n   */\n  private deepClone<T>(obj: T): T {\n    return JSON.parse(JSON.stringify(obj));\n  }\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\templates\\revenue-forecasting-engine.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":428,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":428,"endColumn":54},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":429,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":429,"endColumn":76}],"suppressedMessages":[],"errorCount":2,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Revenue Forecasting Engine\n * \n * Predictive revenue forecasting using:\n * - Stage-weighted pipeline value\n * - Historical win rates\n * - Deal velocity and trends\n * - Quota attainment tracking\n * - Rolling forecasts (30/60/90 day)\n * \n * FORECASTING METHODS:\n * 1. Pipeline-based: Sum of (deal value √ó stage probability)\n * 2. Historical-based: Trend analysis of past performance\n * 3. Quota-based: Tracking against targets\n * 4. Confidence intervals: Best case / Most likely / Worst case\n * \n * INTEGRATION:\n * - Uses industry templates for stage probabilities\n * - Uses deal scoring for adjusted probabilities\n * - Emits signals to Signal Bus\n */\n\nimport { logger } from '@/lib/logger/logger';\nimport { getServerSignalCoordinator } from '@/lib/orchestration/coordinator-factory-server';\nimport type { Deal } from '@/lib/crm/deal-service';\nimport { getTemplateById } from './industry-templates';\nimport type { SalesIndustryTemplate } from './industry-templates';\nimport { calculateDealScore } from './deal-scoring-engine';\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\nexport interface RevenueForecast {\n  organizationId: string;\n  workspaceId: string;\n  period: ForecastPeriod;\n  \n  // Primary forecast\n  forecast: number; // Most likely revenue\n  bestCase: number; // Optimistic scenario (90th percentile)\n  worstCase: number; // Pessimistic scenario (10th percentile)\n  confidence: number; // 0-100 - How confident we are\n  \n  // Breakdown\n  byStage: Map<string, StageRevenue>;\n  byRep?: Map<string, number>;\n  byProduct?: Map<string, number>;\n  \n  // Metrics\n  pipelineCoverage: number; // Pipeline / Quota ratio\n  weightedPipeline: number; // Sum of (deal value √ó probability)\n  commitRevenue: number; // High-probability deals only\n  \n  // Trends\n  trend: 'improving' | 'stable' | 'declining';\n  trendPercentage: number; // +10% or -5%, etc.\n  \n  // Quota tracking\n  quota?: number;\n  quotaAttainment: number; // 0-100% of quota achieved\n  quotaGap: number; // How much more needed to hit quota\n  \n  // Metadata\n  dealsAnalyzed: number;\n  calculatedAt: Date;\n  forecastDate: Date; // End of forecast period\n}\n\nexport interface StageRevenue {\n  stageName: string;\n  dealCount: number;\n  totalValue: number;\n  weightedValue: number; // Value √ó probability\n  probability: number; // Stage probability\n}\n\nexport type ForecastPeriod = '30-day' | '60-day' | '90-day' | 'quarter' | 'annual';\n\nexport interface ForecastOptions {\n  organizationId: string;\n  workspaceId: string;\n  period: ForecastPeriod;\n  templateId?: string;\n  quota?: number;\n  includeRepBreakdown?: boolean;\n  includeProductBreakdown?: boolean;\n}\n\nexport interface QuotaPerformance {\n  quota: number;\n  achieved: number;\n  attainment: number; // 0-100%\n  gap: number;\n  onTrack: boolean;\n  projectedAttainment: number; // Projected end-of-period attainment\n  daysRemaining: number;\n  requiredDailyRevenue: number; // How much per day to hit quota\n}\n\nexport interface ForecastTrend {\n  current: number;\n  previous: number;\n  change: number; // Dollar change\n  changePercentage: number; // Percentage change\n  direction: 'up' | 'down' | 'flat';\n  momentum: 'accelerating' | 'stable' | 'decelerating';\n}\n\n// ============================================================================\n// MAIN FORECASTING ENGINE\n// ============================================================================\n\n/**\n * Generate revenue forecast\n * \n * This is the main entry point for revenue forecasting.\n * \n * @param options - Forecasting options\n * @returns Comprehensive revenue forecast with confidence intervals\n * \n * @example\n * ```typescript\n * const forecast = await generateRevenueForecast({\n *   organizationId: 'org_123',\n *   workspaceId: 'default',\n *   period: '90-day',\n *   templateId: 'saas',\n *   quota: 500000\n * });\n * \n * console.log(`Forecast: $${forecast.forecast.toLocaleString()}`);\n * console.log(`Quota Attainment: ${forecast.quotaAttainment}%`);\n * ```\n */\nexport async function generateRevenueForecast(\n  options: ForecastOptions\n): Promise<RevenueForecast> {\n  const startTime = Date.now();\n  \n  try {\n    logger.info('Generating revenue forecast', {\n      orgId: options.organizationId,\n      period: options.period,\n      templateId: options.templateId\n    });\n    \n    // 1. Get industry template\n    let template: SalesIndustryTemplate | null = null;\n    if (options.templateId) {\n      template = getTemplateById(options.templateId);\n    }\n    \n    // 2. Fetch deals in pipeline (mock for now)\n    const deals = await fetchPipelineDeals(options.organizationId, options.workspaceId, options.period);\n    \n    // 3. Calculate stage-weighted revenue\n    const byStage = calculateRevenueByStage(deals, template);\n    \n    // 4. Calculate weighted pipeline\n    const weightedPipeline = Array.from(byStage.values())\n      .reduce((sum, stage) => sum + stage.weightedValue, 0);\n    \n    // 5. Calculate commit revenue (high-probability deals only)\n    const commitRevenue = calculateCommitRevenue(deals, template);\n    \n    // 6. Generate forecast scenarios\n    const mostLikely = weightedPipeline;\n    const bestCase = calculateBestCase(weightedPipeline, deals, template);\n    const worstCase = calculateWorstCase(weightedPipeline, deals, template);\n    \n    // 7. Calculate confidence\n    const confidence = calculateForecastConfidence(deals, template);\n    \n    // 8. Analyze trends\n    const trend = await analyzeTrend(options.organizationId, options.workspaceId, mostLikely);\n    \n    // 9. Calculate quota metrics\n    let quotaAttainment = 0;\n    let quotaGap = 0;\n    let pipelineCoverage = 0;\n    \n    if (options.quota) {\n      quotaAttainment = Math.round((mostLikely / options.quota) * 100);\n      quotaGap = options.quota - mostLikely;\n      pipelineCoverage = weightedPipeline / options.quota;\n    }\n    \n    // 10. Calculate forecast date (end of period)\n    const forecastDate = calculateForecastDate(options.period);\n    \n    const forecast: RevenueForecast = {\n      organizationId: options.organizationId,\n      workspaceId: options.workspaceId,\n      period: options.period,\n      forecast: Math.round(mostLikely),\n      bestCase: Math.round(bestCase),\n      worstCase: Math.round(worstCase),\n      confidence,\n      byStage,\n      weightedPipeline: Math.round(weightedPipeline),\n      commitRevenue: Math.round(commitRevenue),\n      pipelineCoverage,\n      trend: trend.direction === 'up' ? 'improving' : trend.direction === 'down' ? 'declining' : 'stable',\n      trendPercentage: trend.changePercentage,\n      quota: options.quota,\n      quotaAttainment,\n      quotaGap,\n      dealsAnalyzed: deals.length,\n      calculatedAt: new Date(),\n      forecastDate\n    };\n    \n    // 11. Emit Signal Bus event\n    try {\n      const coordinator = await getServerSignalCoordinator();\n      await coordinator.emitSignal({\n        type: 'forecast.updated',\n        orgId: options.organizationId,\n        workspaceId: options.workspaceId,\n        confidence: confidence / 100,\n        priority: quotaAttainment < 70 ? 'High' : 'Medium',\n        metadata: {\n          period: options.period,\n          forecast: forecast.forecast,\n          bestCase: forecast.bestCase,\n          worstCase: forecast.worstCase,\n          quotaAttainment,\n          quotaGap,\n          trend: forecast.trend,\n          trendPercentage: forecast.trendPercentage,\n          dealsAnalyzed: deals.length,\n          templateId: options.templateId,\n          timestamp: new Date().toISOString()\n        }\n      });\n      \n      logger.info('Signal emitted: forecast.updated', {\n        orgId: options.organizationId,\n        forecast: forecast.forecast\n      });\n    } catch (signalError) {\n      logger.warn('Failed to emit forecast.updated signal', { error: signalError as unknown });\n    }\n    \n    const duration = Date.now() - startTime;\n    logger.info('Revenue forecast generated', {\n      orgId: options.organizationId,\n      period: options.period,\n      forecast: forecast.forecast,\n      quota: options.quota,\n      attainment: quotaAttainment,\n      duration\n    });\n    \n    return forecast;\n    \n  } catch (error) {\n    logger.error('Revenue forecasting failed', error as Error, {\n      orgId: options.organizationId,\n      period: options.period\n    });\n    throw new Error(`Revenue forecasting failed: ${(error as Error).message}`);\n  }\n}\n\n// ============================================================================\n// CALCULATION FUNCTIONS\n// ============================================================================\n\n/**\n * Calculate revenue breakdown by stage\n */\nfunction calculateRevenueByStage(\n  deals: Deal[],\n  template: SalesIndustryTemplate | null\n): Map<string, StageRevenue> {\n  const byStage = new Map<string, StageRevenue>();\n  \n  deals.forEach(deal => {\n    const stage = (deal as { stage?: string }).stage || 'unknown';\n    const value = deal.value || 0;\n    \n    // Get stage probability from template\n    const stageProbability = template?.stages.find(s => s.id === stage)?.probability || 50;\n    const probability = stageProbability / 100;\n    \n    const existing = byStage.get(stage);\n    if (existing) {\n      existing.dealCount += 1;\n      existing.totalValue += value;\n      existing.weightedValue += value * probability;\n    } else {\n      byStage.set(stage, {\n        stageName: stage,\n        dealCount: 1,\n        totalValue: value,\n        weightedValue: value * probability,\n        probability: stageProbability\n      });\n    }\n  });\n  \n  return byStage;\n}\n\n/**\n * Calculate commit revenue (high-probability deals only)\n * Typically deals with >75% probability\n */\nfunction calculateCommitRevenue(\n  deals: Deal[],\n  template: SalesIndustryTemplate | null\n): number {\n  return deals.reduce((sum, deal) => {\n    const stage = (deal as { stage?: string }).stage || 'unknown';\n    const probability = template?.stages.find(s => s.id === stage)?.probability || 50;\n    \n    // Only count high-probability deals\n    if (probability >= 75) {\n      return sum + (deal.value || 0);\n    }\n    return sum;\n  }, 0);\n}\n\n/**\n * Calculate best case scenario (90th percentile)\n */\nfunction calculateBestCase(\n  weightedPipeline: number,\n  deals: Deal[],\n  template: SalesIndustryTemplate | null\n): number {\n  // Best case assumes higher win rates\n  // Increase weighted pipeline by 20-30%\n  const uplift = 1.25;\n  return weightedPipeline * uplift;\n}\n\n/**\n * Calculate worst case scenario (10th percentile)\n */\nfunction calculateWorstCase(\n  weightedPipeline: number,\n  deals: Deal[],\n  template: SalesIndustryTemplate | null\n): number {\n  // Worst case assumes lower win rates\n  // Decrease weighted pipeline by 20-30%\n  const downside = 0.75;\n  return weightedPipeline * downside;\n}\n\n/**\n * Calculate forecast confidence\n */\nfunction calculateForecastConfidence(\n  deals: Deal[],\n  template: SalesIndustryTemplate | null\n): number {\n  let confidence = 60; // Base confidence\n  \n  // More deals = higher confidence\n  if (deals.length >= 50) {confidence += 20;}\n  else if (deals.length >= 20) {confidence += 15;}\n  else if (deals.length >= 10) {confidence += 10;}\n  else if (deals.length < 5) {confidence -= 20;}\n  \n  // Pipeline diversity = higher confidence\n  const stageSet = new Set(deals.map(d => (d as { stage?: string }).stage));\n  if (stageSet.size >= 4) {confidence += 10;}\n  \n  // Template available = higher confidence\n  if (template) {confidence += 10;}\n  \n  return Math.min(100, Math.max(0, confidence));\n}\n\n/**\n * Analyze trend compared to previous period\n */\nasync function analyzeTrend(\n  orgId: string,\n  workspaceId: string,\n  currentForecast: number\n): Promise<ForecastTrend> {\n  // Mock: simulate previous period forecast\n  const previousForecast = currentForecast * (0.8 + Math.random() * 0.4); // 80%-120% of current\n  \n  const change = currentForecast - previousForecast;\n  const changePercentage = Math.round((change / previousForecast) * 100);\n  \n  let direction: 'up' | 'down' | 'flat' = 'flat';\n  if (changePercentage > 5) {direction = 'up';}\n  else if (changePercentage < -5) {direction = 'down';}\n  \n  let momentum: 'accelerating' | 'stable' | 'decelerating' = 'stable';\n  if (Math.abs(changePercentage) > 15) {\n    momentum = changePercentage > 0 ? 'accelerating' : 'decelerating';\n  }\n  \n  return {\n    current: currentForecast,\n    previous: previousForecast,\n    change,\n    changePercentage,\n    direction,\n    momentum\n  };\n}\n\n/**\n * Calculate end date for forecast period\n */\nfunction calculateForecastDate(period: ForecastPeriod): Date {\n  const now = new Date();\n  \n  switch (period) {\n    case '30-day':\n      return new Date(now.getTime() + 30 * 24 * 60 * 60 * 1000);\n    case '60-day':\n      return new Date(now.getTime() + 60 * 24 * 60 * 60 * 1000);\n    case '90-day':\n      return new Date(now.getTime() + 90 * 24 * 60 * 60 * 1000);\n    case 'quarter':\n      // End of current quarter\n      const quarter = Math.floor(now.getMonth() / 3);\n      const quarterEnd = new Date(now.getFullYear(), (quarter + 1) * 3, 0);\n      return quarterEnd;\n    case 'annual':\n      return new Date(now.getFullYear(), 11, 31);\n    default:\n      return new Date(now.getTime() + 90 * 24 * 60 * 60 * 1000);\n  }\n}\n\n/**\n * Mock function to fetch pipeline deals\n */\nasync function fetchPipelineDeals(\n  orgId: string,\n  workspaceId: string,\n  period: ForecastPeriod\n): Promise<Deal[]> {\n  // Mock: generate sample deals\n  const dealCount = Math.floor(Math.random() * 20) + 10; // 10-30 deals\n  const deals: Deal[] = [];\n  \n  const stages = ['discovery', 'demo', 'proposal', 'negotiation'];\n  \n  for (let i = 0; i < dealCount; i++) {\n    const stage = stages[Math.floor(Math.random() * stages.length)];\n    const value = Math.floor(Math.random() * 100000) + 10000; // $10K-$110K\n    \n    deals.push({\n      id: `deal_${i}`,\n      organizationId: orgId,\n      value,\n      createdAt: new Date(Date.now() - Math.random() * 60 * 24 * 60 * 60 * 1000),\n      updatedAt: new Date(),\n      stage\n    } as Deal);\n  }\n  \n  return deals;\n}\n\n// ============================================================================\n// QUOTA TRACKING\n// ============================================================================\n\n/**\n * Calculate quota performance\n */\nexport async function calculateQuotaPerformance(\n  organizationId: string,\n  workspaceId: string,\n  period: ForecastPeriod,\n  quota: number,\n  templateId?: string\n): Promise<QuotaPerformance> {\n  try {\n    // Generate forecast\n    const forecast = await generateRevenueForecast({\n      organizationId,\n      workspaceId,\n      period,\n      quota,\n      templateId\n    });\n    \n    // Calculate days remaining\n    const now = new Date();\n    const endDate = forecast.forecastDate;\n    const daysRemaining = Math.ceil((endDate.getTime() - now.getTime()) / (1000 * 60 * 60 * 24));\n    \n    // Calculate required daily revenue\n    const gap = forecast.quotaGap > 0 ? forecast.quotaGap : 0;\n    const requiredDailyRevenue = daysRemaining > 0 ? gap / daysRemaining : 0;\n    \n    // Project end-of-period attainment\n    const trend = forecast.trendPercentage / 100;\n    const projectedAttainment = forecast.quotaAttainment * (1 + trend);\n    \n    const performance: QuotaPerformance = {\n      quota,\n      achieved: forecast.forecast,\n      attainment: forecast.quotaAttainment,\n      gap,\n      onTrack: forecast.quotaAttainment >= 70, // 70%+ is \"on track\"\n      projectedAttainment: Math.round(projectedAttainment),\n      daysRemaining,\n      requiredDailyRevenue: Math.round(requiredDailyRevenue)\n    };\n    \n    logger.info('Quota performance calculated', {\n      orgId: organizationId,\n      quota,\n      attainment: performance.attainment,\n      onTrack: performance.onTrack\n    });\n    \n    return performance;\n    \n  } catch (error) {\n    logger.error('Quota performance calculation failed', error as Error, {\n      orgId: organizationId\n    });\n    throw new Error(`Quota performance calculation failed: ${(error as Error).message}`);\n  }\n}\n\n// ============================================================================\n// FORECAST COMPARISON\n// ============================================================================\n\n/**\n * Compare forecasts across multiple periods\n */\nexport async function compareForecastPeriods(\n  organizationId: string,\n  workspaceId: string,\n  periods: ForecastPeriod[],\n  templateId?: string\n): Promise<Map<ForecastPeriod, RevenueForecast>> {\n  const forecasts = new Map<ForecastPeriod, RevenueForecast>();\n  \n  for (const period of periods) {\n    try {\n      const forecast = await generateRevenueForecast({\n        organizationId,\n        workspaceId,\n        period,\n        templateId\n      });\n      forecasts.set(period, forecast);\n    } catch (error) {\n      logger.warn('Failed to generate forecast for period', { period, error });\n    }\n  }\n  \n  return forecasts;\n}\n\n/**\n * Get forecast history for trend analysis\n */\nexport async function getForecastHistory(\n  organizationId: string,\n  workspaceId: string,\n  period: ForecastPeriod,\n  months: number = 6\n): Promise<Array<{\n  date: Date;\n  forecast: number;\n  actual?: number;\n  accuracy?: number;\n}>> {\n  // Mock implementation - would fetch from historical data\n  const history: Array<{ date: Date; forecast: number; actual?: number; accuracy?: number }> = [];\n  \n  for (let i = months; i >= 0; i--) {\n    const date = new Date();\n    date.setMonth(date.getMonth() - i);\n    \n    const forecast = Math.floor(Math.random() * 200000) + 100000; // $100K-$300K\n    const actual = i > 0 ? Math.floor(forecast * (0.8 + Math.random() * 0.4)) : undefined;\n    const accuracy = actual ? Math.round((1 - Math.abs(forecast - actual) / forecast) * 100) : undefined;\n    \n    history.push({ date, forecast, actual, accuracy });\n  }\n  \n  return history;\n}\n\nlogger.info('Revenue Forecasting Engine initialized');\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\utils\\retry.ts","messages":[{"ruleId":"no-useless-catch","severity":2,"message":"Unnecessary try/catch wrapper.","line":336,"column":3,"nodeType":"TryStatement","messageId":"unnecessaryCatch","endLine":353,"endColumn":4}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Retry Utility with Exponential Backoff\n * \n * Provides retry logic for operations that may fail transiently,\n * such as API calls, database operations, and LLM requests.\n * \n * Features:\n * - Exponential backoff with jitter\n * - Configurable max retries and delays\n * - Custom retry conditions\n * - Request cancellation support (AbortController)\n * - Detailed error logging\n * \n * Usage:\n * ```typescript\n * const result = await retryWithBackoff(\n *   async () => await callOpenAI(prompt),\n *   {\n *     maxRetries: 3,\n *     baseDelayMs: 1000,\n *     maxDelayMs: 10000,\n *     shouldRetry: (error) => error.status === 429 || error.status >= 500\n *   }\n * );\n * ```\n */\n\nimport { logger } from '@/lib/logger/logger';\n\n// ============================================================================\n// TYPES\n// ============================================================================\n\nexport interface RetryOptions<T = any> {\n  /** Maximum number of retry attempts (default: 3) */\n  maxRetries?: number;\n  \n  /** Base delay between retries in milliseconds (default: 1000) */\n  baseDelayMs?: number;\n  \n  /** Maximum delay between retries in milliseconds (default: 30000 = 30s) */\n  maxDelayMs?: number;\n  \n  /** Custom function to determine if error should trigger retry */\n  shouldRetry?: (error: any, attempt: number) => boolean;\n  \n  /** Callback called before each retry */\n  onRetry?: (error: any, attempt: number, delayMs: number) => void;\n  \n  /** AbortSignal for cancellation support */\n  signal?: AbortSignal;\n  \n  /** Operation name for logging (default: 'operation') */\n  operationName?: string;\n  \n  /** Whether to add jitter to delay (default: true) */\n  addJitter?: boolean;\n}\n\nexport interface RetryResult<T> {\n  /** Result of the operation */\n  result: T;\n  \n  /** Number of attempts made */\n  attempts: number;\n  \n  /** Total time spent in milliseconds */\n  totalTimeMs: number;\n  \n  /** Whether operation succeeded */\n  success: boolean;\n}\n\n// ============================================================================\n// RETRY FUNCTIONS\n// ============================================================================\n\n/**\n * Retry an async operation with exponential backoff\n * \n * @param operation - Async function to retry\n * @param options - Retry configuration\n * @returns Result of the operation\n * @throws Last error if all retries exhausted\n */\nexport async function retryWithBackoff<T>(\n  operation: () => Promise<T>,\n  options: RetryOptions<T> = {}\n): Promise<T> {\n  const {\n    maxRetries = 3,\n    baseDelayMs = 1000,\n    maxDelayMs = 30000,\n    shouldRetry = defaultShouldRetry,\n    onRetry,\n    signal,\n    operationName = 'operation',\n    addJitter = true\n  } = options;\n  \n  const startTime = Date.now();\n  let lastError: any;\n  \n  for (let attempt = 0; attempt <= maxRetries; attempt++) {\n    try {\n      // Check if operation was cancelled\n      if (signal?.aborted) {\n        throw new Error('Operation cancelled');\n      }\n      \n      // Execute operation\n      const result = await operation();\n      \n      // Log success if retries were needed\n      if (attempt > 0) {\n        logger.info(`${operationName} succeeded after ${attempt} retries`, {\n          attempts: attempt + 1,\n          totalTimeMs: Date.now() - startTime\n        });\n      }\n      \n      return result;\n      \n    } catch (error) {\n      lastError = error;\n      \n      // Check if we should retry\n      const isLastAttempt = attempt === maxRetries;\n      const shouldRetryError = shouldRetry(error, attempt);\n      \n      if (isLastAttempt || !shouldRetryError) {\n        // Log final failure\n        logger.error(`${operationName} failed after ${attempt + 1} attempts`, error as Error, {\n          attempts: attempt + 1,\n          totalTimeMs: Date.now() - startTime\n        });\n        throw error;\n      }\n      \n      // Calculate delay with exponential backoff\n      const exponentialDelay = Math.min(\n        baseDelayMs * Math.pow(2, attempt),\n        maxDelayMs\n      );\n      \n      // Add jitter to prevent thundering herd\n      const jitter = addJitter ? Math.random() * 0.3 * exponentialDelay : 0;\n      const delayMs = exponentialDelay + jitter;\n      \n      // Call retry callback\n      if (onRetry) {\n        onRetry(error, attempt + 1, delayMs);\n      }\n      \n      // Log retry attempt\n      logger.warn(`${operationName} failed, retrying in ${Math.round(delayMs)}ms`, {\n        attempt: attempt + 1,\n        maxRetries,\n        error: error instanceof Error ? error.message : String(error)\n      });\n      \n      // Wait before retrying\n      await sleep(delayMs, signal);\n    }\n  }\n  \n  // This should never be reached, but TypeScript requires it\n  throw lastError;\n}\n\n/**\n * Default retry condition - retry on network errors and 5xx status codes\n */\nfunction defaultShouldRetry(error: any, attempt: number): boolean {\n  // Never retry after max attempts\n  if (attempt >= 10) {\n    return false;\n  }\n  \n  // Retry on network errors\n  if (\n    error.code === 'ECONNRESET' ||\n    error.code === 'ETIMEDOUT' ||\n    error.code === 'ENOTFOUND' ||\n    error.message?.includes('network') ||\n    error.message?.includes('timeout')\n  ) {\n    return true;\n  }\n  \n  // Retry on rate limits (429)\n  if (error.status === 429 || error.statusCode === 429) {\n    return true;\n  }\n  \n  // Retry on server errors (5xx)\n  if (error.status >= 500 || error.statusCode >= 500) {\n    return true;\n  }\n  \n  // Don't retry on client errors (4xx, except 429)\n  if ((error.status >= 400 && error.status < 500) || \n      (error.statusCode >= 400 && error.statusCode < 500)) {\n    return false;\n  }\n  \n  // Retry on unknown errors\n  return true;\n}\n\n/**\n * Sleep for specified duration with cancellation support\n */\nfunction sleep(ms: number, signal?: AbortSignal): Promise<void> {\n  return new Promise((resolve, reject) => {\n    // Handle cancellation\n    if (signal?.aborted) {\n      reject(new Error('Sleep cancelled'));\n      return;\n    }\n    \n    const timeoutId = setTimeout(resolve, ms);\n    \n    // Listen for cancellation\n    if (signal) {\n      signal.addEventListener('abort', () => {\n        clearTimeout(timeoutId);\n        reject(new Error('Sleep cancelled'));\n      }, { once: true });\n    }\n  });\n}\n\n// ============================================================================\n// LLM-SPECIFIC RETRY PRESETS\n// ============================================================================\n\n/**\n * Retry options for OpenAI API calls\n */\nexport const OpenAIRetryOptions: RetryOptions = {\n  maxRetries: 3,\n  baseDelayMs: 1000,\n  maxDelayMs: 10000,\n  operationName: 'OpenAI API call',\n  shouldRetry: (error, attempt) => {\n    // Retry on rate limits\n    if (error.status === 429 || error.statusCode === 429) {\n      return true;\n    }\n    \n    // Retry on server errors\n    if (error.status >= 500 || error.statusCode >= 500) {\n      return true;\n    }\n    \n    // Retry on timeout\n    if (error.code === 'ETIMEDOUT' || error.message?.includes('timeout')) {\n      return true;\n    }\n    \n    // Don't retry on invalid requests\n    if (error.status === 400 || error.status === 401 || error.status === 403) {\n      return false;\n    }\n    \n    // Retry on unknown errors (but limit attempts)\n    return attempt < 3;\n  }\n};\n\n/**\n * Retry options for general LLM calls\n */\nexport const LLMRetryOptions: RetryOptions = {\n  maxRetries: 3,\n  baseDelayMs: 2000,\n  maxDelayMs: 15000,\n  operationName: 'LLM call',\n  shouldRetry: (error, attempt) => {\n    // Retry on rate limits and server errors\n    return (\n      error.status === 429 ||\n      error.status >= 500 ||\n      error.code === 'ETIMEDOUT' ||\n      (attempt < 3 && !error.status)\n    );\n  }\n};\n\n/**\n * Retry options for database operations\n */\nexport const DatabaseRetryOptions: RetryOptions = {\n  maxRetries: 5,\n  baseDelayMs: 500,\n  maxDelayMs: 5000,\n  operationName: 'Database operation',\n  shouldRetry: (error, attempt) => {\n    // Retry on deadlocks and timeouts\n    return (\n      error.code === 'ECONNRESET' ||\n      error.code === 'ETIMEDOUT' ||\n      error.message?.includes('deadlock') ||\n      error.message?.includes('timeout') ||\n      (attempt < 5 && !error.status)\n    );\n  }\n};\n\n/**\n * Retry options for external API calls\n */\nexport const ExternalAPIRetryOptions: RetryOptions = {\n  maxRetries: 3,\n  baseDelayMs: 1000,\n  maxDelayMs: 10000,\n  operationName: 'External API call',\n  shouldRetry: defaultShouldRetry\n};\n\n// ============================================================================\n// HELPER FUNCTIONS\n// ============================================================================\n\n/**\n * Retry with exponential backoff and return detailed result\n */\nexport async function retryWithBackoffDetailed<T>(\n  operation: () => Promise<T>,\n  options: RetryOptions<T> = {}\n): Promise<RetryResult<T>> {\n  const startTime = Date.now();\n  let attempts = 0;\n  \n  try {\n    const result = await retryWithBackoff(\n      async () => {\n        attempts++;\n        return operation();\n      },\n      options\n    );\n    \n    return {\n      result,\n      attempts,\n      totalTimeMs: Date.now() - startTime,\n      success: true\n    };\n  } catch (error) {\n    throw error;\n  }\n}\n\n/**\n * Create an AbortController with timeout\n */\nexport function createAbortControllerWithTimeout(timeoutMs: number): AbortController {\n  const controller = new AbortController();\n  \n  setTimeout(() => {\n    controller.abort();\n  }, timeoutMs);\n  \n  return controller;\n}\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\workflows\\actions\\conditional-action.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":100,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":100,"endColumn":84},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":105,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":105,"endColumn":81},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":162,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":162,"endColumn":109},{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":165,"column":7,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":165,"endColumn":112}],"suppressedMessages":[],"errorCount":4,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Conditional Action Executor\n * Executes conditional logic in workflows\n */\n\nimport type { ConditionalBranchAction, WorkflowCondition, WorkflowAction } from '@/types/workflow';\n\n/**\n * Execute conditional action\n */\nexport async function executeConditionalAction(\n  action: ConditionalBranchAction,\n  triggerData: any,\n  workflow: any,\n  organizationId: string\n): Promise<any> {\n  // Evaluate all branches\n  let matchedBranch: ConditionalBranchAction['branches'][0] | null = null;\n  \n  for (const branch of action.branches) {\n    const conditionsMet = await evaluateConditions(branch.conditions, triggerData, branch.conditionOperator);\n    if (conditionsMet) {\n      matchedBranch = branch;\n      break;\n    }\n  }\n  \n  // Execute matched branch or default branch\n  const actionsToExecute = matchedBranch ? matchedBranch.actions : (action.defaultBranch || []);\n  const conditionMet = matchedBranch !== null;\n  \n  if (!actionsToExecute || actionsToExecute.length === 0) {\n    return {\n      conditionMet,\n      executed: false,\n      message: `No actions defined for ${conditionMet ? 'matched' : 'default'} branch`,\n    };\n  }\n  \n  // Execute actions in sequence\n  const results = [];\n  \n  for (const subAction of actionsToExecute) {\n    try {\n      const result = await executeAction(subAction, triggerData, workflow, organizationId);\n      results.push({\n        actionId: subAction.id,\n        success: true,\n        result,\n      });\n    } catch (error: any) {\n      results.push({\n        actionId: subAction.id,\n        success: false,\n        error: error.message,\n      });\n      // Stop on first error (can be made configurable)\n      break;\n    }\n  }\n  \n  return {\n    conditionMet: matchedBranch !== null,\n    executed: true,\n    results,\n  };\n}\n\n/**\n * Evaluate conditions\n */\nasync function evaluateConditions(\n  conditions: WorkflowCondition[],\n  triggerData: any,\n  operator: 'and' | 'or'\n): Promise<boolean> {\n  const results = conditions.map(condition => evaluateCondition(condition, triggerData));\n  \n  if (operator === 'and') {\n    return results.every(r => r);\n  } else {\n    return results.some(r => r);\n  }\n}\n\n/**\n * Evaluate single condition\n */\nfunction evaluateCondition(condition: WorkflowCondition, triggerData: any): boolean {\n  // Get value based on source\n  let fieldValue: any;\n  \n  switch (condition.source) {\n    case 'trigger_data':\n      fieldValue = getNestedValue(triggerData, condition.field);\n      break;\n    case 'entity':\n      // Query entity from trigger data context\n      // The entity data should be populated in triggerData.entity or triggerData.entities\n      const entityData = triggerData?.entity || triggerData?.record || triggerData;\n      fieldValue = getNestedValue(entityData, condition.field);\n      break;\n    case 'variable':\n      // Get from workflow variables stored in triggerData._variables\n      const variables = triggerData?._variables || triggerData?.variables || {};\n      fieldValue = getNestedValue(variables, condition.field);\n      break;\n    case 'date':\n      // Handle date comparisons\n      if (condition.field === 'now') {\n        fieldValue = new Date();\n      } else if (condition.field === 'today') {\n        const today = new Date();\n        today.setHours(0, 0, 0, 0);\n        fieldValue = today;\n      } else {\n        fieldValue = new Date(getNestedValue(triggerData, condition.field));\n      }\n      break;\n    default:\n      fieldValue = null;\n  }\n  \n  // Compare based on operator\n  switch (condition.operator) {\n    case 'equals':\n      // Handle date comparison\n      if (fieldValue instanceof Date && condition.value) {\n        const compareDate = new Date(condition.value as string);\n        return fieldValue.getTime() === compareDate.getTime();\n      }\n      return fieldValue === condition.value;\n    case 'not_equals':\n      return fieldValue !== condition.value;\n    case 'contains':\n      return String(fieldValue || '').toLowerCase().includes(String(condition.value || '').toLowerCase());\n    case 'not_contains':\n      return !String(fieldValue || '').toLowerCase().includes(String(condition.value || '').toLowerCase());\n    case 'greater_than':\n      if (fieldValue instanceof Date && condition.value) {\n        return fieldValue.getTime() > new Date(condition.value as string).getTime();\n      }\n      return Number(fieldValue) > Number(condition.value);\n    case 'less_than':\n      if (fieldValue instanceof Date && condition.value) {\n        return fieldValue.getTime() < new Date(condition.value as string).getTime();\n      }\n      return Number(fieldValue) < Number(condition.value);\n    case 'greater_than_or_equal':\n      return Number(fieldValue) >= Number(condition.value);\n    case 'less_than_or_equal':\n      return Number(fieldValue) <= Number(condition.value);\n    case 'exists':\n      return fieldValue !== undefined && fieldValue !== null && fieldValue !== '';\n    case 'not_exists':\n      return fieldValue === undefined || fieldValue === null || fieldValue === '';\n    case 'starts_with':\n      return String(fieldValue || '').toLowerCase().startsWith(String(condition.value || '').toLowerCase());\n    case 'ends_with':\n      return String(fieldValue || '').toLowerCase().endsWith(String(condition.value || '').toLowerCase());\n    case 'in':\n      const inArray = Array.isArray(condition.value) ? condition.value : String(condition.value).split(',');\n      return inArray.includes(fieldValue);\n    case 'not_in':\n      const notInArray = Array.isArray(condition.value) ? condition.value : String(condition.value).split(',');\n      return !notInArray.includes(fieldValue);\n    case 'is_empty':\n      return !fieldValue || (Array.isArray(fieldValue) && fieldValue.length === 0);\n    case 'is_not_empty':\n      return fieldValue && (!Array.isArray(fieldValue) || fieldValue.length > 0);\n    default:\n      return false;\n  }\n}\n\n/**\n * Execute a single action (helper)\n */\nasync function executeAction(\n  action: WorkflowAction,\n  triggerData: any,\n  workflow: any,\n  organizationId: string\n): Promise<any> {\n  // Import action executors\n  const { executeEmailAction } = await import('./email-action');\n  const { executeSMSAction } = await import('./sms-action');\n  const { executeEntityAction } = await import('./entity-action');\n  const { executeHTTPAction } = await import('./http-action');\n  const { executeDelayAction } = await import('./delay-action');\n  \n  switch (action.type) {\n    case 'send_email':\n      return executeEmailAction(action, triggerData, organizationId);\n    case 'send_sms':\n      return executeSMSAction(action, triggerData, organizationId);\n    case 'create_entity':\n    case 'update_entity':\n    case 'delete_entity':\n      return executeEntityAction(action, triggerData, organizationId);\n    case 'http_request':\n      return executeHTTPAction(action, triggerData);\n    case 'delay':\n      return executeDelayAction(action, triggerData);\n    default:\n      throw new Error(`Unknown action type: ${action.type}`);\n  }\n}\n\n/**\n * Get nested value from object using dot notation\n */\nfunction getNestedValue(obj: any, path: string): any {\n  return path.split('.').reduce((current, key) => current?.[key], obj);\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\workflows\\actions\\entity-action.ts","messages":[{"ruleId":"no-case-declarations","severity":2,"message":"Unexpected lexical declaration in case block.","line":65,"column":9,"nodeType":"VariableDeclaration","messageId":"unexpected","endLine":65,"endColumn":83}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Entity Action Executor\n * Executes entity CRUD actions in workflows\n */\n\nimport { FirestoreService, COLLECTIONS } from '@/lib/db/firestore-service';\nimport type { CreateEntityAction, UpdateEntityAction, DeleteEntityAction } from '@/types/workflow';\nimport type { Schema } from '@/types/schema';\nimport { logger } from '@/lib/logger/logger';\n\n/**\n * Execute create entity action\n */\nexport async function executeCreateEntityAction(\n  action: CreateEntityAction,\n  triggerData: any,\n  organizationId: string,\n  workspaceId: string\n): Promise<any> {\n  // Get schema for field resolution\n  const { FirestoreService: FS, COLLECTIONS: COL } = await import('@/lib/db/firestore-service');\n  const schemaData = await FS.get(\n    `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/${COL.SCHEMAS}`,\n    action.schemaId\n  );\n  \n  if (!schemaData) {\n    throw new Error(`Schema ${action.schemaId} not found`);\n  }\n  \n  const schema = schemaData as Schema;\n  \n  // Build entity data from field mappings with dynamic field resolution\n  const entityData: Record<string, any> = {};\n  \n  for (const mapping of action.fieldMappings) {\n    let value: any;\n    \n    // Resolve target field using field resolver\n    const { FieldResolver } = await import('@/lib/schema/field-resolver');\n    const resolvedTarget = await FieldResolver.resolveFieldWithCommonAliases(\n      schema,\n      mapping.targetField\n    );\n    \n    if (!resolvedTarget) {\n      logger.warn('[Entity Action] Target field not found in schema', {\n        file: 'entity-action.ts',\n        targetField: mapping.targetField,\n        schemaId: action.schemaId,\n      });\n      continue; // Skip this mapping\n    }\n    \n    switch (mapping.source) {\n      case 'static':\n        value = mapping.staticValue;\n        break;\n      case 'trigger':\n        // Use field resolver to get value with flexible matching\n        value = FieldResolver.getFieldValue(triggerData, mapping.sourceField || '');\n        break;\n      case 'variable':\n        // Get from workflow variables stored in triggerData._variables\n        const variables = triggerData?._variables || triggerData?.variables || {};\n        value = FieldResolver.getFieldValue(variables, mapping.sourceField || '');\n        // Fallback to trigger data if not found in variables\n        if (value === undefined) {\n          value = FieldResolver.getFieldValue(triggerData, mapping.sourceField || '');\n        }\n        break;\n      case 'ai':\n        // Generate using AI\n        value = await generateWithAI({\n          organizationId,\n          field: resolvedTarget.fieldKey,\n          prompt: mapping.aiPrompt || `Generate a value for field \"${resolvedTarget.fieldLabel}\"`,\n          context: triggerData,\n        });\n        break;\n      default:\n        value = null;\n    }\n    \n    // Apply transform if specified\n    if (mapping.transform && value !== null && value !== undefined) {\n      value = applyTransform(value, mapping.transform);\n    }\n    \n    // Use resolved field key instead of original reference\n    entityData[resolvedTarget.fieldKey] = value;\n  }\n  \n  const entityName = (schema as any).name || action.schemaId;\n  const entityPath = `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/entities/${entityName}`;\n  \n  const recordId = `rec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n  await FS.set(entityPath, recordId, {\n    ...entityData,\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n  }, false);\n  \n  return { recordId, success: true };\n}\n\n/**\n * Execute update entity action\n */\nexport async function executeUpdateEntityAction(\n  action: UpdateEntityAction,\n  triggerData: any,\n  organizationId: string,\n  workspaceId: string\n): Promise<any> {\n  // Get schema\n  const { FirestoreService: FS, COLLECTIONS: COL } = await import('@/lib/db/firestore-service');\n  const schemaData = await FS.get(\n    `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/${COL.SCHEMAS}`,\n    action.schemaId\n  );\n  \n  if (!schemaData) {\n    throw new Error(`Schema ${action.schemaId} not found`);\n  }\n  \n  const schema = schemaData as Schema;\n  const entityName = schema.name || action.schemaId;\n  const entityPath = `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/entities/${entityName}`;\n  \n  // Determine which record(s) to update\n  let recordIds: string[] = [];\n  \n  if (action.targetRecord === 'trigger') {\n    const triggerRecordId = triggerData?.recordId || triggerData?.id;\n    if (!triggerRecordId) {\n      throw new Error('No record ID in trigger data');\n    }\n    recordIds = [triggerRecordId];\n  } else if (action.targetRecord === 'specific' && action.entityId) {\n    recordIds = [action.entityId];\n  } else if (action.targetRecord === 'query' && action.query) {\n    // Query entities matching the criteria\n    const queryResults = await queryEntities({\n      entityPath,\n      query: action.query,\n      triggerData,\n    });\n    recordIds = queryResults.map((r: any) => r.id);\n    if (recordIds.length === 0) {\n      throw new Error('No records found matching query');\n    }\n  }\n  \n  // Build update data from field mappings with dynamic field resolution\n  const updateData: Record<string, any> = {};\n  const { FieldResolver } = await import('@/lib/schema/field-resolver');\n  \n  for (const mapping of action.fieldMappings) {\n    let value: any;\n    \n    // Resolve target field\n    const resolvedTarget = await FieldResolver.resolveFieldWithCommonAliases(\n      schema,\n      mapping.targetField\n    );\n    \n    if (!resolvedTarget) {\n      logger.warn('[Entity Action] Target field not found in schema for update', {\n        file: 'entity-action.ts',\n        targetField: mapping.targetField,\n        schemaId: action.schemaId,\n      });\n      continue;\n    }\n    \n    switch (mapping.source) {\n      case 'static':\n        value = mapping.staticValue;\n        break;\n      case 'trigger':\n        value = FieldResolver.getFieldValue(triggerData, mapping.sourceField || '');\n        break;\n      default:\n        value = null;\n    }\n    \n    if (mapping.transform && value !== null && value !== undefined) {\n      value = applyTransform(value, mapping.transform);\n    }\n    \n    updateData[resolvedTarget.fieldKey] = value;\n  }\n  \n  // Update records\n  for (const recordId of recordIds) {\n    const existing = await FS.get(entityPath, recordId);\n    if (!existing) {\n      throw new Error(`Record ${recordId} not found`);\n    }\n    \n    await FS.set(entityPath, recordId, {\n      ...existing,\n      ...updateData,\n      updatedAt: new Date().toISOString(),\n    }, false);\n  }\n  \n  return { recordIds, success: true };\n}\n\n/**\n * Execute delete entity action\n */\nexport async function executeDeleteEntityAction(\n  action: DeleteEntityAction,\n  triggerData: any,\n  organizationId: string,\n  workspaceId: string\n): Promise<any> {\n  // Get schema\n  const { FirestoreService: FS, COLLECTIONS: COL } = await import('@/lib/db/firestore-service');\n  const schemaData = await FS.get(\n    `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/${COL.SCHEMAS}`,\n    action.schemaId\n  );\n  \n  if (!schemaData) {\n    throw new Error(`Schema ${action.schemaId} not found`);\n  }\n  \n  const schema = schemaData as Schema;\n  const entityName = schema.name || action.schemaId;\n  const entityPath = `${COL.ORGANIZATIONS}/${organizationId}/${COL.WORKSPACES}/${workspaceId}/entities/${entityName}`;\n  \n  // Determine which record(s) to delete\n  let recordIds: string[] = [];\n  \n  if (action.targetRecord === 'trigger') {\n    const triggerRecordId = triggerData?.recordId || triggerData?.id;\n    if (!triggerRecordId) {\n      throw new Error('No record ID in trigger data');\n    }\n    recordIds = [triggerRecordId];\n  } else if (action.targetRecord === 'specific' && action.entityId) {\n    recordIds = [action.entityId];\n  } else if (action.targetRecord === 'query' && action.query) {\n    // Query entities matching the criteria\n    const queryResults = await queryEntities({\n      entityPath,\n      query: action.query,\n      triggerData,\n    });\n    recordIds = queryResults.map((r: any) => r.id);\n    if (recordIds.length === 0) {\n      logger.info('[Entity Action] No records found matching query for delete', { file: 'entity-action.ts' });\n      return { recordIds: [], success: true, message: 'No records matched query' };\n    }\n  }\n  \n  // Delete records\n  for (const recordId of recordIds) {\n    if (action.softDelete) {\n      // Soft delete: mark as deleted\n      const existing = await FS.get(entityPath, recordId);\n      if (existing) {\n        await FS.set(entityPath, recordId, {\n          ...existing,\n          deleted: true,\n          deletedAt: new Date().toISOString(),\n          updatedAt: new Date().toISOString(),\n        }, false);\n      }\n    } else {\n      // Hard delete\n      await FS.delete(entityPath, recordId);\n    }\n  }\n  \n  return { recordIds, success: true };\n}\n\n/**\n * Execute entity action (router)\n */\nexport async function executeEntityAction(\n  action: CreateEntityAction | UpdateEntityAction | DeleteEntityAction,\n  triggerData: any,\n  organizationId: string\n): Promise<any> {\n  const workspaceId = triggerData?.workspaceId || (action as any).workspaceId;\n  if (!workspaceId) {\n    throw new Error('Workspace ID required for entity actions');\n  }\n  \n  if (action.type === 'create_entity') {\n    return executeCreateEntityAction(action, triggerData, organizationId, workspaceId);\n  } else if (action.type === 'update_entity') {\n    return executeUpdateEntityAction(action, triggerData, organizationId, workspaceId);\n  } else if (action.type === 'delete_entity') {\n    return executeDeleteEntityAction(action, triggerData, organizationId, workspaceId);\n  } else {\n    const actionType = (action as any).type;\n    throw new Error(`Unknown entity action type: ${actionType}`);\n  }\n}\n\n/**\n * Apply field transform\n */\nfunction applyTransform(value: any, transform: any): any {\n  switch (transform.type) {\n    case 'uppercase':\n      return String(value).toUpperCase();\n    case 'lowercase':\n      return String(value).toLowerCase();\n    case 'trim':\n      return String(value).trim();\n    default:\n      return value;\n  }\n}\n\n/**\n * Resolve variables in config\n */\nfunction resolveVariables(config: any, triggerData: any): any {\n  if (typeof config === 'string') {\n    return config.replace(/\\{\\{([^}]+)\\}\\}/g, (match, path) => {\n      const value = getNestedValue(triggerData, path.trim());\n      return value !== undefined ? String(value) : match;\n    });\n  } else if (Array.isArray(config)) {\n    return config.map(item => resolveVariables(item, triggerData));\n  } else if (config && typeof config === 'object') {\n    const resolved: any = {};\n    for (const key in config) {\n      resolved[key] = resolveVariables(config[key], triggerData);\n    }\n    return resolved;\n  }\n  return config;\n}\n\n/**\n * Get nested value from object using dot notation\n */\nfunction getNestedValue(obj: any, path: string): any {\n  return path.split('.').reduce((current, key) => current?.[key], obj);\n}\n\n/**\n * Generate value using AI\n */\nasync function generateWithAI(params: {\n  organizationId: string;\n  field: string;\n  prompt: string;\n  context: any;\n}): Promise<string> {\n  const { organizationId, field, prompt, context } = params;\n  \n  try {\n    const { sendUnifiedChatMessage } = await import('@/lib/ai/unified-ai-service');\n    \n    // Build context-aware prompt\n    const fullPrompt = `You are helping generate data for a workflow automation.\n\nField to generate: ${field}\nInstructions: ${prompt}\n\nContext data:\n${JSON.stringify(context, null, 2).slice(0, 2000)}\n\nGenerate ONLY the value for this field. Do not include any explanation or formatting - just the raw value.`;\n\n    const response = await sendUnifiedChatMessage({\n      model: 'gpt-4-turbo',\n      messages: [{ role: 'user', content: fullPrompt }],\n      temperature: 0.7,\n      maxTokens: 500,\n    });\n    \n    return response.text.trim();\n  } catch (error) {\n    logger.error('[Entity Action] AI generation failed:', error, { file: 'entity-action.ts' });\n    return `[AI Error: ${error}]`;\n  }\n}\n\n/**\n * Query entities based on criteria\n */\nasync function queryEntities(params: {\n  entityPath: string;\n  query: any;\n  triggerData: any;\n}): Promise<any[]> {\n  const { entityPath, query, triggerData } = params;\n  const { FirestoreService: FS } = await import('@/lib/db/firestore-service');\n  \n  // Build Firestore query from criteria\n  const filters: any[] = [];\n  \n  if (query.filters && Array.isArray(query.filters)) {\n    for (const filter of query.filters) {\n      let value = filter.value;\n      \n      // Resolve dynamic values\n      if (typeof value === 'string' && value.startsWith('{{') && value.endsWith('}}')) {\n        const path = value.slice(2, -2).trim();\n        value = getNestedValue(triggerData, path);\n      }\n      \n      filters.push({\n        field: filter.field,\n        operator: mapOperator(filter.operator),\n        value,\n      });\n    }\n  }\n  \n  // Get matching records\n  const results = await FS.getAll(entityPath, filters);\n  \n  // Apply limit if specified\n  if (query.limit && typeof query.limit === 'number') {\n    return results.slice(0, query.limit);\n  }\n  \n  return results;\n}\n\n/**\n * Map query operator to Firestore operator\n */\nfunction mapOperator(op: string): string {\n  const operatorMap: Record<string, string> = {\n    'equals': '==',\n    'not_equals': '!=',\n    'greater_than': '>',\n    'less_than': '<',\n    'greater_than_or_equals': '>=',\n    'less_than_or_equals': '<=',\n    'contains': 'array-contains',\n    'in': 'in',\n    'not_in': 'not-in',\n  };\n  return operatorMap[op] || '==';\n}\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\src\\lib\\workflows\\triggers\\schedule-trigger.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":10,"column":20,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":10,"endColumn":42}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\n * Schedule Trigger Handler\n * Handles scheduled workflow execution (cron jobs)\n */\n\nimport { FirestoreService, COLLECTIONS } from '@/lib/db/firestore-service';\nimport type { Workflow, ScheduleTrigger } from '@/types/workflow';\nimport { executeWorkflow } from '../workflow-executor';\nimport { logger } from '@/lib/logger/logger';\nconst cronParser = require('cron-parser');\n\n/**\n * Register schedule trigger\n * In production, this would set up Cloud Scheduler\n */\nexport async function registerScheduleTrigger(\n  workflow: Workflow,\n  organizationId: string,\n  workspaceId: string\n): Promise<void> {\n  const trigger = workflow.trigger as ScheduleTrigger;\n  \n  if (trigger?.type !== 'schedule') {\n    return;\n  }\n  \n  // Store schedule configuration\n  await FirestoreService.set(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/${COLLECTIONS.WORKSPACES}/${workspaceId}/scheduleTriggers`,\n    workflow.id,\n    {\n      workflowId: workflow.id,\n      schedule: trigger.schedule,\n      organizationId,\n      workspaceId,\n      registeredAt: new Date().toISOString(),\n      nextRun: calculateNextRun(trigger.schedule),\n    },\n    false\n  );\n  \n  logger.info('Schedule Trigger Registered schedule for workflow workflow.id}', { file: 'schedule-trigger.ts' });\n}\n\n/**\n * Calculate next run time from schedule\n */\nfunction calculateNextRun(schedule: ScheduleTrigger['schedule']): string {\n  const now = new Date();\n  \n  if (schedule.type === 'interval') {\n    const interval = schedule.interval!;\n    let milliseconds = interval.value;\n    \n    switch (interval.unit) {\n      case 'minutes':\n        milliseconds *= 60 * 1000;\n        break;\n      case 'hours':\n        milliseconds *= 60 * 60 * 1000;\n        break;\n      case 'days':\n        milliseconds *= 24 * 60 * 60 * 1000;\n        break;\n      case 'weeks':\n        milliseconds *= 7 * 24 * 60 * 60 * 1000;\n        break;\n      case 'months':\n        milliseconds *= 30 * 24 * 60 * 60 * 1000; // Approximate\n        break;\n    }\n    \n    return new Date(now.getTime() + milliseconds).toISOString();\n  } else if (schedule.type === 'cron') {\n    try {\n      const cronExpression = schedule.cron!;\n      \n      // Validate and parse cron expression\n      const interval = cronParser.parseExpression(cronExpression, {\n        currentDate: now,\n        tz: 'UTC' // Or get from organization settings\n      });\n      \n      // Get next occurrence\n      const next = interval.next().toDate();\n      return next.toISOString();\n    } catch (error) {\n      logger.error('[Schedule] Invalid cron expression', error, {\n        cron: schedule.cron,\n        file: 'schedule-trigger.ts'\n      });\n      \n      // Fallback to 1 day from now if invalid\n      return new Date(now.getTime() + 24 * 60 * 60 * 1000).toISOString();\n    }\n  }\n  \n  return now.toISOString();\n}\n\n/**\n * Execute scheduled workflows\n * This would be called by Cloud Scheduler or a cron job\n */\nexport async function executeScheduledWorkflows(): Promise<void> {\n  const now = new Date().toISOString();\n  \n  // Find all schedule triggers that are due\n  const { where, orderBy, limit } = await import('firebase/firestore');\n  \n  // Get all organizations\n  const orgs = await FirestoreService.getAll(COLLECTIONS.ORGANIZATIONS, []);\n  \n  for (const org of orgs) {\n    const workspaces = await FirestoreService.getAll(\n      `${COLLECTIONS.ORGANIZATIONS}/${org.id}/${COLLECTIONS.WORKSPACES}`,\n      []\n    );\n    \n    for (const workspace of workspaces) {\n      const triggers = await FirestoreService.getAll(\n        `${COLLECTIONS.ORGANIZATIONS}/${org.id}/${COLLECTIONS.WORKSPACES}/${workspace.id}/scheduleTriggers`,\n        [\n          where('nextRun', '<=', now),\n          orderBy('nextRun', 'asc'),\n          limit(100), // Process in batches\n        ]\n      );\n      \n      for (const trigger of triggers) {\n        try {\n          // Load workflow\n          const workflow = await FirestoreService.get(\n            `${COLLECTIONS.ORGANIZATIONS}/${org.id}/${COLLECTIONS.WORKSPACES}/${workspace.id}/${COLLECTIONS.WORKFLOWS}`,\n            trigger.workflowId\n          );\n          \n          if (!workflow || (workflow as any).status !== 'active') {\n            continue; // Skip inactive workflows\n          }\n          \n          // Execute workflow\n          const triggerData = {\n            organizationId: org.id,\n            workspaceId: workspace.id,\n            scheduledAt: now,\n            scheduleType: (trigger as any).schedule.type,\n          };\n          \n          await executeWorkflow(workflow as Workflow, triggerData);\n          \n          // Update next run time\n          const scheduleTrigger = workflow.trigger as ScheduleTrigger;\n          const nextRun = calculateNextRun(scheduleTrigger.schedule);\n          \n          await FirestoreService.set(\n            `${COLLECTIONS.ORGANIZATIONS}/${org.id}/${COLLECTIONS.WORKSPACES}/${workspace.id}/scheduleTriggers`,\n            trigger.workflowId,\n            {\n              ...trigger,\n              nextRun,\n              lastRun: now,\n            },\n            false\n          );\n        } catch (error) {\n          logger.error('[Schedule Trigger] Error executing workflow ${trigger.workflowId}:', error, { file: 'schedule-trigger.ts' });\n          // Continue with other workflows\n        }\n      }\n    }\n  }\n}\n\n/**\n * Unregister schedule trigger\n */\nexport async function unregisterScheduleTrigger(\n  workflowId: string,\n  organizationId: string,\n  workspaceId: string\n): Promise<void> {\n  await FirestoreService.delete(\n    `${COLLECTIONS.ORGANIZATIONS}/${organizationId}/${COLLECTIONS.WORKSPACES}/${workspaceId}/scheduleTriggers`,\n    workflowId\n  );\n  \n  logger.info('Schedule Trigger Unregistered schedule for workflow workflowId}', { file: 'schedule-trigger.ts' });\n}\n\n/**\n * Validate cron expression\n */\nexport function validateCronExpression(cron: string): { valid: boolean; error?: string } {\n  try {\n    cronParser.parseExpression(cron);\n    return { valid: true };\n  } catch (error) {\n    return { \n      valid: false, \n      error: error instanceof Error ? error.message : 'Invalid cron expression'\n    };\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\e2e\\ecommerce-checkout.e2e.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":265,"column":37,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":265,"endColumn":81}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * E2E Test: E-Commerce Checkout Flow\r\n * REAL end-to-end testing with actual Stripe test mode\r\n * \r\n * Prerequisites:\r\n * 1. Stripe test API keys configured\r\n * 2. Test organization with products\r\n * 3. Firestore emulator running (optional, will use dev if not)\r\n */\r\n\r\nimport { describe, it, expect, beforeAll, afterAll } from '@jest/globals';\r\nimport { processCheckout } from '@/lib/ecommerce/checkout-service';\r\nimport { getOrCreateCart, addToCart, clearCart } from '@/lib/ecommerce/cart-service';\r\nimport { createProduct } from '@/lib/ecommerce/product-service';\r\nimport { FirestoreService } from '@/lib/db/firestore-service';\r\n\r\ndescribe('E-Commerce Checkout E2E', () => {\r\n  const testOrgId = `test-org-${Date.now()}`;\r\n  const testWorkspaceId = 'default';\r\n  let testProductId: string;\r\n  let testCartId: string;\r\n\r\n  beforeAll(async () => {\r\n    // Create test organization\r\n    await FirestoreService.set('organizations', testOrgId, {\r\n      id: testOrgId,\r\n      name: 'Test E-Commerce Org',\r\n      createdAt: new Date().toISOString(),\r\n    }, false);\r\n\r\n    // Create e-commerce config\r\n    await FirestoreService.set(\r\n      `organizations/${testOrgId}/workspaces/${testWorkspaceId}/ecommerce`,\r\n      'config',\r\n      {\r\n        productSchema: 'products',\r\n        productMappings: {\r\n          name: 'name',\r\n          price: 'price',\r\n          description: 'description',\r\n          inventory: 'stockQuantity',\r\n        },\r\n        payments: {\r\n          providers: [\r\n            {\r\n              provider: 'stripe',\r\n              isDefault: true,\r\n              enabled: true,\r\n              mode: 'test',\r\n            },\r\n          ],\r\n        },\r\n        inventory: {\r\n          trackInventory: true,\r\n          inventoryField: 'stockQuantity',\r\n        },\r\n        notifications: {\r\n          customer: {\r\n            orderConfirmation: {\r\n              enabled: true,\r\n              subject: 'Order Confirmation',\r\n              body: 'Thank you for your order {{orderNumber}}!',\r\n              fromEmail: 'orders@test.com',\r\n              fromName: 'Test Store',\r\n            },\r\n          },\r\n        },\r\n        integration: {\r\n          createCustomerEntity: true,\r\n          customerSchema: 'contacts',\r\n          createOrderEntity: true,\r\n          orderSchema: 'orders',\r\n          triggerWorkflows: false, // Disable for test\r\n        },\r\n      },\r\n      false\r\n    );\r\n\r\n    // Create test product\r\n    const product = await createProduct(testOrgId, {\r\n      name: 'Test Product',\r\n      description: 'A test product for checkout',\r\n      sku: 'TEST-001',\r\n      price: 99.99,\r\n      inStock: true,\r\n      stockQuantity: 100,\r\n      trackInventory: true,\r\n      category: 'Test',\r\n    }, testWorkspaceId);\r\n    testProductId = product.id;\r\n\r\n    console.log(`‚úÖ Test product created: ${testProductId}`);\r\n  }, 30000);\r\n\r\n  afterAll(async () => {\r\n    // Cleanup: Delete test data\r\n    try {\r\n      if (testCartId) {\r\n        await clearCart(testCartId, testWorkspaceId, testOrgId);\r\n      }\r\n      \r\n      // Note: Leave test org for manual inspection if needed\r\n      // In production, we'd clean up everything\r\n      console.log(`‚úÖ Test completed for org: ${testOrgId}`);\r\n    } catch (error) {\r\n      console.warn('Cleanup warning:', error);\r\n    }\r\n  }, 30000);\r\n\r\n  describe('Cart Management', () => {\r\n    it('should create a cart', async () => {\r\n      const sessionId = `test-session-${Date.now()}`;\r\n      const cart = await getOrCreateCart(sessionId, testWorkspaceId, testOrgId);\r\n      \r\n      expect(cart).toBeDefined();\r\n      expect(cart.sessionId).toBe(sessionId);\r\n      expect(cart.items).toEqual([]);\r\n      expect(cart.subtotal).toBe(0);\r\n      \r\n      testCartId = cart.sessionId;\r\n      console.log(`‚úÖ Cart created: ${testCartId}`);\r\n    });\r\n\r\n    it('should add product to cart', async () => {\r\n      expect(testCartId).toBeDefined();\r\n      expect(testProductId).toBeDefined();\r\n      \r\n      const cart = await addToCart(testCartId, testWorkspaceId, testOrgId, testProductId, 2);\r\n\r\n      expect(cart.items.length).toBe(1);\r\n      expect(cart.items[0].productId).toBe(testProductId);\r\n      expect(cart.items[0].quantity).toBe(2);\r\n      expect(cart.items[0].price).toBe(99.99);\r\n      expect(cart.subtotal).toBe(199.98); // 99.99 * 2\r\n      \r\n      console.log(`‚úÖ Product added to cart. Subtotal: $${cart.subtotal}`);\r\n    });\r\n  });\r\n\r\n  describe('Checkout Flow', () => {\r\n    it('should process checkout with Stripe test mode', async () => {\r\n      // NOTE: Requires Stripe test API key to be configured\r\n      // To run this test successfully:\r\n      // 1. Set STRIPE_TEST_SECRET_KEY in environment or API keys\r\n      // 2. Use Stripe test card: pm_card_visa\r\n      // 3. Test will skip if Stripe not configured\r\n      \r\n      expect(testCartId).toBeDefined();\r\n      \r\n      const checkoutData = {\r\n        cartId: testCartId,\r\n        organizationId: testOrgId,\r\n        workspaceId: testWorkspaceId,\r\n        customer: {\r\n          email: 'test@example.com',\r\n          firstName: 'Test',\r\n          lastName: 'Customer',\r\n          phone: '+1-555-0100',\r\n        },\r\n        billingAddress: {\r\n          firstName: 'Test',\r\n          lastName: 'Customer',\r\n          address1: '123 Test St',\r\n          city: 'Test City',\r\n          state: 'CA',\r\n          zip: '90210',\r\n          country: 'US',\r\n        },\r\n        shippingAddress: {\r\n          firstName: 'Test',\r\n          lastName: 'Customer',\r\n          address1: '123 Test St',\r\n          city: 'Test City',\r\n          state: 'CA',\r\n          zip: '90210',\r\n          country: 'US',\r\n        },\r\n        paymentMethod: 'card',\r\n        paymentToken: 'pm_card_visa', // Stripe test token\r\n      };\r\n\r\n      try {\r\n        const order = await processCheckout(checkoutData);\r\n\r\n        // Verify order was created\r\n        expect(order).toBeDefined();\r\n        expect(order.id).toBeDefined();\r\n        expect(order.orderNumber).toBeDefined();\r\n        expect(order.status).toBe('processing');\r\n        expect(order.total).toBeGreaterThan(199); // subtotal + tax/shipping\r\n        expect(order.items.length).toBe(1);\r\n        \r\n        // Verify payment was processed\r\n        expect(order.payment).toBeDefined();\r\n        expect(order.payment.status).toBe('captured');\r\n        expect(order.payment.provider).toBe('stripe');\r\n        expect(order.payment.transactionId).toBeDefined();\r\n        \r\n        console.log(`‚úÖ Order created: ${order.orderNumber}`);\r\n        console.log(`   Transaction ID: ${order.payment.transactionId}`);\r\n        console.log(`   Total: $${order.total}`);\r\n      } catch (error: any) {\r\n        if (error.message.includes('Stripe API key not configured')) {\r\n          console.warn('‚ö†Ô∏è  Skipping Stripe test - API key not configured');\r\n          expect(true).toBe(true); // Pass test with warning\r\n        } else {\r\n          throw error; // Re-throw other errors\r\n        }\r\n      }\r\n    });\r\n\r\n    it('should validate cart before checkout', async () => {\r\n      // Test with empty cart\r\n      const emptyCartId = `cart-empty-${Date.now()}`;\r\n      \r\n      await expect(async () => {\r\n        await processCheckout({\r\n          cartId: emptyCartId,\r\n          organizationId: testOrgId,\r\n          workspaceId: testWorkspaceId,\r\n          customer: {\r\n            email: 'test@example.com',\r\n            firstName: 'Test',\r\n            lastName: 'User',\r\n          },\r\n          billingAddress: {\r\n            firstName: 'Test',\r\n            lastName: 'User',\r\n            address1: '123 Test St',\r\n            city: 'Test City',\r\n            state: 'CA',\r\n            zip: '90210',\r\n            country: 'US',\r\n          },\r\n          shippingAddress: {\r\n            firstName: 'Test',\r\n            lastName: 'User',\r\n            address1: '123 Test St',\r\n            city: 'Test City',\r\n            state: 'CA',\r\n            zip: '90210',\r\n            country: 'US',\r\n          },\r\n          paymentMethod: 'card',\r\n        });\r\n      }).rejects.toThrow('Cart is empty');\r\n      \r\n      console.log(`‚úÖ Empty cart validation works`);\r\n    });\r\n  });\r\n\r\n  describe('Inventory Management', () => {\r\n    it('should track inventory after checkout', async () => {\r\n      // NOTE: This test would check that inventory was decremented\r\n      // Requires successful checkout first (which is skipped above)\r\n      // Once Stripe is configured, this will validate inventory tracking\r\n      \r\n      console.log(`‚ö†Ô∏è  Inventory test skipped - requires successful checkout`);\r\n      expect(true).toBe(true); // Placeholder\r\n    });\r\n  });\r\n\r\n  describe('Payment Providers', () => {\r\n    it('should have multiple payment providers configured', () => {\r\n      const { PAYMENT_PROVIDERS } = require('@/lib/ecommerce/payment-providers');\r\n      \r\n      expect(PAYMENT_PROVIDERS).toBeDefined();\r\n      expect(PAYMENT_PROVIDERS.length).toBeGreaterThan(0);\r\n      \r\n      // Check for major providers\r\n      const providerIds = PAYMENT_PROVIDERS.map((p: any) => p.id);\r\n      expect(providerIds).toContain('stripe');\r\n      expect(providerIds).toContain('paypal');\r\n      \r\n      console.log(`‚úÖ ${PAYMENT_PROVIDERS.length} payment providers available`);\r\n    });\r\n  });\r\n});\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\integration\\email-integration.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":90,"column":41,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":90,"endColumn":78},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":102,"column":41,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":102,"endColumn":78},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":114,"column":34,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":114,"endColumn":71}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Email Integration Tests\r\n * Real integration tests for email sending (uses test mode)\r\n */\r\n\r\nimport { describe, it, expect } from '@jest/globals';\r\nimport { sendEmail } from '@/lib/email/email-service';\r\n\r\ndescribe('Email Integration Tests', () => {\r\n  describe('Email Sending (Requires SendGrid/Gmail Test Config)', () => {\r\n    it.skip('should send email via SendGrid', async () => {\r\n      // SKIP: Requires SendGrid API key configured\r\n      // To run this test:\r\n      // 1. Add SENDGRID_API_KEY to environment\r\n      // 2. Remove .skip from this test\r\n      \r\n      const result = await sendEmail({\r\n        to: 'test@example.com',\r\n        subject: 'Integration Test Email',\r\n        html: '<h1>Test</h1><p>This is a test email from integration tests.</p>',\r\n        from: 'noreply@test.com',\r\n        fromName: 'Test Platform',\r\n      });\r\n\r\n      expect(result).toBeDefined();\r\n      expect(result.success).toBe(true);\r\n      expect(result.messageId).toBeDefined();\r\n    });\r\n\r\n    it.skip('should send email via Gmail API', async () => {\r\n      // SKIP: Requires Gmail OAuth token\r\n      \r\n      const result = await sendEmail({\r\n        to: 'test@example.com',\r\n        subject: 'Integration Test Email (Gmail)',\r\n        html: '<h1>Test via Gmail</h1>',\r\n        from: 'you@gmail.com',\r\n        metadata: {\r\n          organizationId: 'test-org',\r\n        },\r\n      });\r\n\r\n      expect(result.success).toBe(true);\r\n    });\r\n  });\r\n\r\n  describe('Email Template Rendering', () => {\r\n    it('should replace variables in email templates', () => {\r\n      const template = 'Hello {{firstName}}, your order {{orderNumber}} is confirmed!';\r\n      const variables = {\r\n        firstName: 'Jane',\r\n        orderNumber: 'ORD-98765',\r\n      };\r\n      \r\n      // Simple variable replacement (actual implementation in email-service.ts)\r\n      const rendered = template.replace(/\\{\\{(\\w+)\\}\\}/g, (_, key) => variables[key as keyof typeof variables] || '');\r\n      \r\n      expect(rendered).toBe('Hello Jane, your order ORD-98765 is confirmed!');\r\n    });\r\n  });\r\n\r\n  describe('Email Validation', () => {\r\n    it('should validate email addresses', () => {\r\n      const validEmails = [\r\n        'test@example.com',\r\n        'user.name@company.co.uk',\r\n        'firstname+lastname@domain.com',\r\n      ];\r\n      \r\n      const invalidEmails = [\r\n        'not-an-email',\r\n        '@nodomain.com',\r\n        'missing@',\r\n      ];\r\n      \r\n      const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\r\n      \r\n      validEmails.forEach(email => {\r\n        expect(emailRegex.test(email)).toBe(true);\r\n      });\r\n      \r\n      invalidEmails.forEach(email => {\r\n        expect(emailRegex.test(email)).toBe(false);\r\n      });\r\n    });\r\n  });\r\n\r\n  describe('Email Tracking', () => {\r\n    it('should generate tracking pixels', () => {\r\n      const { generateTrackingPixel } = require('@/lib/email/email-tracking');\r\n      \r\n      const trackingId = 'track-12345';\r\n      const pixel = generateTrackingPixel(trackingId);\r\n      \r\n      expect(pixel).toContain(`/api/email/track/${trackingId}`);\r\n      expect(pixel).toContain('<img');\r\n      expect(pixel).toContain('width=\"1\"');\r\n      expect(pixel).toContain('height=\"1\"');\r\n    });\r\n\r\n    it('should wrap links with tracking', () => {\r\n      const { wrapLinksWithTracking } = require('@/lib/email/email-tracking');\r\n      \r\n      const html = '<a href=\"https://example.com\">Click here</a>';\r\n      const wrapped = wrapLinksWithTracking(html, 'track-12345');\r\n      \r\n      expect(wrapped).toContain('/api/email/track/link');\r\n      expect(wrapped).toContain('url=https%3A%2F%2Fexample.com');\r\n    });\r\n  });\r\n\r\n  describe('Email Bounce Handling', () => {\r\n    it('should classify bounce types', () => {\r\n      const { classifyBounce } = require('@/lib/email/email-tracking');\r\n      \r\n      // Hard bounces (permanent)\r\n      expect(classifyBounce('550 5.1.1 User unknown')).toBe('hard');\r\n      expect(classifyBounce('Invalid recipient')).toBe('hard');\r\n      \r\n      // Soft bounces (temporary)\r\n      expect(classifyBounce('Mailbox full')).toBe('soft');\r\n      expect(classifyBounce('Temporarily unavailable')).toBe('soft');\r\n      \r\n      // Spam/blocked\r\n      expect(classifyBounce('Spam detected')).toBe('spam');\r\n      expect(classifyBounce('550 5.7.1 Blocked')).toBe('blocked');\r\n    });\r\n  });\r\n});\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\integration\\sms-integration.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":49,"column":33,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":49,"endColumn":65},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":62,"column":39,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":62,"endColumn":71},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":76,"column":37,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":76,"endColumn":69}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * SMS Integration Tests  \r\n * Real integration tests for SMS sending (uses test mode/sandbox)\r\n */\r\n\r\nimport { describe, it, expect } from '@jest/globals';\r\nimport { sendSMS } from '@/lib/sms/sms-service';\r\n\r\ndescribe('SMS Integration Tests', () => {\r\n  describe('SMS Sending (Requires Twilio Test Account)', () => {\r\n    it.skip('should send SMS via Twilio test mode', async () => {\r\n      // SKIP: Requires Twilio test credentials configured\r\n      // To run this test:\r\n      // 1. Get Twilio test Account SID and Auth Token\r\n      // 2. Configure in apiKeyService for test org\r\n      // 3. Remove .skip from this test\r\n      \r\n      const result = await sendSMS({\r\n        to: '+15005550006', // Twilio magic number (valid, delivers in test mode)\r\n        message: 'Test message from integration test',\r\n        from: '+15005550006', // Twilio test number\r\n        organizationId: 'test-org',\r\n      });\r\n\r\n      expect(result).toBeDefined();\r\n      expect(result.success).toBe(true);\r\n      expect(result.messageId).toBeDefined();\r\n      expect(result.provider).toBe('twilio');\r\n    });\r\n\r\n    it.skip('should handle invalid phone numbers', async () => {\r\n      // SKIP: Requires Twilio configured\r\n      \r\n      const result = await sendSMS({\r\n        to: '+15005550001', // Twilio magic number (invalid)\r\n        message: 'Test message',\r\n        from: '+15005550006',\r\n        organizationId: 'test-org',\r\n      });\r\n\r\n      expect(result.success).toBe(false);\r\n      expect(result.error).toContain('invalid');\r\n    });\r\n  });\r\n\r\n  describe('SMS Provider Configuration', () => {\r\n    it('should have Twilio and Vonage providers configured', () => {\r\n      // This test verifies provider configurations exist\r\n      const { SMS_PROVIDERS } = require('@/lib/sms/sms-service');\r\n      \r\n      expect(SMS_PROVIDERS).toBeDefined();\r\n      expect(Array.isArray(SMS_PROVIDERS)).toBe(true);\r\n      \r\n      const providerIds = SMS_PROVIDERS.map((p: any) => p.id);\r\n      expect(providerIds).toContain('twilio');\r\n      expect(providerIds).toContain('vonage');\r\n    });\r\n  });\r\n\r\n  describe('Phone Number Validation', () => {\r\n    it('should validate phone numbers', () => {\r\n      const { validatePhoneNumber } = require('@/lib/sms/sms-service');\r\n      \r\n      // Valid formats\r\n      expect(validatePhoneNumber('+15551234567')).toBe(true);\r\n      expect(validatePhoneNumber('+447911123456')).toBe(true);\r\n      \r\n      // Invalid formats\r\n      expect(validatePhoneNumber('555-1234')).toBe(false);\r\n      expect(validatePhoneNumber('not-a-phone')).toBe(false);\r\n    });\r\n  });\r\n\r\n  describe('SMS Templates', () => {\r\n    it('should support variable replacement in templates', () => {\r\n      const { renderSMSTemplate } = require('@/lib/sms/sms-service');\r\n      \r\n      const template = 'Hello {{firstName}}, your order {{orderNumber}} is ready!';\r\n      const variables = {\r\n        firstName: 'John',\r\n        orderNumber: 'ORD-12345',\r\n      };\r\n      \r\n      const rendered = renderSMSTemplate(template, variables);\r\n      expect(rendered).toBe('Hello John, your order ORD-12345 is ready!');\r\n    });\r\n  });\r\n});\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\lib\\slack\\slack-service.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":352,"column":22,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":352,"endColumn":39}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Slack Service Tests\r\n * \r\n * Comprehensive test coverage for SlackService class.\r\n */\r\n\r\nimport { SlackService } from '@/lib/slack/slack-service';\r\nimport type { SlackServiceConfig, SlackWorkspace } from '@/lib/slack/types';\r\nimport { Timestamp } from 'firebase-admin/firestore';\r\n\r\n// Mock fetch\r\nglobal.fetch = jest.fn();\r\n\r\ndescribe('SlackService', () => {\r\n  let service: SlackService;\r\n  let mockConfig: SlackServiceConfig;\r\n  \r\n  beforeEach(() => {\r\n    mockConfig = {\r\n      clientId: 'test-client-id',\r\n      clientSecret: 'test-client-secret',\r\n      signingSecret: 'test-signing-secret',\r\n      scopes: ['channels:read', 'chat:write'],\r\n      rateLimit: {\r\n        maxPerMinute: 60,\r\n        maxPerHour: 3000,\r\n      },\r\n      retry: {\r\n        maxRetries: 3,\r\n        initialDelayMs: 1000,\r\n        maxDelayMs: 30000,\r\n        backoffMultiplier: 2,\r\n      },\r\n      verifyWebhooks: true,\r\n    };\r\n    \r\n    service = new SlackService(mockConfig);\r\n    \r\n    // Clear mocks\r\n    jest.clearAllMocks();\r\n  });\r\n  \r\n  describe('getAuthorizationUrl', () => {\r\n    it('should generate correct OAuth URL', () => {\r\n      const state = 'test-state';\r\n      const redirectUri = 'https://example.com/callback';\r\n      \r\n      const url = service.getAuthorizationUrl(state, redirectUri);\r\n      \r\n      expect(url).toContain('slack.com/oauth/v2/authorize');\r\n      expect(url).toContain(`client_id=${mockConfig.clientId}`);\r\n      expect(url).toContain(`state=${state}`);\r\n      expect(url).toContain(`redirect_uri=${encodeURIComponent(redirectUri)}`);\r\n      expect(url).toContain('scope=');\r\n    });\r\n  });\r\n  \r\n  describe('exchangeOAuthCode', () => {\r\n    it('should successfully exchange code for token', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        access_token: 'xoxb-test-token',\r\n        token_type: 'bot',\r\n        scope: 'channels:read,chat:write',\r\n        bot_user_id: 'U123',\r\n        app_id: 'A123',\r\n        team: {\r\n          id: 'T123',\r\n          name: 'Test Team',\r\n        },\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      const result = await service.exchangeOAuthCode('test-code', 'https://example.com/callback');\r\n      \r\n      expect(result.access_token).toBe('xoxb-test-token');\r\n      expect(result.team.id).toBe('T123');\r\n      expect(result.bot_user_id).toBe('U123');\r\n    });\r\n    \r\n    it('should throw error on failed exchange', async () => {\r\n      const mockResponse = {\r\n        ok: false,\r\n        error: 'invalid_code',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 400,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      await expect(\r\n        service.exchangeOAuthCode('invalid-code', 'https://example.com/callback')\r\n      ).rejects.toThrow();\r\n    });\r\n  });\r\n  \r\n  describe('sendMessage', () => {\r\n    let mockWorkspace: SlackWorkspace;\r\n    \r\n    beforeEach(() => {\r\n      mockWorkspace = {\r\n        id: 'workspace-1',\r\n        organizationId: 'org-1',\r\n        teamId: 'T123',\r\n        teamName: 'Test Team',\r\n        botToken: 'xoxb-test-token',\r\n        botUserId: 'U123',\r\n        scopes: ['channels:read', 'chat:write'],\r\n        installedBy: {\r\n          userId: 'user-1',\r\n        },\r\n        status: 'connected',\r\n        connectedAt: Timestamp.now(),\r\n        settings: {\r\n          enabled: true,\r\n          mentions: {\r\n            allowChannelMentions: true,\r\n            allowHereMentions: true,\r\n          },\r\n        },\r\n        createdAt: Timestamp.now(),\r\n        updatedAt: Timestamp.now(),\r\n      };\r\n    });\r\n    \r\n    it('should successfully send text message', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        channel: 'C123',\r\n        ts: '1234567890.123456',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock)\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => mockResponse,\r\n        })\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => ({\r\n            ok: true,\r\n            permalink: 'https://example.slack.com/archives/C123/p1234567890123456',\r\n          }),\r\n        });\r\n      \r\n      const result = await service.sendMessage(mockWorkspace, {\r\n        channelId: 'C123',\r\n        text: 'Test message',\r\n        type: 'text',\r\n        priority: 'medium',\r\n        category: 'system',\r\n      });\r\n      \r\n      expect(result.ts).toBe('1234567890.123456');\r\n      expect(result.channel).toBe('C123');\r\n      expect(result.permalink).toBeTruthy();\r\n    });\r\n    \r\n    it('should add channel mention for critical priority', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        channel: 'C123',\r\n        ts: '1234567890.123456',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock)\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => mockResponse,\r\n        })\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => ({\r\n            ok: true,\r\n            permalink: 'https://example.slack.com/archives/C123/p1234567890123456',\r\n          }),\r\n        });\r\n      \r\n      await service.sendMessage(mockWorkspace, {\r\n        channelId: 'C123',\r\n        text: 'Critical alert',\r\n        type: 'text',\r\n        priority: 'critical',\r\n        category: 'deal_risk',\r\n        mentions: {\r\n          channel: true,\r\n        },\r\n      });\r\n      \r\n      const fetchCalls = (global.fetch as jest.Mock).mock.calls;\r\n      const messageCall = fetchCalls.find(call => call[0].includes('chat.postMessage'));\r\n      const payload = JSON.parse(messageCall[1].body);\r\n      \r\n      expect(payload.text).toContain('<!channel>');\r\n    });\r\n    \r\n    it('should send message with blocks', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        channel: 'C123',\r\n        ts: '1234567890.123456',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock)\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => mockResponse,\r\n        })\r\n        .mockResolvedValueOnce({\r\n          status: 200,\r\n          json: async () => ({\r\n            ok: true,\r\n            permalink: 'https://example.slack.com/archives/C123/p1234567890123456',\r\n          }),\r\n        });\r\n      \r\n      await service.sendMessage(mockWorkspace, {\r\n        channelId: 'C123',\r\n        text: 'Test message',\r\n        type: 'blocks',\r\n        priority: 'medium',\r\n        category: 'system',\r\n        blocks: [\r\n          {\r\n            type: 'section',\r\n            text: {\r\n              type: 'mrkdwn',\r\n              text: 'Hello *world*',\r\n            },\r\n          },\r\n        ],\r\n      });\r\n      \r\n      const fetchCalls = (global.fetch as jest.Mock).mock.calls;\r\n      const messageCall = fetchCalls.find(call => call[0].includes('chat.postMessage'));\r\n      const payload = JSON.parse(messageCall[1].body);\r\n      \r\n      expect(payload.blocks).toHaveLength(1);\r\n      expect(payload.blocks[0].type).toBe('section');\r\n    });\r\n    \r\n    it('should handle rate limit errors', async () => {\r\n      const mockResponse = {\r\n        ok: false,\r\n        error: 'rate_limited',\r\n        retry_after: 60,\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 429,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      await expect(\r\n        service.sendMessage(mockWorkspace, {\r\n          channelId: 'C123',\r\n          text: 'Test message',\r\n          type: 'text',\r\n          priority: 'medium',\r\n          category: 'system',\r\n        })\r\n      ).rejects.toThrow();\r\n    });\r\n  });\r\n  \r\n  describe('listChannels', () => {\r\n    it('should successfully list channels', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        channels: [\r\n          {\r\n            id: 'C123',\r\n            name: 'general',\r\n            is_channel: true,\r\n            is_group: false,\r\n            is_im: false,\r\n            is_mpim: false,\r\n            is_private: false,\r\n            created: 1234567890,\r\n            is_archived: false,\r\n            is_member: true,\r\n            num_members: 10,\r\n          },\r\n          {\r\n            id: 'C456',\r\n            name: 'random',\r\n            is_channel: true,\r\n            is_group: false,\r\n            is_im: false,\r\n            is_mpim: false,\r\n            is_private: false,\r\n            created: 1234567890,\r\n            is_archived: false,\r\n            is_member: false,\r\n            num_members: 5,\r\n          },\r\n        ],\r\n        response_metadata: {\r\n          next_cursor: '',\r\n        },\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      const result = await service.listChannels('xoxb-test-token', {\r\n        excludeArchived: true,\r\n        limit: 100,\r\n      });\r\n      \r\n      expect(result.channels).toHaveLength(2);\r\n      expect(result.channels[0].name).toBe('general');\r\n      expect(result.channels[0].type).toBe('public_channel');\r\n    });\r\n    \r\n    it('should handle pagination', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        channels: [],\r\n        response_metadata: {\r\n          next_cursor: 'next-page-cursor',\r\n        },\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      const result = await service.listChannels('xoxb-test-token', {\r\n        limit: 100,\r\n        cursor: 'current-cursor',\r\n      });\r\n      \r\n      expect(result.nextCursor).toBe('next-page-cursor');\r\n    });\r\n  });\r\n  \r\n  describe('verifyWebhookSignature', () => {\r\n    it('should verify valid signature', () => {\r\n      const timestamp = Math.floor(Date.now() / 1000).toString();\r\n      const body = JSON.stringify({ type: 'event_callback' });\r\n      \r\n      // Generate valid signature\r\n      const crypto = require('crypto');\r\n      const sigBasestring = `v0:${timestamp}:${body}`;\r\n      const signature = `v0=${crypto\r\n        .createHmac('sha256', mockConfig.signingSecret)\r\n        .update(sigBasestring)\r\n        .digest('hex')}`;\r\n      \r\n      const isValid = service.verifyWebhookSignature(timestamp, signature, body);\r\n      \r\n      expect(isValid).toBe(true);\r\n    });\r\n    \r\n    it('should reject invalid signature', () => {\r\n      const timestamp = Math.floor(Date.now() / 1000).toString();\r\n      const body = JSON.stringify({ type: 'event_callback' });\r\n      const signature = 'v0=invalid-signature';\r\n      \r\n      const isValid = service.verifyWebhookSignature(timestamp, signature, body);\r\n      \r\n      expect(isValid).toBe(false);\r\n    });\r\n    \r\n    it('should reject old timestamp', () => {\r\n      const oldTimestamp = Math.floor(Date.now() / 1000 - 400).toString(); // 6+ minutes ago\r\n      const body = JSON.stringify({ type: 'event_callback' });\r\n      const signature = 'v0=test';\r\n      \r\n      const isValid = service.verifyWebhookSignature(oldTimestamp, signature, body);\r\n      \r\n      expect(isValid).toBe(false);\r\n    });\r\n  });\r\n  \r\n  describe('testAuth', () => {\r\n    it('should successfully test auth', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        url: 'https://example.slack.com/',\r\n        team: 'Test Team',\r\n        user: 'test-user',\r\n        team_id: 'T123',\r\n        user_id: 'U123',\r\n        bot_id: 'B123',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      const result = await service.testAuth('xoxb-test-token');\r\n      \r\n      expect(result.team_id).toBe('T123');\r\n      expect(result.bot_id).toBe('B123');\r\n    });\r\n    \r\n    it('should throw error on invalid token', async () => {\r\n      const mockResponse = {\r\n        ok: false,\r\n        error: 'invalid_auth',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 401,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      await expect(\r\n        service.testAuth('invalid-token')\r\n      ).rejects.toThrow();\r\n    });\r\n  });\r\n  \r\n  describe('revokeToken', () => {\r\n    it('should successfully revoke token', async () => {\r\n      const mockResponse = {\r\n        ok: true,\r\n        revoked: true,\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      await expect(\r\n        service.revokeToken('xoxb-test-token')\r\n      ).resolves.not.toThrow();\r\n    });\r\n    \r\n    it('should handle already revoked token', async () => {\r\n      const mockResponse = {\r\n        ok: false,\r\n        error: 'token_revoked',\r\n      };\r\n      \r\n      (global.fetch as jest.Mock).mockResolvedValueOnce({\r\n        status: 200,\r\n        json: async () => mockResponse,\r\n      });\r\n      \r\n      await expect(\r\n        service.revokeToken('xoxb-test-token')\r\n      ).resolves.not.toThrow();\r\n    });\r\n  });\r\n});\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\oauth-service.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":11,"column":35,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":11,"endColumn":78},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":20,"column":31,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":20,"endColumn":74},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":27,"column":31,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":27,"endColumn":74},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":33,"column":31,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":33,"endColumn":74},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":39,"column":31,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":39,"endColumn":74},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":49,"column":44,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":49,"endColumn":92},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":57,"column":43,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":57,"endColumn":91},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":65,"column":43,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":65,"endColumn":91},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":75,"column":38,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":75,"endColumn":80},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":83,"column":37,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":83,"endColumn":79},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":91,"column":37,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":91,"endColumn":79},{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":99,"column":34,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":99,"endColumn":76}],"suppressedMessages":[],"errorCount":12,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * OAuth Service Tests\r\n * Test OAuth 2.0 flows for integrations\r\n */\r\n\r\nimport { describe, it, expect } from '@jest/globals';\r\n\r\ndescribe('OAuth Service', () => {\r\n  describe('Authorization URL Generation', () => {\r\n    it('should generate valid OAuth URL with state token', async () => {\r\n      const { generateAuthUrl } = require('@/lib/integrations/oauth-service');\r\n      \r\n      // This would need mocking in real tests\r\n      expect(typeof generateAuthUrl).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Supported Providers', () => {\r\n    it('should support Google OAuth', () => {\r\n      const { OAuthConfig } = require('@/lib/integrations/oauth-service');\r\n      \r\n      // Verify type exists\r\n      expect(OAuthConfig).toBeDefined();\r\n    });\r\n    \r\n    it('should support Microsoft OAuth', () => {\r\n      const { OAuthConfig } = require('@/lib/integrations/oauth-service');\r\n      \r\n      expect(OAuthConfig).toBeDefined();\r\n    });\r\n    \r\n    it('should support QuickBooks OAuth', () => {\r\n      const { OAuthConfig } = require('@/lib/integrations/oauth-service');\r\n      \r\n      expect(OAuthConfig).toBeDefined();\r\n    });\r\n    \r\n    it('should support Xero OAuth', () => {\r\n      const { OAuthConfig } = require('@/lib/integrations/oauth-service');\r\n      \r\n      expect(OAuthConfig).toBeDefined();\r\n    });\r\n  });\r\n});\r\n\r\ndescribe('QuickBooks Service', () => {\r\n  describe('Customer Sync', () => {\r\n    it('should format customer data for QuickBooks API', () => {\r\n      const { syncCustomerToQuickBooks } = require('@/lib/integrations/quickbooks-service');\r\n      \r\n      expect(typeof syncCustomerToQuickBooks).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Invoice Creation', () => {\r\n    it('should format invoice data correctly', () => {\r\n      const { createQuickBooksInvoice } = require('@/lib/integrations/quickbooks-service');\r\n      \r\n      expect(typeof createQuickBooksInvoice).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Payment Recording', () => {\r\n    it('should format payment data correctly', () => {\r\n      const { recordQuickBooksPayment } = require('@/lib/integrations/quickbooks-service');\r\n      \r\n      expect(typeof recordQuickBooksPayment).toBe('function');\r\n    });\r\n  });\r\n});\r\n\r\ndescribe('Xero Service', () => {\r\n  describe('Contact Sync', () => {\r\n    it('should format contact data for Xero API', () => {\r\n      const { syncCustomerToXero } = require('@/lib/integrations/xero-service');\r\n      \r\n      expect(typeof syncCustomerToXero).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Invoice Creation', () => {\r\n    it('should create invoices in Xero format', () => {\r\n      const { createXeroInvoice } = require('@/lib/integrations/xero-service');\r\n      \r\n      expect(typeof createXeroInvoice).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Payment Recording', () => {\r\n    it('should record payments in Xero', () => {\r\n      const { recordXeroPayment } = require('@/lib/integrations/xero-service');\r\n      \r\n      expect(typeof recordXeroPayment).toBe('function');\r\n    });\r\n  });\r\n  \r\n  describe('Tenant Management', () => {\r\n    it('should fetch available Xero tenants', () => {\r\n      const { getXeroTenants } = require('@/lib/integrations/xero-service');\r\n      \r\n      expect(typeof getXeroTenants).toBe('function');\r\n    });\r\n  });\r\n});\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\performance\\load-test.js","messages":[{"ruleId":"no-undef","severity":2,"message":"'__ENV' is not defined.","line":35,"column":18,"nodeType":"Identifier","messageId":"undef","endLine":35,"endColumn":23},{"ruleId":"no-undef","severity":2,"message":"'__VU' is not defined.","line":74,"column":34,"nodeType":"Identifier","messageId":"undef","endLine":74,"endColumn":38},{"ruleId":"no-undef","severity":2,"message":"'__VU' is not defined.","line":134,"column":21,"nodeType":"Identifier","messageId":"undef","endLine":134,"endColumn":25}],"suppressedMessages":[],"errorCount":3,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * k6 Load Testing Script\r\n * Test platform performance under high load\r\n * \r\n * Run with: k6 run load-test.js\r\n */\r\n\r\nimport http from 'k6/http';\r\nimport { check, sleep } from 'k6';\r\nimport { Rate } from 'k6/metrics';\r\n\r\n// Custom metrics\r\nconst errorRate = new Rate('errors');\r\n\r\n// Test configuration\r\nexport const options = {\r\n  stages: [\r\n    // Ramp up\r\n    { duration: '2m', target: 100 },   // 100 users over 2 minutes\r\n    { duration: '5m', target: 100 },   // Stay at 100 for 5 minutes\r\n    { duration: '2m', target: 200 },   // Ramp to 200\r\n    { duration: '5m', target: 200 },   // Stay at 200\r\n    { duration: '2m', target: 500 },   // Ramp to 500\r\n    { duration: '5m', target: 500 },   // Stay at 500\r\n    { duration: '5m', target: 1000 },  // Spike to 1000\r\n    { duration: '10m', target: 0 },    // Ramp down\r\n  ],\r\n  thresholds: {\r\n    http_req_duration: ['p(95)<500'],  // 95% of requests < 500ms\r\n    http_req_failed: ['rate<0.01'],    // Error rate < 1%\r\n    errors: ['rate<0.05'],             // Custom error rate < 5%\r\n  },\r\n};\r\n\r\nconst BASE_URL = __ENV.BASE_URL || 'http://localhost:3000';\r\n\r\n// Test scenarios\r\nexport default function () {\r\n  const scenarios = [\r\n    testHomePage,\r\n    testAgentChat,\r\n    testCustomerList,\r\n    testProductCatalog,\r\n    testCheckout,\r\n  ];\r\n  \r\n  // Random scenario selection\r\n  const scenario = scenarios[Math.floor(Math.random() * scenarios.length)];\r\n  scenario();\r\n  \r\n  sleep(1);\r\n}\r\n\r\n/**\r\n * Test home page load\r\n */\r\nfunction testHomePage() {\r\n  const res = http.get(`${BASE_URL}/`);\r\n  \r\n  const success = check(res, {\r\n    'status is 200': (r) => r.status === 200,\r\n    'page loads in < 500ms': (r) => r.timings.duration < 500,\r\n  });\r\n  \r\n  errorRate.add(!success);\r\n}\r\n\r\n/**\r\n * Test agent chat endpoint\r\n */\r\nfunction testAgentChat() {\r\n  const payload = JSON.stringify({\r\n    message: 'What is your return policy?',\r\n    customerId: `test-customer-${__VU}`,\r\n    agentId: 'test-agent',\r\n    stream: false,\r\n  });\r\n  \r\n  const params = {\r\n    headers: {\r\n      'Content-Type': 'application/json',\r\n      'Authorization': 'Bearer test-token',\r\n    },\r\n  };\r\n  \r\n  const res = http.post(`${BASE_URL}/api/agent/chat`, payload, params);\r\n  \r\n  const success = check(res, {\r\n    'status is 200 or 401': (r) => r.status === 200 || r.status === 401,\r\n    'response time < 2s': (r) => r.timings.duration < 2000,\r\n  });\r\n  \r\n  errorRate.add(!success);\r\n}\r\n\r\n/**\r\n * Test customer list\r\n */\r\nfunction testCustomerList() {\r\n  const res = http.get(`${BASE_URL}/api/customers?page=1&limit=50`);\r\n  \r\n  const success = check(res, {\r\n    'status is 200 or 401': (r) => r.status === 200 || r.status === 401,\r\n    'response time < 300ms': (r) => r.timings.duration < 300,\r\n  });\r\n  \r\n  errorRate.add(!success);\r\n}\r\n\r\n/**\r\n * Test product catalog\r\n */\r\nfunction testProductCatalog() {\r\n  const res = http.get(`${BASE_URL}/api/products?page=1&limit=20`);\r\n  \r\n  const success = check(res, {\r\n    'status is 200 or 401': (r) => r.status === 200 || r.status === 401,\r\n    'response time < 300ms': (r) => r.timings.duration < 300,\r\n  });\r\n  \r\n  errorRate.add(!success);\r\n}\r\n\r\n/**\r\n * Test checkout flow\r\n */\r\nfunction testCheckout() {\r\n  const payload = JSON.stringify({\r\n    items: [\r\n      { productId: 'test-product-1', quantity: 1 },\r\n      { productId: 'test-product-2', quantity: 2 },\r\n    ],\r\n    customer: {\r\n      email: `test${__VU}@example.com`,\r\n      firstName: 'Test',\r\n      lastName: 'User',\r\n    },\r\n  });\r\n  \r\n  const params = {\r\n    headers: {\r\n      'Content-Type': 'application/json',\r\n    },\r\n  };\r\n  \r\n  const res = http.post(`${BASE_URL}/api/checkout/calculate`, payload, params);\r\n  \r\n  const success = check(res, {\r\n    'status is 200 or 401': (r) => r.status === 200 || r.status === 401,\r\n    'response time < 1s': (r) => r.timings.duration < 1000,\r\n  });\r\n  \r\n  errorRate.add(!success);\r\n}\r\n\r\n/**\r\n * Stress test - maximum load\r\n */\r\nexport function stressTest() {\r\n  // Override options for stress testing\r\n  options.stages = [\r\n    { duration: '2m', target: 1000 },\r\n    { duration: '5m', target: 1000 },\r\n    { duration: '2m', target: 2000 },\r\n    { duration: '5m', target: 2000 },\r\n    { duration: '5m', target: 0 },\r\n  ];\r\n}\r\n\r\n/**\r\n * Spike test - sudden traffic spike\r\n */\r\nexport function spikeTest() {\r\n  options.stages = [\r\n    { duration: '10s', target: 100 },\r\n    { duration: '1m', target: 100 },\r\n    { duration: '10s', target: 1400 },  // Spike!\r\n    { duration: '3m', target: 1400 },\r\n    { duration: '10s', target: 100 },\r\n    { duration: '3m', target: 100 },\r\n    { duration: '10s', target: 0 },\r\n  ];\r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","usedDeprecatedRules":[]},{"filePath":"C:\\Users\\David\\PycharmProjects\\AI Sales Platform\\tests\\validation.test.ts","messages":[{"ruleId":"@typescript-eslint/no-require-imports","severity":2,"message":"A `require()` style import is forbidden.","line":14,"column":5,"nodeType":"CallExpression","messageId":"noRequireImports","endLine":14,"endColumn":45}],"suppressedMessages":[],"errorCount":1,"fatalErrorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"source":"/**\r\n * Unit Tests for Validation Schemas\r\n * Tests critical input validation to ensure security\r\n */\r\n\r\nconst {\r\n  emailSendSchema,\r\n  smsSendSchema,\r\n  paymentIntentSchema,\r\n  workflowExecuteSchema,\r\n  leadScoringSchema,\r\n  campaignCreateSchema,\r\n  validateInput,\r\n} = require('../src/lib/validation/schemas');\r\n\r\ndescribe('Validation Schemas', () => {\r\n  describe('emailSendSchema', () => {\r\n    it('should validate correct email data', () => {\r\n      const validData = {\r\n        to: 'test@example.com',\r\n        subject: 'Test Subject',\r\n        html: '<p>Test</p>',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(emailSendSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n\r\n    it('should reject invalid email', () => {\r\n      const invalidData = {\r\n        to: 'not-an-email',\r\n        subject: 'Test',\r\n        html: '<p>Test</p>',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(emailSendSchema, invalidData);\r\n      expect(result.success).toBe(false);\r\n    });\r\n\r\n    it('should require organizationId', () => {\r\n      const invalidData = {\r\n        to: 'test@example.com',\r\n        subject: 'Test',\r\n        html: '<p>Test</p>',\r\n      };\r\n      const result = validateInput(emailSendSchema, invalidData);\r\n      expect(result.success).toBe(false);\r\n    });\r\n\r\n    it('should require either html or text', () => {\r\n      const invalidData = {\r\n        to: 'test@example.com',\r\n        subject: 'Test',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(emailSendSchema, invalidData);\r\n      expect(result.success).toBe(false);\r\n    });\r\n  });\r\n\r\n  describe('smsSendSchema', () => {\r\n    it('should validate correct SMS data', () => {\r\n      const validData = {\r\n        to: '+1234567890',\r\n        message: 'Test message',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(smsSendSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n\r\n    it('should require organizationId', () => {\r\n      const invalidData = {\r\n        to: '+1234567890',\r\n        message: 'Test',\r\n      };\r\n      const result = validateInput(smsSendSchema, invalidData);\r\n      expect(result.success).toBe(false);\r\n    });\r\n  });\r\n\r\n  describe('createPaymentIntentSchema', () => {\r\n    it('should validate correct payment intent data', () => {\r\n      const validData = {\r\n        amount: 1000,\r\n        currency: 'usd',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(paymentIntentSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n\r\n    it('should reject negative amounts', () => {\r\n      const invalidData = {\r\n        amount: -100,\r\n        currency: 'usd',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(paymentIntentSchema, invalidData);\r\n      expect(result.success).toBe(false);\r\n    });\r\n  });\r\n\r\n  describe('workflowExecuteSchema', () => {\r\n    it('should validate correct workflow execution data', () => {\r\n      const validData = {\r\n        workflowId: 'workflow-123',\r\n        triggerData: { event: 'contact.created' },\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(workflowExecuteSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n  });\r\n\r\n  describe('leadScoringSchema', () => {\r\n    it('should validate correct lead scoring data', () => {\r\n      const validData = {\r\n        leadId: 'lead-123',\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(leadScoringSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n  });\r\n\r\n  describe('createCampaignSchema', () => {\r\n    it('should validate correct campaign data', () => {\r\n      const validData = {\r\n        name: 'Test Campaign',\r\n        subject: 'Test Subject',\r\n        templateId: 'template-123',\r\n        recipientList: ['test@example.com'],\r\n        organizationId: 'org-123',\r\n      };\r\n      const result = validateInput(campaignCreateSchema, validData);\r\n      expect(result.success).toBe(true);\r\n    });\r\n  });\r\n});\r\n\r\n","usedDeprecatedRules":[]}]